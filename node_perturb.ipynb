{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document:\n",
    "- Creates a node perturbation network, and trains it\n",
    "- then saves the weights and parameters of that network to a file\n",
    "- then saves the relevant data to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "from IPython.display import Image, SVG, display\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import contextlib\n",
    "import io\n",
    "\n",
    "## Other functions imports\n",
    "from helpers import sigmoid, ReLU, add_bias, create_batches, calculate_accuracy, calculate_cosine_similarity, calculate_grad_snr\n",
    "\n",
    "from MLP import MLP, NodePerturbMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST function\n",
    "def download_mnist(train_prop=0.8, keep_prop=0.5):\n",
    "\n",
    "  valid_prop = 1 - train_prop\n",
    "\n",
    "  discard_prop = 1 - keep_prop\n",
    "\n",
    "  transform = torchvision.transforms.Compose(\n",
    "      [torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "      )\n",
    "\n",
    "\n",
    "  with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "    \n",
    "    rng_data = np.random.default_rng(seed=42)\n",
    "    train_num = 50000\n",
    "    shuffled_train_idx = rng_data.permutation(train_num)\n",
    "\n",
    "    full_train_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=True, download=True, transform=transform)\n",
    "    full_test_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    full_train_images = full_train_set.data.numpy().astype(float) / 255\n",
    "    train_images = full_train_images[shuffled_train_idx[:train_num]].reshape((-1, 784)).T.copy()\n",
    "    valid_images = full_train_images[shuffled_train_idx[train_num:]].reshape((-1, 784)).T.copy()\n",
    "    test_images = (full_test_set.data.numpy().astype(float) / 255).reshape((-1, 784)).T\n",
    "\n",
    "    full_train_labels = torch.nn.functional.one_hot(full_train_set.targets, num_classes=10).numpy()\n",
    "    train_labels = full_train_labels[shuffled_train_idx[:train_num]].T.copy()\n",
    "    valid_labels = full_train_labels[shuffled_train_idx[train_num:]].T.copy()\n",
    "    test_labels = torch.nn.functional.one_hot(full_test_set.targets, num_classes=10).numpy().T\n",
    "\n",
    "    train_set, valid_set, _ = torch.utils.data.random_split(\n",
    "      full_train_set, [train_prop * keep_prop, valid_prop * keep_prop, discard_prop])\n",
    "    test_set, _ = torch.utils.data.random_split(\n",
    "      full_test_set, [keep_prop, discard_prop])\n",
    "\n",
    "  print(\"Number of examples retained:\")\n",
    "  print(f\"  {len(train_set)} (training)\")\n",
    "  print(f\"  {len(valid_set)} (validation)\")\n",
    "  print(f\"  {len(test_set)} (test)\")\n",
    "\n",
    "  return train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels = download_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparams\n",
    "NUM_INPUTS = 784\n",
    "NUM_OUTPUTS = 10\n",
    "numhidden = 500\n",
    "batchsize = 128\n",
    "initweight = 0.1\n",
    "learnrate = 0.001\n",
    "noise = 0.1\n",
    "numepochs = 25\n",
    "numrepeats = 1\n",
    "numbatches = int(train_images.shape[1] / batchsize)\n",
    "numupdates = numepochs * numbatches\n",
    "activation = 'sigmoid'\n",
    "report = True\n",
    "rep_rate = 1\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the network\n",
    "\n",
    "# @title Train and observe the performance of NodePerturbMLP\n",
    "\n",
    "losses_node_perturb = np.zeros((numupdates,))\n",
    "accuracy_node_perturb = np.zeros((numepochs,))\n",
    "test_losses_node_perturb = np.zeros((numepochs,))\n",
    "snr_node_perturb = np.zeros((numepochs,))\n",
    "cosine_similarity_node_perturb = np.zeros((numepochs,))\n",
    "\n",
    "# set the random seed\n",
    "rng_np = np.random.default_rng(seed=seed)\n",
    "\n",
    "# select 1000 random images to test the accuracy on\n",
    "indices = rng_np.choice(range(test_images.shape[1]), size=(1000,), replace=False)\n",
    "\n",
    "# create a network and train it using weight perturbation\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    netnodeperturb = NodePerturbMLP(rng_np, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "    (losses_node_perturb[:], accuracy_node_perturb[:], test_losses_node_perturb[:], snr_node_perturb, cosine_similarity_node_perturb[:]) = \\\n",
    "        netnodeperturb.train(rng_np, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                             learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, \\\n",
    "                             report=report, report_rate=rep_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weights and params\n",
    "torch.save(netnodeperturb.state_dict(), \"node_perturb_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the weights and params, in the main doc:\n",
    "netnodeperturb = MLP()\n",
    "netnodeperturb.load_state_dict(torch.load('mlp_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dfs as csv\n",
    "\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "data = [losses_node_perturb, accuracy_node_perturb, test_losses_node_perturb, snr_node_perturb, cosine_similarity_node_perturb]\n",
    "\n",
    "for i, df in enumerate(data):\n",
    "  df.tofile(f\"data/node_perturb/{filenames[i]}.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb = data[0]\n",
    "accuracy_node_perturb = data[1]\n",
    "test_losses_node_perturb = data[2]\n",
    "snr_node_perturb = data[3]\n",
    "cosine_similarity_node_perturb = data[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
