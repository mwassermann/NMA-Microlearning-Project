{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much code taken from Neuromatch NeuroAI 2024 Microlearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from IPython.display import Image, SVG, display\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import contextlib\n",
    "import io\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "## Plotting and metrics imports\n",
    "from metrics import get_plotting_color, plot_examples, plot_class_distribution, plot_results, plot_scores_per_class, plot_weights\n",
    "\n",
    "## Other functions imports\n",
    "from helpers import sigmoid, ReLU, add_bias, create_batches, calculate_accuracy, calculate_cosine_similarity, calculate_grad_snr\n",
    "\n",
    "## MLP imports\n",
    "from MLP import MLP, NodePerturbMLP, KolenPollackMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST function\n",
    "def download_mnist(train_prop=0.8, keep_prop=0.5):\n",
    "\n",
    "  valid_prop = 1 - train_prop\n",
    "\n",
    "  discard_prop = 1 - keep_prop\n",
    "\n",
    "  transform = torchvision.transforms.Compose(\n",
    "      [torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "      )\n",
    "\n",
    "\n",
    "  with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "    \n",
    "    rng_data = np.random.default_rng(seed=42)\n",
    "    train_num = 50000\n",
    "    shuffled_train_idx = rng_data.permutation(train_num)\n",
    "\n",
    "    full_train_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=True, download=True, transform=transform)\n",
    "    full_test_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    full_train_images = full_train_set.data.numpy().astype(float) / 255\n",
    "    train_images = full_train_images[shuffled_train_idx[:train_num]].reshape((-1, 784)).T.copy()\n",
    "    valid_images = full_train_images[shuffled_train_idx[train_num:]].reshape((-1, 784)).T.copy()\n",
    "    test_images = (full_test_set.data.numpy().astype(float) / 255).reshape((-1, 784)).T\n",
    "\n",
    "    full_train_labels = torch.nn.functional.one_hot(full_train_set.targets, num_classes=10).numpy()\n",
    "    train_labels = full_train_labels[shuffled_train_idx[:train_num]].T.copy()\n",
    "    valid_labels = full_train_labels[shuffled_train_idx[train_num:]].T.copy()\n",
    "    test_labels = torch.nn.functional.one_hot(full_test_set.targets, num_classes=10).numpy().T\n",
    "\n",
    "    train_set, valid_set, _ = torch.utils.data.random_split(\n",
    "      full_train_set, [train_prop * keep_prop, valid_prop * keep_prop, discard_prop])\n",
    "    test_set, _ = torch.utils.data.random_split(\n",
    "      full_test_set, [keep_prop, discard_prop])\n",
    "\n",
    "  print(\"Number of examples retained:\")\n",
    "  print(f\"  {len(train_set)} (training)\")\n",
    "  print(f\"  {len(valid_set)} (validation)\")\n",
    "  print(f\"  {len(test_set)} (test)\")\n",
    "\n",
    "  return train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels = download_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "NUM_INPUTS = 784\n",
    "NUM_OUTPUTS = 10\n",
    "numhidden = 500\n",
    "batchsize = 128\n",
    "initweight = 0.1\n",
    "learnrate = 0.001\n",
    "noise = 0.1\n",
    "numepochs = 25\n",
    "numrepeats = 1\n",
    "numbatches = int(train_images.shape[1] / batchsize)\n",
    "numupdates = numepochs * numbatches\n",
    "activation = 'sigmoid'\n",
    "report = True\n",
    "rep_rate = 1\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "indices = np.random.choice(test_images.shape[1], size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal learning\n",
    "netbackprop = MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_normal, accuracy_bp_normal, test_loss_bp_normal, snr_bp_normal, cosine_similarity_bp_normal) = \\\n",
    "    netbackprop.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online learning\n",
    "from MLP import MLP, NodePerturbMLP, KolenPollackMLP\n",
    "\n",
    "net_bp_online = MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_online, accuracy_bp_online, test_loss_bp_online, snr_bp_online, cosine_similarity_bp_online) = \\\n",
    "    net_bp_online.train_online(rng, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-1, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "# create a network and train it using backprop\n",
    "netbackprop_noisy = MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_noisy, accuracy_bp_noisy, test_loss_bp_noisy, snr_bp_noisy, cosine_similarity_bp_noisy) = \\\n",
    "    netbackprop_noisy.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_bp_nonstat = MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_nonstat, accuracy_bp_nonstat, test_loss_bp_nonstat, snr_bp_nonstat, cosine_similarity_bp_nonstat) = \\\n",
    "    net_bp_nonstat.train_nonstat_data(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "netffa_online = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_online_ce, test_loss_ffa_online_ce, \n",
    " losses_ffa_online_mse, test_loss_ffa_online_mse,\n",
    " accuracy_ffa_online) = netffa_online.train_online(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    max_it=150000, conv_loss=0.50, \n",
    "    report_rate=batchsize, lr=0.01,\n",
    "    model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(losses_ffa_online_ce), \n",
    "      len(test_loss_ffa_online_ce),\n",
    "      len(losses_ffa_online_mse),\n",
    "      len(test_loss_ffa_online_mse),\n",
    "      len(accuracy_ffa_online)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_online_ce.npy', np.asarray(losses_ffa_online_ce))\n",
    "np.save('results/netffa/test_loss_ffa_online_ce.npy', np.asarray(test_loss_ffa_online_ce))\n",
    "np.save('results/netffa/losses_ffa_online_mse.npy', np.asarray(losses_ffa_online_mse))\n",
    "np.save('results/netffa/test_loss_ffa_online_mse.npy', np.asarray(test_loss_ffa_online_mse))\n",
    "np.save('results/netffa/accuracy_ffa_online.npy', np.asarray(accuracy_ffa_online))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "net_ffa_nonstat = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_nonstat_ce, test_loss_ffa_nonstat_ce, \n",
    " losses_ffa_nonstat_mse, test_loss_ffa_nonstat_mse,\n",
    " accuracy_ffa_nonstat) = net_ffa_nonstat.train_nonstationary(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    epochs=numepochs, model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(losses_ffa_nonstat_ce), \n",
    "      len(test_loss_ffa_nonstat_ce),\n",
    "      len(losses_ffa_nonstat_mse),\n",
    "      len(test_loss_ffa_nonstat_mse),\n",
    "      len(accuracy_ffa_nonstat)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_nonstat_ce.npy', np.asarray(losses_ffa_nonstat_ce))\n",
    "np.save('results/netffa/test_loss_ffa_nonstat_ce.npy', np.asarray(test_loss_ffa_nonstat_ce))\n",
    "np.save('results/netffa/losses_ffa_nonstat_mse.npy', np.asarray(losses_ffa_nonstat_mse))\n",
    "np.save('results/netffa/test_loss_ffa_nonstat_mse.npy', np.asarray(test_loss_ffa_nonstat_mse))\n",
    "np.save('results/netffa/accuracy_ffa_nonstat.npy', np.asarray(accuracy_ffa_nonstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "net_ffa_noisy = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_noisy_ce, test_loss_ffa_noisy_ce, \n",
    " losses_ffa_noisy_mse, test_loss_ffa_noisy_mse,\n",
    " accuracy_ffa_noisy) = net_ffa_noisy.train_noisydata(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    epochs=numepochs, model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(losses_ffa_noisy_ce), \n",
    "      len(test_loss_ffa_noisy_ce),\n",
    "      len(losses_ffa_noisy_mse),\n",
    "      len(test_loss_ffa_noisy_mse),\n",
    "      len(accuracy_ffa_noisy)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_noisy_ce.npy', np.asarray(losses_ffa_noisy_ce))\n",
    "np.save('results/netffa/test_loss_ffa_noisy_ce.npy', np.asarray(test_loss_ffa_noisy_ce))\n",
    "np.save('results/netffa/losses_ffa_noisy_mse.npy', np.asarray(losses_ffa_noisy_mse))\n",
    "np.save('results/netffa/test_loss_ffa_noisy_mse.npy', np.asarray(test_loss_ffa_noisy_mse))\n",
    "np.save('results/netffa/accuracy_ffa_noisy.npy', np.asarray(accuracy_ffa_noisy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/test/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_test = data[0]\n",
    "accuracy_node_perturb_test = data[1]\n",
    "test_losses_node_perturb_test = data[2]\n",
    "snr_node_perturb_test = data[3]\n",
    "cosine_similarity_node_perturb_test = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/normal/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_normal = data[0]\n",
    "accuracy_node_perturb_normal = data[1]\n",
    "test_losses_node_perturb_normal = data[2]\n",
    "snr_node_perturb_normal = data[3]\n",
    "cosine_similarity_node_perturb_normal = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/online/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_online = data[0]\n",
    "accuracy_node_perturb_online = data[1]\n",
    "test_losses_node_perturb_online = data[2]\n",
    "snr_node_perturb_online = data[3]\n",
    "cosine_similarity_node_perturb_online = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/noisy/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_noisy = data[0]\n",
    "accuracy_node_perturb_noisy = data[1]\n",
    "test_losses_node_perturb_noisy = data[2]\n",
    "snr_node_perturb_noisy = data[3]\n",
    "cosine_similarity_node_perturb_noisy = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/non-stat/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_non_stat = data[0]\n",
    "accuracy_node_perturb_non_stat = data[1]\n",
    "test_losses_node_perturb_non_stat = data[2]\n",
    "snr_node_perturb_non_stat = data[3]\n",
    "cosine_similarity_node_perturb_non_stat = data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolen-Pollack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "netkolepoll = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_normal, accuracy_kp_normal, test_loss_kp_normal, snr_kp_normal, cosine_similarity_kp_normal) = \\\n",
    "    netkolepoll.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)\n",
    "\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "net_kp_online = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_online, accuracy_kp_online, test_loss_kp_online, snr_kp_online, cosine_similarity_kp_online) = \\\n",
    "    net_kp_online.train_online(rng, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-1, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "net_kp_noisy = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_noisy, accuracy_kp_noisy, test_loss_kp_noisy, snr_kp_noisy, cosine_similarity_kp_noisy) = \\\n",
    "    net_kp_noisy.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_kp_nonstat = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_nonstat, accuracy_kp_nonstat, test_loss_kp_nonstat, snr_kp_nonstat, cosine_similarity_kp_nonstat) = \\\n",
    "    net_kp_nonstat.train_nonstat_data(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run without node perturb and ffa\n",
    "# FFA\n",
    "snr_ffa_normal, cosine_similarity_ffa_normal = [0], [0]\n",
    "snr_ffa_online, cosine_similarity_ffa_online = [0], [0]\n",
    "snr_ffa_noisy, cosine_similarity_ffa_noisy = [0], [0]\n",
    "snr_ffa_nonstat, cosine_similarity_ffa_nonstat = [0], [0]\n",
    "\n",
    "# Node Perturb\n",
    "losses_np_normal, accuracy_np_normal, test_loss_np_normal, snr_np_normal, cosine_similarity_np_normal = [0], [0], [0], [0], [0]\n",
    "losses_np_online, accuracy_np_online, test_loss_np_online, snr_np_online, cosine_similarity_np_online = [0], [0], [0], [0], [0]\n",
    "losses_np_noisy, accuracy_np_noisy, test_loss_np_noisy, snr_np_noisy, cosine_similarity_np_noisy = [0], [0], [0], [0], [0]\n",
    "losses_np_nonstat, accuracy_np_nonstat, test_loss_np_nonstat, snr_np_nonstat, cosine_similarity_np_nonstat = [0], [0], [0], [0], [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays\n",
    "# normal \n",
    "tr_loss_normal = [losses_bp_normal, losses_ffa_normal_ce, losses_np_normal, losses_kp_normal]\n",
    "te_acc_normal = [accuracy_bp_normal, accuracy_ffa_normal, accuracy_np_normal, accuracy_kp_normal]\n",
    "te_loss_normal = [test_loss_bp_normal, test_loss_ffa_normal_ce, test_loss_np_normal, test_loss_kp_normal]\n",
    "snr_normal = [snr_bp_normal, snr_ffa_normal, snr_np_normal, snr_kp_normal]\n",
    "cosine_similarity_normal = [cosine_similarity_bp_normal, cosine_similarity_ffa_normal, cosine_similarity_np_normal, cosine_similarity_kp_normal]\n",
    "\n",
    "# online\n",
    "# Calculate the moving average\n",
    "window_size = 100\n",
    "losses_bp_online_mean = uniform_filter1d(losses_bp_online, size=window_size)\n",
    "losses_ffa_online_mean = uniform_filter1d(losses_ffa_online_ce, size=window_size)\n",
    "losses_np_online_mean = uniform_filter1d(losses_np_online, size=window_size)\n",
    "losses_kp_online_mean = uniform_filter1d(losses_kp_online, size=window_size)\n",
    "tr_loss_online_mean = [losses_bp_online_mean, losses_ffa_online_mean, losses_np_online_mean, losses_kp_online_mean]\n",
    "\n",
    "tr_loss_online = [losses_bp_online, losses_ffa_online_ce, losses_np_online, losses_kp_online]\n",
    "te_acc_online = [accuracy_bp_online, accuracy_ffa_online, accuracy_np_online, accuracy_kp_online]\n",
    "te_loss_online = [test_loss_bp_online, test_loss_ffa_online_ce, test_loss_np_online, test_loss_kp_online]\n",
    "snr_online = [snr_bp_online, snr_ffa_online, snr_np_online, snr_kp_online]\n",
    "cosine_similarity_online = [cosine_similarity_bp_online, cosine_similarity_ffa_online, cosine_similarity_np_online, cosine_similarity_kp_online]\n",
    "\n",
    "# noisy\n",
    "tr_loss_noisy = [losses_bp_noisy, losses_ffa_noisy_ce, losses_np_noisy, losses_kp_noisy]\n",
    "te_acc_noisy = [accuracy_bp_noisy, accuracy_ffa_noisy, accuracy_np_noisy, accuracy_kp_noisy]\n",
    "te_loss_noisy = [test_loss_bp_noisy, test_loss_ffa_noisy_ce, test_loss_np_noisy, test_loss_kp_noisy]\n",
    "snr_noisy = [snr_bp_noisy, snr_ffa_noisy, snr_np_noisy, snr_kp_noisy]\n",
    "cosine_similarity_noisy = [cosine_similarity_bp_noisy, cosine_similarity_ffa_noisy, cosine_similarity_np_noisy, cosine_similarity_kp_noisy]\n",
    "\n",
    "# nonstat\n",
    "tr_loss_nonstat = [losses_bp_nonstat, losses_ffa_nonstat, losses_np_nonstat, losses_kp_nonstat]\n",
    "te_acc_nonstat = [accuracy_bp_nonstat, accuracy_ffa_nonstat, accuracy_np_nonstat, accuracy_kp_nonstat]\n",
    "te_loss_nonstat = [test_loss_bp_nonstat, test_loss_ffa_nonstat_ce, test_loss_np_nonstat, test_loss_kp_nonstat]\n",
    "snr_nonstat = [snr_bp_nonstat, snr_ffa_nonstat, snr_np_nonstat, snr_kp_nonstat]\n",
    "cosine_similarity_nonstat = [cosine_similarity_bp_nonstat, cosine_similarity_ffa_nonstat, cosine_similarity_np_nonstat, cosine_similarity_kp_nonstat]\n",
    "\n",
    "# algorithms\n",
    "# algos = ['normal', 'online', 'noisy', 'nonstat']\n",
    "algos = ['normal', 'noisy', 'nonstat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "for i, algo in enumerate(algos):\n",
    "    if algo == 'normal':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_normal, te_acc_normal, te_loss_normal, snr_normal, cosine_similarity_normal\n",
    "    # elif algo == 'online':\n",
    "    #     tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_online, te_acc_online, te_loss_online, snr_online, cosine_similarity_online\n",
    "    elif algo == 'noisy':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_noisy, te_acc_noisy, te_loss_noisy, snr_noisy, cosine_similarity_noisy\n",
    "    elif algo == 'nonstat':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_nonstat, te_acc_nonstat, te_loss_nonstat, snr_nonstat, cosine_similarity_nonstat\n",
    "        \n",
    "    # plot\n",
    "    plt.figure(figsize=(30, 5))\n",
    "    plt.subplot(151)\n",
    "\n",
    "    plt.plot(tr_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(tr_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(tr_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(tr_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    \n",
    "    plt.xlabel(\"Updates (every batch)\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training loss\")\n",
    "\n",
    "    plt.subplot(152)\n",
    "    plt.plot(te_acc[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_acc[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_acc[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_acc[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Performance over time\")\n",
    "\n",
    "    plt.subplot(153)\n",
    "    plt.plot(te_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Test loss\")\n",
    "\n",
    "    plt.subplot(154)\n",
    "    with plt.xkcd():\n",
    "            x = [0, 1, 2, 3]\n",
    "            snr1_vals = [snr[0][:, 1], snr[0][:, 2], snr[0][:, 3], snr[0][:, 0]]\n",
    "            snr2_vals = [snr[1][:, 1], snr[1][:, 2], snr[1][:, 3], snr[1][:, 0]]\n",
    "            colors = ['gold', 'c', 'k', 'r']\n",
    "            labels = ['FFA', 'Node Perturbation', 'Kolen Pollack', 'Backprop']\n",
    "            for i in range(len(snr1_vals)):\n",
    "                plt.bar(x, snr1_vals[i], color=colors, tick_label=labels)\n",
    "                plt.bar(x, snr2_vals[i], color=colors, tick_label=labels, alpha=0.5)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.ylabel('SNR')\n",
    "            plt.xlabel('Algorithm')\n",
    "            plt.title('Gradient SNR')\n",
    "\n",
    "    plt.subplot(155)\n",
    "    with plt.xkcd():\n",
    "        epochs = np.arange(0, numepochs, 1)\n",
    "        plt.plot(epochs, cos_sim[0][:, 0], label=\"Backprop, 1st layer\", color='r', linestyle=':')\n",
    "        plt.plot(epochs, cos_sim[0][:, 1], label=\"Backprop, 2nd layer\", color='r', linestyle='-.')\n",
    "        # plt.plot(cos_sim[1][:, 0], label=\"FFA, 1st layer\", color='gold', linestyle=':')\n",
    "        # plt.plot(cos_sim[1][:, 1], label=\"FFA, 2nd layer\", color='gold', linestyle='-.')\n",
    "        # plt.plot(cos_sim[2][:, 0], label=\"Node Perturbation, 1st layer\", color='c', linestyle=':')\n",
    "        # plt.plot(cos_sim[2][:, 1], label=\"Node Perturbation, 2nd layer\", color='c', linestyle='-.')\n",
    "        plt.plot(epochs, cos_sim[3][:, 0], label=\"Kollen-Pollack, 1st layer\", color='k', linestyle=':')\n",
    "        plt.plot(epochs, cos_sim[3][:, 1], label=\"Kollen-Pollack, 2nd layer\", color='k', linestyle='-.')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Cosine Sim\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Cosine Similarity to Backprop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning separately becuase of different lenghts and additional smoothing operation\n",
    "# plot\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(151)\n",
    "\n",
    "plt.plot(tr_loss_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(tr_loss_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(tr_loss_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(tr_loss_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "\n",
    "plt.xlabel(\"Updates (every batch)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "plt.subplot(152)\n",
    "plt.plot(te_acc_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(te_acc_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(te_acc_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(te_acc_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance over time\")\n",
    "\n",
    "plt.subplot(153)\n",
    "plt.plot(te_loss_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(te_loss_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(te_loss_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(te_loss_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Test loss\")\n",
    "\n",
    "plt.subplot(154)\n",
    "with plt.xkcd():\n",
    "        x = [0, 1, 2, 3]\n",
    "        snr1_vals = [snr_online[0][:, 1], snr_online[0][:, 2], snr_online[0][:, 3], snr_online[0][:, 0]]\n",
    "        snr2_vals = [snr_online[1][:, 1], snr_online[1][:, 2], snr_online[1][:, 3], snr_online[1][:, 0]]\n",
    "        colors = ['gold', 'c', 'k', 'r']\n",
    "        labels = ['FFA', 'Node Perturbation', 'Kolen Pollack', 'Backprop']\n",
    "        for i in range(len(snr1_vals)):\n",
    "            plt.bar(x, snr1_vals[i], color=colors, tick_label=labels)\n",
    "            plt.bar(x, snr2_vals[i], color=colors, tick_label=labels, alpha=0.5)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('SNR')\n",
    "        plt.xlabel('Algorithm')\n",
    "        plt.title('Gradient SNR')\n",
    "\n",
    "plt.subplot(155)\n",
    "with plt.xkcd():\n",
    "    epochs = np.arange(0, numepochs, 1)\n",
    "    plt.plot(epochs, cosine_similarity_online[0][:, 0], label=\"Backprop, 1st layer\", color='r', linestyle=':')\n",
    "    plt.plot(epochs, cosine_similarity_online[0][:, 1], label=\"Backprop, 2nd layer\", color='r', linestyle='-.')\n",
    "    # plt.plot(cos_sim[1][:, 0], label=\"FFA, 1st layer\", color='gold', linestyle=':')\n",
    "    # plt.plot(cos_sim[1][:, 1], label=\"FFA, 2nd layer\", color='gold', linestyle='-.')\n",
    "    # plt.plot(cos_sim[2][:, 0], label=\"Node Perturbation, 1st layer\", color='c', linestyle=':')\n",
    "    # plt.plot(cos_sim[2][:, 1], label=\"Node Perturbation, 2nd layer\", color='c', linestyle='-.')\n",
    "    plt.plot(epochs, cosine_similarity_online[3][:, 0], label=\"Kollen-Pollack, 1st layer\", color='k', linestyle=':')\n",
    "    plt.plot(epochs, cosine_similarity_online[3][:, 1], label=\"Kollen-Pollack, 2nd layer\", color='k', linestyle='-.')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Cosine Sim\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Cosine Similarity to Backprop\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
