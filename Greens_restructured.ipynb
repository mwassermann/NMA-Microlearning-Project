{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much code taken from Neuromatch NeuroAI 2024 Microlearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'MLP' from 'd:\\\\MyFolders\\\\project\\\\2024summer\\\\NeuroAI\\\\NMA-Microlearning-Project\\\\MLP.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dependencies\n",
    "from IPython.display import Image, SVG, display\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import contextlib\n",
    "import io\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "## Plotting and metrics imports\n",
    "from metrics import get_plotting_color, plot_examples, plot_class_distribution, plot_results, plot_scores_per_class, plot_weights\n",
    "\n",
    "## Other functions imports\n",
    "from helpers import sigmoid, ReLU, add_bias, create_batches, calculate_accuracy, calculate_cosine_similarity, calculate_grad_snr\n",
    "\n",
    "## MLP imports\n",
    "import MLP\n",
    "from MLP import NodePerturbMLP, KolenPollackMLP\n",
    "\n",
    "## FF imports\n",
    "import net_ff_model\n",
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "import importlib\n",
    "importlib.reload(net_ff_model)\n",
    "importlib.reload(MLP)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST function\n",
    "def download_mnist(train_prop=0.8, keep_prop=0.5):\n",
    "\n",
    "  valid_prop = 1 - train_prop\n",
    "\n",
    "  discard_prop = 1 - keep_prop\n",
    "\n",
    "  transform = torchvision.transforms.Compose(\n",
    "      [torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "      )\n",
    "\n",
    "\n",
    "  with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "    \n",
    "    rng_data = np.random.default_rng(seed=42)\n",
    "    train_num = 50000\n",
    "    shuffled_train_idx = rng_data.permutation(train_num)\n",
    "\n",
    "    full_train_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=True, download=True, transform=transform)\n",
    "    full_test_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    full_train_images = full_train_set.data.numpy().astype(float) / 255\n",
    "    train_images = full_train_images[shuffled_train_idx[:train_num]].reshape((-1, 784)).T.copy()\n",
    "    valid_images = full_train_images[shuffled_train_idx[train_num:]].reshape((-1, 784)).T.copy()\n",
    "    test_images = (full_test_set.data.numpy().astype(float) / 255).reshape((-1, 784)).T\n",
    "\n",
    "    full_train_labels = torch.nn.functional.one_hot(full_train_set.targets, num_classes=10).numpy()\n",
    "    train_labels = full_train_labels[shuffled_train_idx[:train_num]].T.copy()\n",
    "    valid_labels = full_train_labels[shuffled_train_idx[train_num:]].T.copy()\n",
    "    test_labels = torch.nn.functional.one_hot(full_test_set.targets, num_classes=10).numpy().T\n",
    "\n",
    "    train_set, valid_set, _ = torch.utils.data.random_split(\n",
    "      full_train_set, [train_prop * keep_prop, valid_prop * keep_prop, discard_prop])\n",
    "    test_set, _ = torch.utils.data.random_split(\n",
    "      full_test_set, [keep_prop, discard_prop])\n",
    "\n",
    "  print(\"Number of examples retained:\")\n",
    "  print(f\"  {len(train_set)} (training)\")\n",
    "  print(f\"  {len(valid_set)} (validation)\")\n",
    "  print(f\"  {len(test_set)} (test)\")\n",
    "\n",
    "  return train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of examples retained:\n",
      "  24001 (training)\n",
      "  5999 (validation)\n",
      "  5000 (test)\n"
     ]
    }
   ],
   "source": [
    "train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels = download_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1248000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HYPERPARAMETERS\n",
    "NUM_INPUTS = 784\n",
    "NUM_OUTPUTS = 10\n",
    "numhidden = 500\n",
    "batchsize = 128\n",
    "initweight = 0.1\n",
    "learnrate = 0.001\n",
    "noise = 0.1\n",
    "numepochs = 25\n",
    "numrepeats = 1\n",
    "numbatches = int(train_images.shape[1] / batchsize)\n",
    "numupdates = numepochs * numbatches\n",
    "activation = 'sigmoid'\n",
    "report = True\n",
    "rep_rate = 1\n",
    "seed = 12345\n",
    "numupdates*batchsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "rng = np.random.default_rng(seed=seed)\n",
    "indices = np.random.choice(test_images.shape[1], size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting...\n",
      "...completed  1.0  epochs of training. Current training loss:  2.11  epochs of training. Current testing loss:  2.12\n",
      "...completed  2.0  epochs of training. Current training loss:  1.94  epochs of training. Current testing loss:  1.96\n",
      "...completed  3.0  epochs of training. Current training loss:  1.85  epochs of training. Current testing loss:  1.87\n",
      "...completed  4.0  epochs of training. Current training loss:  1.8  epochs of training. Current testing loss:  1.82\n",
      "...completed  5.0  epochs of training. Current training loss:  1.77  epochs of training. Current testing loss:  1.79\n",
      "...completed  6.0  epochs of training. Current training loss:  1.75  epochs of training. Current testing loss:  1.76\n",
      "...completed  7.0  epochs of training. Current training loss:  1.73  epochs of training. Current testing loss:  1.74\n",
      "...completed  8.0  epochs of training. Current training loss:  1.71  epochs of training. Current testing loss:  1.73\n",
      "...completed  9.0  epochs of training. Current training loss:  1.7  epochs of training. Current testing loss:  1.72\n",
      "...completed  10.0  epochs of training. Current training loss:  1.69  epochs of training. Current testing loss:  1.7\n",
      "...completed  11.0  epochs of training. Current training loss:  1.68  epochs of training. Current testing loss:  1.7\n",
      "...completed  12.0  epochs of training. Current training loss:  1.68  epochs of training. Current testing loss:  1.69\n",
      "...completed  13.0  epochs of training. Current training loss:  1.67  epochs of training. Current testing loss:  1.68\n",
      "...completed  14.0  epochs of training. Current training loss:  1.66  epochs of training. Current testing loss:  1.67\n",
      "...completed  15.0  epochs of training. Current training loss:  1.66  epochs of training. Current testing loss:  1.67\n",
      "...completed  16.0  epochs of training. Current training loss:  1.65  epochs of training. Current testing loss:  1.66\n",
      "...completed  17.0  epochs of training. Current training loss:  1.65  epochs of training. Current testing loss:  1.66\n",
      "...completed  18.0  epochs of training. Current training loss:  1.65  epochs of training. Current testing loss:  1.65\n",
      "...completed  19.0  epochs of training. Current training loss:  1.64  epochs of training. Current testing loss:  1.65\n",
      "...completed  20.0  epochs of training. Current training loss:  1.64  epochs of training. Current testing loss:  1.65\n",
      "...completed  21.0  epochs of training. Current training loss:  1.64  epochs of training. Current testing loss:  1.64\n",
      "...completed  22.0  epochs of training. Current training loss:  1.63  epochs of training. Current testing loss:  1.64\n",
      "...completed  23.0  epochs of training. Current training loss:  1.63  epochs of training. Current testing loss:  1.64\n",
      "...completed  24.0  epochs of training. Current training loss:  1.63  epochs of training. Current testing loss:  1.64\n",
      "...completed  25.0  epochs of training. Current training loss:  1.63  epochs of training. Current testing loss:  1.63\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# normal learning\n",
    "netbackprop = MLP.MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_normal, accuracy_bp_normal, test_loss_bp_normal, snr_bp_normal, cosine_similarity_bp_normal) = \\\n",
    "    netbackprop.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9750,) (25,) (25,) 0.10656327458858571 (25, 2)\n"
     ]
    }
   ],
   "source": [
    "print(losses_bp_normal.shape, accuracy_bp_normal.shape, test_loss_bp_normal.shape, snr_bp_normal, cosine_similarity_bp_normal.shape)\n",
    "np.save('results/netbackprop/losses_bp_normal.npy', losses_bp_normal)\n",
    "np.save('results/netbackprop/accuracy_bp_normal.npy', accuracy_bp_normal)\n",
    "np.save('results/netbackprop/test_loss_bp_normal.npy', test_loss_bp_normal)\n",
    "np.save('results/netbackprop/snr_bp_normal.npy', snr_bp_normal)\n",
    "np.save('results/netbackprop/cosine_similarity_bp_normal.npy', cosine_similarity_bp_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# accuracy_online = accuracy_online[::batchsize]\n",
    "#plt.plot(losses_feedback, label=\"Feedback Alignment\", color='g')\n",
    "plt.plot(accuracy_bp_normal, label=\"Backprop\", color='r')\n",
    "'''\n",
    "plt.plot(accuracy_kolepoll, label=\"Kolen-Pollack\", color='k')\n",
    "# plt.plot(accuracy_node_perturb, label=\"Node Perturbation\", color='c')\n",
    "plt.plot(accuracy_online, label=\"Online Learning\", color='gold')\n",
    "plt.plot(accuracy_nonstat, label=\"Non-stationary Data\", color='forestgreen')\n",
    "'''\n",
    "# plt.plot(accuracy_noisy_input, label=\"Noisy Input Data\", color='dodgerblue')\n",
    "plt.xlabel(\"Updates\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting...\n",
      "At iteration 1, the accuracy is 10.0\n",
      "At iteration 129, the accuracy is 8.799999999999999\n",
      "At iteration 257, the accuracy is 8.7\n",
      "At iteration 385, the accuracy is 17.1\n",
      "At iteration 513, the accuracy is 21.0\n",
      "At iteration 641, the accuracy is 9.9\n",
      "At iteration 769, the accuracy is 9.700000000000001\n",
      "At iteration 897, the accuracy is 24.2\n",
      "At iteration 1025, the accuracy is 28.4\n",
      "At iteration 1153, the accuracy is 15.2\n",
      "At iteration 1281, the accuracy is 31.900000000000002\n",
      "At iteration 1409, the accuracy is 29.5\n",
      "At iteration 1537, the accuracy is 34.4\n",
      "At iteration 1665, the accuracy is 24.5\n",
      "At iteration 1793, the accuracy is 30.8\n",
      "At iteration 1921, the accuracy is 35.9\n",
      "At iteration 2049, the accuracy is 40.400000000000006\n",
      "At iteration 2177, the accuracy is 29.799999999999997\n",
      "At iteration 2305, the accuracy is 25.4\n",
      "At iteration 2433, the accuracy is 43.4\n",
      "At iteration 2561, the accuracy is 45.0\n",
      "At iteration 2689, the accuracy is 39.800000000000004\n",
      "At iteration 2817, the accuracy is 34.8\n",
      "At iteration 2945, the accuracy is 42.9\n",
      "At iteration 3073, the accuracy is 50.6\n",
      "At iteration 3201, the accuracy is 35.4\n",
      "At iteration 3329, the accuracy is 57.199999999999996\n",
      "At iteration 3457, the accuracy is 43.9\n",
      "At iteration 3585, the accuracy is 48.6\n",
      "At iteration 3713, the accuracy is 53.1\n",
      "At iteration 3841, the accuracy is 45.4\n",
      "At iteration 3969, the accuracy is 43.6\n",
      "At iteration 4097, the accuracy is 46.2\n",
      "At iteration 4225, the accuracy is 48.8\n",
      "At iteration 4353, the accuracy is 57.3\n",
      "At iteration 4481, the accuracy is 51.1\n",
      "At iteration 4609, the accuracy is 50.6\n",
      "At iteration 4737, the accuracy is 62.4\n",
      "At iteration 4865, the accuracy is 61.4\n",
      "At iteration 4993, the accuracy is 54.800000000000004\n",
      "...completed  5000  iterations (corresponding to 1 epoch) of training data (single images). Current loss:  2.1507 .\n",
      "At iteration 5121, the accuracy is 54.50000000000001\n",
      "At iteration 5249, the accuracy is 52.0\n",
      "At iteration 5377, the accuracy is 61.6\n",
      "At iteration 5505, the accuracy is 62.6\n",
      "At iteration 5633, the accuracy is 56.699999999999996\n",
      "At iteration 5761, the accuracy is 54.6\n",
      "At iteration 5889, the accuracy is 61.1\n",
      "At iteration 6017, the accuracy is 63.7\n",
      "At iteration 6145, the accuracy is 60.099999999999994\n",
      "At iteration 6273, the accuracy is 62.6\n",
      "At iteration 6401, the accuracy is 56.8\n",
      "At iteration 6529, the accuracy is 63.3\n",
      "At iteration 6657, the accuracy is 67.10000000000001\n",
      "At iteration 6785, the accuracy is 62.6\n",
      "At iteration 6913, the accuracy is 65.0\n",
      "At iteration 7041, the accuracy is 56.49999999999999\n",
      "At iteration 7169, the accuracy is 69.6\n",
      "At iteration 7297, the accuracy is 65.60000000000001\n",
      "At iteration 7425, the accuracy is 69.19999999999999\n",
      "At iteration 7553, the accuracy is 66.2\n",
      "At iteration 7681, the accuracy is 72.3\n",
      "At iteration 7809, the accuracy is 66.10000000000001\n",
      "At iteration 7937, the accuracy is 67.30000000000001\n",
      "At iteration 8065, the accuracy is 73.1\n",
      "At iteration 8193, the accuracy is 69.0\n",
      "At iteration 8321, the accuracy is 73.1\n",
      "At iteration 8449, the accuracy is 68.10000000000001\n",
      "At iteration 8577, the accuracy is 76.5\n",
      "At iteration 8705, the accuracy is 72.8\n",
      "At iteration 8833, the accuracy is 72.7\n",
      "At iteration 8961, the accuracy is 74.0\n",
      "At iteration 9089, the accuracy is 75.0\n",
      "At iteration 9217, the accuracy is 71.39999999999999\n",
      "At iteration 9345, the accuracy is 72.7\n",
      "At iteration 9473, the accuracy is 68.2\n",
      "At iteration 9601, the accuracy is 72.1\n",
      "At iteration 9729, the accuracy is 76.9\n",
      "At iteration 9857, the accuracy is 77.9\n",
      "At iteration 9985, the accuracy is 72.0\n",
      "...completed  10000  iterations (corresponding to 1 epoch) of training data (single images). Current loss:  1.9651 .\n",
      "At iteration 10113, the accuracy is 74.0\n",
      "At iteration 10241, the accuracy is 79.60000000000001\n",
      "At iteration 10369, the accuracy is 73.4\n",
      "At iteration 10497, the accuracy is 70.1\n",
      "At iteration 10625, the accuracy is 70.19999999999999\n",
      "At iteration 10753, the accuracy is 75.1\n",
      "At iteration 10881, the accuracy is 72.7\n",
      "At iteration 11009, the accuracy is 76.4\n",
      "At iteration 11137, the accuracy is 76.4\n",
      "At iteration 11265, the accuracy is 74.0\n",
      "At iteration 11393, the accuracy is 77.4\n",
      "At iteration 11521, the accuracy is 75.0\n",
      "At iteration 11649, the accuracy is 73.3\n",
      "At iteration 11777, the accuracy is 75.9\n",
      "At iteration 11905, the accuracy is 79.80000000000001\n",
      "At iteration 12033, the accuracy is 78.10000000000001\n",
      "At iteration 12161, the accuracy is 76.7\n",
      "At iteration 12289, the accuracy is 79.4\n",
      "At iteration 12417, the accuracy is 79.5\n",
      "At iteration 12545, the accuracy is 78.9\n",
      "At iteration 12673, the accuracy is 79.3\n",
      "At iteration 12801, the accuracy is 78.5\n",
      "At iteration 12929, the accuracy is 78.2\n",
      "At iteration 13057, the accuracy is 79.7\n",
      "At iteration 13185, the accuracy is 77.7\n",
      "At iteration 13313, the accuracy is 80.5\n",
      "At iteration 13441, the accuracy is 79.60000000000001\n",
      "At iteration 13569, the accuracy is 80.30000000000001\n",
      "At iteration 13697, the accuracy is 78.3\n",
      "At iteration 13825, the accuracy is 80.2\n",
      "At iteration 13953, the accuracy is 81.39999999999999\n",
      "At iteration 14081, the accuracy is 78.60000000000001\n",
      "At iteration 14209, the accuracy is 80.10000000000001\n",
      "At iteration 14337, the accuracy is 78.60000000000001\n",
      "At iteration 14465, the accuracy is 77.3\n",
      "At iteration 14593, the accuracy is 78.10000000000001\n",
      "At iteration 14721, the accuracy is 81.3\n",
      "At iteration 14849, the accuracy is 79.5\n",
      "At iteration 14977, the accuracy is 78.8\n",
      "...completed  15000  iterations (corresponding to 1 epoch) of training data (single images). Current loss:  1.8689 .\n",
      "At iteration 15105, the accuracy is 78.0\n",
      "At iteration 15233, the accuracy is 82.6\n",
      "At iteration 15361, the accuracy is 80.10000000000001\n",
      "At iteration 15489, the accuracy is 81.89999999999999\n",
      "At iteration 15617, the accuracy is 81.8\n",
      "At iteration 15745, the accuracy is 81.5\n",
      "At iteration 15873, the accuracy is 80.7\n",
      "At iteration 16001, the accuracy is 80.60000000000001\n",
      "At iteration 16129, the accuracy is 79.10000000000001\n",
      "At iteration 16257, the accuracy is 82.6\n",
      "At iteration 16385, the accuracy is 84.3\n",
      "At iteration 16513, the accuracy is 85.0\n",
      "At iteration 16641, the accuracy is 84.0\n",
      "At iteration 16769, the accuracy is 78.8\n",
      "At iteration 16897, the accuracy is 83.39999999999999\n",
      "At iteration 17025, the accuracy is 83.2\n",
      "At iteration 17153, the accuracy is 84.8\n",
      "At iteration 17281, the accuracy is 83.1\n",
      "At iteration 17409, the accuracy is 78.8\n",
      "At iteration 17537, the accuracy is 83.7\n",
      "At iteration 17665, the accuracy is 83.7\n",
      "At iteration 17793, the accuracy is 82.39999999999999\n",
      "At iteration 17921, the accuracy is 83.8\n",
      "At iteration 18049, the accuracy is 78.8\n",
      "At iteration 18177, the accuracy is 84.0\n",
      "At iteration 18305, the accuracy is 85.2\n",
      "At iteration 18433, the accuracy is 82.5\n",
      "At iteration 18561, the accuracy is 83.39999999999999\n",
      "At iteration 18689, the accuracy is 85.6\n",
      "At iteration 18817, the accuracy is 83.6\n",
      "At iteration 18945, the accuracy is 82.3\n",
      "At iteration 19073, the accuracy is 84.1\n",
      "At iteration 19201, the accuracy is 84.5\n",
      "At iteration 19329, the accuracy is 85.7\n",
      "At iteration 19457, the accuracy is 85.3\n",
      "At iteration 19585, the accuracy is 82.69999999999999\n",
      "At iteration 19713, the accuracy is 84.3\n",
      "At iteration 19841, the accuracy is 85.6\n",
      "At iteration 19969, the accuracy is 84.5\n",
      "...completed  20000  iterations (corresponding to 1 epoch) of training data (single images). Current loss:  1.7879 .\n",
      "At iteration 20097, the accuracy is 82.39999999999999\n",
      "At iteration 20225, the accuracy is 85.7\n",
      "At iteration 20353, the accuracy is 84.5\n",
      "At iteration 20481, the accuracy is 83.39999999999999\n",
      "At iteration 20609, the accuracy is 82.69999999999999\n",
      "At iteration 20737, the accuracy is 82.5\n",
      "At iteration 20865, the accuracy is 84.1\n",
      "At iteration 20993, the accuracy is 81.2\n",
      "At iteration 21121, the accuracy is 85.1\n",
      "At iteration 21249, the accuracy is 85.3\n",
      "At iteration 21377, the accuracy is 84.3\n",
      "At iteration 21505, the accuracy is 86.5\n",
      "At iteration 21633, the accuracy is 83.3\n",
      "At iteration 21761, the accuracy is 85.7\n",
      "At iteration 21889, the accuracy is 84.8\n",
      "At iteration 22017, the accuracy is 84.5\n",
      "At iteration 22145, the accuracy is 84.2\n",
      "At iteration 22273, the accuracy is 85.6\n",
      "At iteration 22401, the accuracy is 85.6\n",
      "At iteration 22529, the accuracy is 85.3\n",
      "At iteration 22657, the accuracy is 84.1\n",
      "At iteration 22785, the accuracy is 84.39999999999999\n",
      "At iteration 22913, the accuracy is 85.39999999999999\n",
      "At iteration 23041, the accuracy is 84.8\n",
      "At iteration 23169, the accuracy is 86.6\n",
      "At iteration 23297, the accuracy is 86.2\n",
      "At iteration 23425, the accuracy is 86.5\n",
      "At iteration 23553, the accuracy is 84.8\n",
      "At iteration 23681, the accuracy is 85.1\n",
      "At iteration 23809, the accuracy is 86.0\n",
      "At iteration 23937, the accuracy is 84.39999999999999\n",
      "At iteration 24065, the accuracy is 86.0\n",
      "At iteration 24193, the accuracy is 86.3\n",
      "At iteration 24321, the accuracy is 85.6\n",
      "At iteration 24449, the accuracy is 86.0\n",
      "At iteration 24577, the accuracy is 85.1\n",
      "At iteration 24705, the accuracy is 87.4\n",
      "At iteration 24833, the accuracy is 84.7\n",
      "At iteration 24961, the accuracy is 85.2\n",
      "...completed  25000  iterations (corresponding to 1 epoch) of training data (single images). Current loss:  1.7879 .\n",
      "At iteration 25089, the accuracy is 86.4\n",
      "At iteration 25217, the accuracy is 86.1\n",
      "At iteration 25345, the accuracy is 85.9\n",
      "At iteration 25473, the accuracy is 86.5\n",
      "...completed  25473  iterations of training data (single images). Current loss:  1.57\n",
      "Training complete.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Online learning\u001b[39;00m\n\u001b[0;32m      2\u001b[0m net_bp_online \u001b[38;5;241m=\u001b[39m MLP\u001b[38;5;241m.\u001b[39mMLP(rng, numhidden, sigma\u001b[38;5;241m=\u001b[39minitweight, activation\u001b[38;5;241m=\u001b[39mactivation)\n\u001b[1;32m----> 3\u001b[0m (losses_bp_online, accuracy_bp_online, test_loss_bp_online, snr_bp_online, cosine_similarity_bp_online) \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m      4\u001b[0m     net_bp_online\u001b[38;5;241m.\u001b[39mtrain_online(rng, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n\u001b[0;32m      5\u001b[0m                       learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, max_it\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m, conv_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.75\u001b[39m, algorithm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackprop\u001b[39m\u001b[38;5;124m'\u001b[39m, noise\u001b[38;5;241m=\u001b[39mnoise, \\\n\u001b[0;32m      6\u001b[0m                       report\u001b[38;5;241m=\u001b[39mreport, report_rate\u001b[38;5;241m=\u001b[39mbatchsize)\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 5)"
     ]
    }
   ],
   "source": [
    "# Online learning\n",
    "net_bp_online = MLP.MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_online, accuracy_bp_online, test_loss_bp_online, snr_bp_online, cosine_similarity_bp_online) = \\\n",
    "    net_bp_online.train_online(rng, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=100000, conv_loss = 1.75, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(232,) (231,) (231,) 0.10301087401898926 (231, 2)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/net_bp_online/losses_bp_normal.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m      2\u001b[0m     np\u001b[38;5;241m.\u001b[39masarray(losses_bp_online)\u001b[38;5;241m.\u001b[39mshape, \n\u001b[0;32m      3\u001b[0m     np\u001b[38;5;241m.\u001b[39masarray(accuracy_bp_online)\u001b[38;5;241m.\u001b[39mshape, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     np\u001b[38;5;241m.\u001b[39masarray(cosine_similarity_bp_online)\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/net_bp_online/losses_bp_normal.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlosses_bp_online\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/net_bp_online/accuracy_bp_normal.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39masarray(accuracy_bp_online))\n\u001b[0;32m     10\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/net_bp_online/test_loss_bp_normal.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39masarray(test_loss_bp_online))\n",
      "File \u001b[1;32md:\\.conda\\envs\\neuromatch\\Lib\\site-packages\\numpy\\lib\\npyio.py:542\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    541\u001b[0m         file \u001b[38;5;241m=\u001b[39m file \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[0;32m    545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/net_bp_online/losses_bp_normal.npy'"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.asarray(losses_bp_online).shape, \n",
    "    np.asarray(accuracy_bp_online).shape, \n",
    "    np.asarray(test_loss_bp_online).shape, \n",
    "    np.asarray(snr_bp_online), \n",
    "    np.asarray(cosine_similarity_bp_online).shape\n",
    ")\n",
    "np.save('results/net_bp_online/losses_bp_normal.npy', np.asarray(losses_bp_online))\n",
    "np.save('results/net_bp_online/accuracy_bp_normal.npy', np.asarray(accuracy_bp_online))\n",
    "np.save('results/net_bp_online/test_loss_bp_normal.npy', np.asarray(test_loss_bp_online))\n",
    "np.save('results/net_bp_online/snr_bp_normal.npy', np.asarray(snr_bp_online))\n",
    "np.save('results/net_bp_online/cosine_similarity_bp_normal.npy', np.asarray(cosine_similarity_bp_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training starting...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.92 GiB for an array with shape (1000, 500, 785) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Noisy Input\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# create a network and train it using backprop\u001b[39;00m\n\u001b[0;32m      3\u001b[0m netbackprop_noisy \u001b[38;5;241m=\u001b[39m MLP\u001b[38;5;241m.\u001b[39mMLP(rng, numhidden, sigma\u001b[38;5;241m=\u001b[39minitweight, activation\u001b[38;5;241m=\u001b[39mactivation)\n\u001b[0;32m      4\u001b[0m (losses_bp_noisy, accuracy_bp_noisy, test_loss_bp_noisy, snr_bp_noisy, cosine_similarity_bp_noisy) \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mnetbackprop_noisy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearnrate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbackprop\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mnoise_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgauss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mreport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreport_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrep_rate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyFolders\\project\\2024summer\\NeuroAI\\NMA-Microlearning-Project\\MLP.py:393\u001b[0m, in \u001b[0;36mMLP.train\u001b[1;34m(self, rng, images, labels, num_epochs, test_images, test_labels, learning_rate, batch_size, algorithm, noise, noise_type, report, report_rate)\u001b[0m\n\u001b[0;32m    391\u001b[0m     targets \u001b[38;5;241m=\u001b[39m test_labels[:, [t]]\n\u001b[0;32m    392\u001b[0m     grad[t, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_grad(rng, inputs, targets, algorithm\u001b[38;5;241m=\u001b[39malgorithm, eta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[1;32m--> 393\u001b[0m snr \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_grad_snr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noise_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgauss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms&p\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m    396\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malter_inputs(np\u001b[38;5;241m.\u001b[39mcopy(images), noise_type)\n",
      "File \u001b[1;32md:\\MyFolders\\project\\2024summer\\NeuroAI\\NMA-Microlearning-Project\\helpers.py:98\u001b[0m, in \u001b[0;36mcalculate_grad_snr\u001b[1;34m(grad, epsilon)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_grad_snr\u001b[39m(grad, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m):\n\u001b[0;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Calculate the average SNR |mean|/std across all parameters in a gradient update\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs(np\u001b[38;5;241m.\u001b[39mmean(grad, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m (\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m epsilon))\n",
      "File \u001b[1;32md:\\.conda\\envs\\neuromatch\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3645\u001b[0m, in \u001b[0;36mstd\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m   3642\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3643\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m std(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 3645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3646\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\.conda\\envs\\neuromatch\\Lib\\site-packages\\numpy\\core\\_methods.py:206\u001b[0m, in \u001b[0;36m_std\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_std\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    205\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 206\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    210\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39msqrt(ret, out\u001b[38;5;241m=\u001b[39mret)\n",
      "File \u001b[1;32md:\\.conda\\envs\\neuromatch\\Lib\\site-packages\\numpy\\core\\_methods.py:173\u001b[0m, in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[0;32m    168\u001b[0m     arrmean \u001b[38;5;241m=\u001b[39m arrmean \u001b[38;5;241m/\u001b[39m rcount\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# Compute sum of squared deviations from mean\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# Note that x may not be inexact and that we need it to be an array,\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# not a scalar.\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m x \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marrmean\u001b[49m)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m    176\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, x, out\u001b[38;5;241m=\u001b[39mx)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.92 GiB for an array with shape (1000, 500, 785) and data type float64"
     ]
    }
   ],
   "source": [
    "# Noisy Input\n",
    "# create a network and train it using backprop\n",
    "netbackprop_noisy = MLP.MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_noisy, accuracy_bp_noisy, test_loss_bp_noisy, snr_bp_noisy, cosine_similarity_bp_noisy) = \\\n",
    "    netbackprop_noisy.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_bp_noisy.shape, accuracy_bp_noisy.shape, test_loss_bp_noisy.shape, snr_bp_noisy, cosine_similarity_bp_noisy.shape\n",
    "np.save('results/netbackprop/losses_bp_normal.npy', losses_bp_noisy)\n",
    "np.save('results/netbackprop/accuracy_bp_normal.npy', accuracy_bp_noisy)\n",
    "np.save('results/netbackprop/test_loss_bp_normal.npy', test_loss_bp_noisy)\n",
    "np.save('results/netbackprop/snr_bp_normal.npy', snr_bp_noisy)\n",
    "np.save('results/netbackprop/cosine_similarity_bp_normal.npy', cosine_similarity_bp_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_bp_nonstat = MLP.MLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_nonstat, accuracy_bp_nonstat, test_loss_bp_nonstat, snr_bp_nonstat, cosine_similarity_bp_nonstat) = \\\n",
    "    net_bp_nonstat.train_nonstat_data(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "device: cpu\n",
      "input:\n",
      "  path: datasets\n",
      "  batch_size: 128\n",
      "model:\n",
      "  peer_normalization: 0.03\n",
      "  momentum: 0.9\n",
      "  hidden_dim: 500\n",
      "  num_layers: 2\n",
      "training:\n",
      "  epochs: 100\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0\n",
      "  momentum: 0\n",
      "  downstream_learning_rate: 0.001\n",
      "  downstream_weight_decay: 0\n",
      "  val_idx: 0\n",
      "  final_test: true\n",
      "\n",
      "FF_model(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  )\n",
      "  (ff_loss): BCEWithLogitsLoss()\n",
      "  (linear_classifier): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=10, bias=False)\n",
      "  )\n",
      "  (classification_loss): CrossEntropyLoss()\n",
      ") \n",
      "\n",
      "...completed  0  epochs of training. \n",
      "\n",
      "            Current innate loss:  58.88356817196577, \n",
      "\n",
      "            Current training cross_entropy loss:  1.774866653100038, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.2531416416168213, \n",
      "   \n",
      "            Current testing accuracy:  0.7843 \n",
      "         \n",
      "            \n",
      "...completed  1  epochs of training. \n",
      "\n",
      "            Current innate loss:  45.21569881683741, \n",
      "\n",
      "            Current training cross_entropy loss:  1.366656632683216, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.7395602464675903, \n",
      "   \n",
      "            Current testing accuracy:  0.8491 \n",
      "         \n",
      "            \n",
      "...completed  2  epochs of training. \n",
      "\n",
      "            Current innate loss:  36.52814167422107, \n",
      "\n",
      "            Current training cross_entropy loss:  1.1269396652013828, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.5524837970733643, \n",
      "   \n",
      "            Current testing accuracy:  0.8781 \n",
      "         \n",
      "            \n",
      "...completed  3  epochs of training. \n",
      "\n",
      "            Current innate loss:  30.534103430540135, \n",
      "\n",
      "            Current training cross_entropy loss:  0.9781208742314424, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.4700471758842468, \n",
      "   \n",
      "            Current testing accuracy:  0.8913 \n",
      "         \n",
      "            \n",
      "...completed  4  epochs of training. \n",
      "\n",
      "            Current innate loss:  26.257527987040007, \n",
      "\n",
      "            Current training cross_entropy loss:  0.8766050295035044, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.42961207032203674, \n",
      "   \n",
      "            Current testing accuracy:  0.8995 \n",
      "         \n",
      "            \n",
      "...completed  5  epochs of training. \n",
      "\n",
      "            Current innate loss:  23.06932901898001, \n",
      "\n",
      "            Current training cross_entropy loss:  0.8023105828043742, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.4017144441604614, \n",
      "   \n",
      "            Current testing accuracy:  0.9048 \n",
      "         \n",
      "            \n",
      "...completed  6  epochs of training. \n",
      "\n",
      "            Current innate loss:  20.832097696079003, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7447694387191381, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.37011194229125977, \n",
      "   \n",
      "            Current testing accuracy:  0.9088 \n",
      "         \n",
      "            \n",
      "...completed  7  epochs of training. \n",
      "\n",
      "            Current innate loss:  19.02399027462189, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6986822772054718, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3494960069656372, \n",
      "   \n",
      "            Current testing accuracy:  0.9111 \n",
      "         \n",
      "            \n",
      "...completed  8  epochs of training. \n",
      "\n",
      "            Current innate loss:  17.409993954635414, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6612810045056193, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.332368403673172, \n",
      "   \n",
      "            Current testing accuracy:  0.9127 \n",
      "         \n",
      "            \n",
      "...completed  9  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.119177632454115, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6298325081895559, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.32570987939834595, \n",
      "   \n",
      "            Current testing accuracy:  0.9179 \n",
      "         \n",
      "            \n",
      "...completed  10  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.038566826468026, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6029254250072099, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3206612467765808, \n",
      "   \n",
      "            Current testing accuracy:  0.918 \n",
      "         \n",
      "            \n",
      "...completed  11  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.13245244456662, \n",
      "\n",
      "            Current training cross_entropy loss:  0.5794245414945305, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3065776228904724, \n",
      "   \n",
      "            Current testing accuracy:  0.9226 \n",
      "         \n",
      "            \n",
      "...completed  12  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.299930709647475, \n",
      "\n",
      "            Current training cross_entropy loss:  0.5589670241172967, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3005058169364929, \n",
      "   \n",
      "            Current testing accuracy:  0.9227 \n",
      "         \n",
      "            \n",
      "...completed  13  epochs of training. \n",
      "\n",
      "            Current innate loss:  12.558144259158071, \n",
      "\n",
      "            Current training cross_entropy loss:  0.5410271632174651, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.2964203953742981, \n",
      "   \n",
      "            Current testing accuracy:  0.9242 \n",
      "         \n",
      "            \n",
      "...completed  14  epochs of training. \n",
      "\n",
      "            Current innate loss:  11.954064203765657, \n",
      "\n",
      "            Current training cross_entropy loss:  0.5247421028369512, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.2888953685760498, \n",
      "   \n",
      "            Current testing accuracy:  0.9248 \n",
      "         \n",
      "            \n",
      "...completed  15  epochs of training. \n",
      "\n",
      "            Current innate loss:  11.385902768344833, \n",
      "\n",
      "            Current training cross_entropy loss:  0.510090854147879, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.2796480655670166, \n",
      "   \n",
      "            Current testing accuracy:  0.9262 \n",
      "         \n",
      "            \n",
      "...completed  16  epochs of training. \n",
      "\n",
      "            Current innate loss:  10.91861654476882, \n",
      "\n",
      "            Current training cross_entropy loss:  0.49672414339056203, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.26732298731803894, \n",
      "   \n",
      "            Current testing accuracy:  0.9283 \n",
      "         \n",
      "            \n",
      "...completed  17  epochs of training. \n",
      "\n",
      "            Current innate loss:  10.448480428063291, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4847280744537499, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.26206985116004944, \n",
      "   \n",
      "            Current testing accuracy:  0.9282 \n",
      "         \n",
      "            \n",
      "...completed  18  epochs of training. \n",
      "\n",
      "            Current innate loss:  10.03368983250237, \n",
      "\n",
      "            Current training cross_entropy loss:  0.47351521286967635, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.26404085755348206, \n",
      "   \n",
      "            Current testing accuracy:  0.931 \n",
      "         \n",
      "            \n",
      "...completed  19  epochs of training. \n",
      "\n",
      "            Current innate loss:  9.678782910261399, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4633006597119264, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.25221961736679077, \n",
      "   \n",
      "            Current testing accuracy:  0.9303 \n",
      "         \n",
      "            \n",
      "...completed  20  epochs of training. \n",
      "\n",
      "            Current innate loss:  9.33386038120413, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4537227320165279, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.24803921580314636, \n",
      "   \n",
      "            Current testing accuracy:  0.9318 \n",
      "         \n",
      "            \n",
      "...completed  21  epochs of training. \n",
      "\n",
      "            Current innate loss:  9.00675213322356, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4447589092859716, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.2492453157901764, \n",
      "   \n",
      "            Current testing accuracy:  0.9326 \n",
      "         \n",
      "            \n",
      "...completed  22  epochs of training. \n",
      "\n",
      "            Current innate loss:  8.713726526917423, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4364229184545269, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.24299746751785278, \n",
      "   \n",
      "            Current testing accuracy:  0.9352 \n",
      "         \n",
      "            \n",
      "...completed  23  epochs of training. \n",
      "\n",
      "            Current innate loss:  8.44172476559368, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4285777093882426, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.24600234627723694, \n",
      "   \n",
      "            Current testing accuracy:  0.9335 \n",
      "         \n",
      "            \n",
      "...completed  24  epochs of training. \n",
      "\n",
      "            Current innate loss:  8.201803872750355, \n",
      "\n",
      "            Current training cross_entropy loss:  0.42123146903056363, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.2353791743516922, \n",
      "   \n",
      "            Current testing accuracy:  0.9351 \n",
      "         \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "netffa = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_normal_ce, test_loss_ffa_normal_ce, \n",
    " losses_ffa_normal_mse, test_loss_ffa_normal_mse,\n",
    " accuracy_ffa_normal) = netffa.train_over(\n",
    "    train_images, train_labels, \n",
    "    test_images, test_labels,\n",
    "    epochs=numepochs, model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9750 25 9750 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(losses_ffa_normal_ce), \n",
    "      len(test_loss_ffa_normal_ce),\n",
    "      len(losses_ffa_normal_mse),\n",
    "      len(test_loss_ffa_normal_mse),\n",
    "      len(accuracy_ffa_normal)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_normal_ce.npy', np.asarray(losses_ffa_normal_ce))\n",
    "np.save('results/netffa/test_loss_ffa_normal_ce.npy', np.asarray(test_loss_ffa_normal_ce))\n",
    "np.save('results/netffa/losses_ffa_normal_mse.npy', np.asarray(losses_ffa_normal_mse))\n",
    "np.save('results/netffa/test_loss_ffa_normal_mse.npy', np.asarray(test_loss_ffa_normal_mse))\n",
    "np.save('results/netffa/accuracy_ffa_normal.npy', np.asarray(accuracy_ffa_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "device: cpu\n",
      "input:\n",
      "  path: datasets\n",
      "  batch_size: 128\n",
      "model:\n",
      "  peer_normalization: 0.03\n",
      "  momentum: 0.9\n",
      "  hidden_dim: 500\n",
      "  num_layers: 2\n",
      "training:\n",
      "  epochs: 100\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0\n",
      "  momentum: 0\n",
      "  downstream_learning_rate: 0.001\n",
      "  downstream_weight_decay: 0\n",
      "  val_idx: 0\n",
      "  final_test: true\n",
      "\n",
      "FF_model(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  )\n",
      "  (ff_loss): BCEWithLogitsLoss()\n",
      "  (linear_classifier): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=10, bias=False)\n",
      "  )\n",
      "  (classification_loss): CrossEntropyLoss()\n",
      ") \n",
      "\n",
      "...completed  1  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.06137740612030029, \n",
      "\n",
      "                Current testing accuracy:  0.113 \n",
      "\n",
      "                Current testing loss:  4.456904888153076 \n",
      " \n",
      "...completed  129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.49282130858046, \n",
      "\n",
      "                Current testing accuracy:  0.104 \n",
      "\n",
      "                Current testing loss:  4.498246192932129 \n",
      " \n",
      "...completed  257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.69406203678227, \n",
      "\n",
      "                Current testing accuracy:  0.104 \n",
      "\n",
      "                Current testing loss:  4.751631736755371 \n",
      " \n",
      "...completed  385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.505632612796035, \n",
      "\n",
      "                Current testing accuracy:  0.104 \n",
      "\n",
      "                Current testing loss:  4.307456970214844 \n",
      " \n",
      "...completed  513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.506413144204998, \n",
      "\n",
      "                Current testing accuracy:  0.113 \n",
      "\n",
      "                Current testing loss:  4.839576721191406 \n",
      " \n",
      "...completed  641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.32862094862503, \n",
      "\n",
      "                Current testing accuracy:  0.104 \n",
      "\n",
      "                Current testing loss:  4.55812406539917 \n",
      " \n",
      "...completed  769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.243188118067337, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  4.130993366241455 \n",
      " \n",
      "...completed  897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.4887741177517455, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  3.9181880950927734 \n",
      " \n",
      "...completed  1025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.663624407432508, \n",
      "\n",
      "                Current testing accuracy:  0.109 \n",
      "\n",
      "                Current testing loss:  4.285031795501709 \n",
      " \n",
      "...completed  1153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.216533324637567, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  4.558902263641357 \n",
      " \n",
      "...completed  1281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.493098247330636, \n",
      "\n",
      "                Current testing accuracy:  0.097 \n",
      "\n",
      "                Current testing loss:  4.37053918838501 \n",
      " \n",
      "...completed  1409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.53915730243898, \n",
      "\n",
      "                Current testing accuracy:  0.113 \n",
      "\n",
      "                Current testing loss:  4.596261024475098 \n",
      " \n",
      "...completed  1537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.327555978496093, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  4.0014214515686035 \n",
      " \n",
      "...completed  1665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.326874578517163, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.591428756713867 \n",
      " \n",
      "...completed  1793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.42219578003278, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  4.549188137054443 \n",
      " \n",
      "...completed  1921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.240667915990343, \n",
      "\n",
      "                Current testing accuracy:  0.097 \n",
      "\n",
      "                Current testing loss:  4.68412446975708 \n",
      " \n",
      "...completed  2049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.3584181062324205, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.446433067321777 \n",
      " \n",
      "...completed  2177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.245986080757575, \n",
      "\n",
      "                Current testing accuracy:  0.091 \n",
      "\n",
      "                Current testing loss:  3.581174850463867 \n",
      " \n",
      "...completed  2305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.45475030617672, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.6154561042785645 \n",
      " \n",
      "...completed  2433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.204289705507108, \n",
      "\n",
      "                Current testing accuracy:  0.096 \n",
      "\n",
      "                Current testing loss:  4.433156967163086 \n",
      " \n",
      "...completed  2561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.172287840468925, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.469615936279297 \n",
      " \n",
      "...completed  2689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.073316727794008, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.240513324737549 \n",
      " \n",
      "...completed  2817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.050901824288303, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  3.7376372814178467 \n",
      " \n",
      "...completed  2945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.396425068931421, \n",
      "\n",
      "                Current testing accuracy:  0.096 \n",
      "\n",
      "                Current testing loss:  4.7031569480896 \n",
      " \n",
      "...completed  3073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.14442595816945, \n",
      "\n",
      "                Current testing accuracy:  0.097 \n",
      "\n",
      "                Current testing loss:  4.3357672691345215 \n",
      " \n",
      "...completed  3201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.351558740410837, \n",
      "\n",
      "                Current testing accuracy:  0.096 \n",
      "\n",
      "                Current testing loss:  4.267838954925537 \n",
      " \n",
      "...completed  3329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.295560218641185, \n",
      "\n",
      "                Current testing accuracy:  0.109 \n",
      "\n",
      "                Current testing loss:  4.214486122131348 \n",
      " \n",
      "...completed  3457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.236712020545383, \n",
      "\n",
      "                Current testing accuracy:  0.117 \n",
      "\n",
      "                Current testing loss:  4.14381217956543 \n",
      " \n",
      "...completed  3585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.083941512595629, \n",
      "\n",
      "                Current testing accuracy:  0.091 \n",
      "\n",
      "                Current testing loss:  4.526726245880127 \n",
      " \n",
      "...completed  3713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.340107149429969, \n",
      "\n",
      "                Current testing accuracy:  0.109 \n",
      "\n",
      "                Current testing loss:  3.8902041912078857 \n",
      " \n",
      "...completed  3841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.211127921487787, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  3.882974624633789 \n",
      " \n",
      "...completed  3969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.995198448839801, \n",
      "\n",
      "                Current testing accuracy:  0.098 \n",
      "\n",
      "                Current testing loss:  3.6997339725494385 \n",
      " \n",
      "...completed  4097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.193885448206856, \n",
      "\n",
      "                Current testing accuracy:  0.105 \n",
      "\n",
      "                Current testing loss:  4.131247043609619 \n",
      " \n",
      "...completed  4225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.966741313561215, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  3.684644937515259 \n",
      " \n",
      "...completed  4353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.034046016895445, \n",
      "\n",
      "                Current testing accuracy:  0.098 \n",
      "\n",
      "                Current testing loss:  4.193429946899414 \n",
      " \n",
      "...completed  4481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.8351545189216267, \n",
      "\n",
      "                Current testing accuracy:  0.096 \n",
      "\n",
      "                Current testing loss:  4.29706335067749 \n",
      " \n",
      "...completed  4609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.040573429600045, \n",
      "\n",
      "                Current testing accuracy:  0.096 \n",
      "\n",
      "                Current testing loss:  4.217624664306641 \n",
      " \n",
      "...completed  4737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.9637173291121144, \n",
      "\n",
      "                Current testing accuracy:  0.097 \n",
      "\n",
      "                Current testing loss:  4.150228977203369 \n",
      " \n",
      "...completed  4865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.798225860855382, \n",
      "\n",
      "                Current testing accuracy:  0.121 \n",
      "\n",
      "                Current testing loss:  3.670684576034546 \n",
      " \n",
      "...completed  4993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.035244602153398, \n",
      "\n",
      "                Current testing accuracy:  0.101 \n",
      "\n",
      "                Current testing loss:  4.331151485443115 \n",
      " \n",
      "...completed  5121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.9617248597569414, \n",
      "\n",
      "                Current testing accuracy:  0.094 \n",
      "\n",
      "                Current testing loss:  4.051617622375488 \n",
      " \n",
      "...completed  5249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  4.029525573205319, \n",
      "\n",
      "                Current testing accuracy:  0.1 \n",
      "\n",
      "                Current testing loss:  3.9731738567352295 \n",
      " \n",
      "...completed  5377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.685203509463463, \n",
      "\n",
      "                Current testing accuracy:  0.107 \n",
      "\n",
      "                Current testing loss:  4.157733917236328 \n",
      " \n",
      "...completed  5505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.8273072837037034, \n",
      "\n",
      "                Current testing accuracy:  0.163 \n",
      "\n",
      "                Current testing loss:  3.2013115882873535 \n",
      " \n",
      "...completed  5633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.890681406373915, \n",
      "\n",
      "                Current testing accuracy:  0.108 \n",
      "\n",
      "                Current testing loss:  3.6933822631835938 \n",
      " \n",
      "...completed  5761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.8807627320747997, \n",
      "\n",
      "                Current testing accuracy:  0.119 \n",
      "\n",
      "                Current testing loss:  3.4787282943725586 \n",
      " \n",
      "...completed  5889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.8334102994649584, \n",
      "\n",
      "                Current testing accuracy:  0.114 \n",
      "\n",
      "                Current testing loss:  4.125405788421631 \n",
      " \n",
      "...completed  6017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.4503256402822444, \n",
      "\n",
      "                Current testing accuracy:  0.163 \n",
      "\n",
      "                Current testing loss:  3.2942986488342285 \n",
      " \n",
      "...completed  6145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.531457657882129, \n",
      "\n",
      "                Current testing accuracy:  0.125 \n",
      "\n",
      "                Current testing loss:  3.400735855102539 \n",
      " \n",
      "...completed  6273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.5632309680295293, \n",
      "\n",
      "                Current testing accuracy:  0.124 \n",
      "\n",
      "                Current testing loss:  3.6093013286590576 \n",
      " \n",
      "...completed  6401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.724362664288492, \n",
      "\n",
      "                Current testing accuracy:  0.109 \n",
      "\n",
      "                Current testing loss:  4.003568649291992 \n",
      " \n",
      "...completed  6529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.4110101013211533, \n",
      "\n",
      "                Current testing accuracy:  0.11 \n",
      "\n",
      "                Current testing loss:  4.124059200286865 \n",
      " \n",
      "...completed  6657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.4849060810192896, \n",
      "\n",
      "                Current testing accuracy:  0.148 \n",
      "\n",
      "                Current testing loss:  3.4617691040039062 \n",
      " \n",
      "...completed  6785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.5153123474074164, \n",
      "\n",
      "                Current testing accuracy:  0.182 \n",
      "\n",
      "                Current testing loss:  3.08951997756958 \n",
      " \n",
      "...completed  6913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.392367820677464, \n",
      "\n",
      "                Current testing accuracy:  0.119 \n",
      "\n",
      "                Current testing loss:  3.7153379917144775 \n",
      " \n",
      "...completed  7041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.6528975231049117, \n",
      "\n",
      "                Current testing accuracy:  0.139 \n",
      "\n",
      "                Current testing loss:  2.8642237186431885 \n",
      " \n",
      "...completed  7169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.209142426557264, \n",
      "\n",
      "                Current testing accuracy:  0.139 \n",
      "\n",
      "                Current testing loss:  3.5526316165924072 \n",
      " \n",
      "...completed  7297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.2534322735918977, \n",
      "\n",
      "                Current testing accuracy:  0.142 \n",
      "\n",
      "                Current testing loss:  3.2236196994781494 \n",
      " \n",
      "...completed  7425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.2786992254841607, \n",
      "\n",
      "                Current testing accuracy:  0.122 \n",
      "\n",
      "                Current testing loss:  3.655290365219116 \n",
      " \n",
      "...completed  7553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.534109565684048, \n",
      "\n",
      "                Current testing accuracy:  0.155 \n",
      "\n",
      "                Current testing loss:  3.5945208072662354 \n",
      " \n",
      "...completed  7681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.5087105356324173, \n",
      "\n",
      "                Current testing accuracy:  0.125 \n",
      "\n",
      "                Current testing loss:  3.8072915077209473 \n",
      " \n",
      "...completed  7809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.4174553511875274, \n",
      "\n",
      "                Current testing accuracy:  0.176 \n",
      "\n",
      "                Current testing loss:  2.8016011714935303 \n",
      " \n",
      "...completed  7937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.1793333406517377, \n",
      "\n",
      "                Current testing accuracy:  0.161 \n",
      "\n",
      "                Current testing loss:  3.499176502227783 \n",
      " \n",
      "...completed  8065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.1847269569334458, \n",
      "\n",
      "                Current testing accuracy:  0.112 \n",
      "\n",
      "                Current testing loss:  3.9930355548858643 \n",
      " \n",
      "...completed  8193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.289746338568875, \n",
      "\n",
      "                Current testing accuracy:  0.201 \n",
      "\n",
      "                Current testing loss:  2.3073105812072754 \n",
      " \n",
      "...completed  8321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.124361564521678, \n",
      "\n",
      "                Current testing accuracy:  0.123 \n",
      "\n",
      "                Current testing loss:  2.776186943054199 \n",
      " \n",
      "...completed  8449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.4263974571970266, \n",
      "\n",
      "                Current testing accuracy:  0.103 \n",
      "\n",
      "                Current testing loss:  3.5910942554473877 \n",
      " \n",
      "...completed  8577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.7980156422763685, \n",
      "\n",
      "                Current testing accuracy:  0.214 \n",
      "\n",
      "                Current testing loss:  2.600963830947876 \n",
      " \n",
      "...completed  8705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.9151840334234294, \n",
      "\n",
      "                Current testing accuracy:  0.261 \n",
      "\n",
      "                Current testing loss:  2.262669086456299 \n",
      " \n",
      "...completed  8833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.8339390851615462, \n",
      "\n",
      "                Current testing accuracy:  0.231 \n",
      "\n",
      "                Current testing loss:  2.9898324012756348 \n",
      " \n",
      "...completed  8961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.9747491674625053, \n",
      "\n",
      "                Current testing accuracy:  0.286 \n",
      "\n",
      "                Current testing loss:  2.3149607181549072 \n",
      " \n",
      "...completed  9089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.869052780628408, \n",
      "\n",
      "                Current testing accuracy:  0.186 \n",
      "\n",
      "                Current testing loss:  3.1166539192199707 \n",
      " \n",
      "...completed  9217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  3.0919535579014337, \n",
      "\n",
      "                Current testing accuracy:  0.337 \n",
      "\n",
      "                Current testing loss:  2.0118117332458496 \n",
      " \n",
      "...completed  9345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.8513880536467013, \n",
      "\n",
      "                Current testing accuracy:  0.178 \n",
      "\n",
      "                Current testing loss:  2.7287025451660156 \n",
      " \n",
      "...completed  9473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.626061036529677, \n",
      "\n",
      "                Current testing accuracy:  0.199 \n",
      "\n",
      "                Current testing loss:  2.481731414794922 \n",
      " \n",
      "...completed  9601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.543901687537584, \n",
      "\n",
      "                Current testing accuracy:  0.22 \n",
      "\n",
      "                Current testing loss:  2.581613302230835 \n",
      " \n",
      "...completed  9729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.8383597891088357, \n",
      "\n",
      "                Current testing accuracy:  0.25 \n",
      "\n",
      "                Current testing loss:  2.425382614135742 \n",
      " \n",
      "...completed  9857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5011067482738554, \n",
      "\n",
      "                Current testing accuracy:  0.242 \n",
      "\n",
      "                Current testing loss:  2.2208681106567383 \n",
      " \n",
      "...completed  9985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.449645071582836, \n",
      "\n",
      "                Current testing accuracy:  0.19 \n",
      "\n",
      "                Current testing loss:  2.6520493030548096 \n",
      " \n",
      "...completed  10113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.477142282294153, \n",
      "\n",
      "                Current testing accuracy:  0.167 \n",
      "\n",
      "                Current testing loss:  3.0205891132354736 \n",
      " \n",
      "...completed  10241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.4168888826822297, \n",
      "\n",
      "                Current testing accuracy:  0.155 \n",
      "\n",
      "                Current testing loss:  2.932710647583008 \n",
      " \n",
      "...completed  10369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.6839755468363364, \n",
      "\n",
      "                Current testing accuracy:  0.184 \n",
      "\n",
      "                Current testing loss:  2.862492322921753 \n",
      " \n",
      "...completed  10497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5197926702362565, \n",
      "\n",
      "                Current testing accuracy:  0.433 \n",
      "\n",
      "                Current testing loss:  1.6369540691375732 \n",
      " \n",
      "...completed  10625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5040733973655733, \n",
      "\n",
      "                Current testing accuracy:  0.217 \n",
      "\n",
      "                Current testing loss:  2.7960336208343506 \n",
      " \n",
      "...completed  10753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5050352920848127, \n",
      "\n",
      "                Current testing accuracy:  0.17 \n",
      "\n",
      "                Current testing loss:  3.3854691982269287 \n",
      " \n",
      "...completed  10881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.4607039768035026, \n",
      "\n",
      "                Current testing accuracy:  0.355 \n",
      "\n",
      "                Current testing loss:  1.8990317583084106 \n",
      " \n",
      "...completed  11009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.49991644891702, \n",
      "\n",
      "                Current testing accuracy:  0.287 \n",
      "\n",
      "                Current testing loss:  1.8648282289505005 \n",
      " \n",
      "...completed  11137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.621376073464944, \n",
      "\n",
      "                Current testing accuracy:  0.258 \n",
      "\n",
      "                Current testing loss:  2.4497313499450684 \n",
      " \n",
      "...completed  11265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2898607784004525, \n",
      "\n",
      "                Current testing accuracy:  0.283 \n",
      "\n",
      "                Current testing loss:  2.3348453044891357 \n",
      " \n",
      "...completed  11393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.373753838076766, \n",
      "\n",
      "                Current testing accuracy:  0.285 \n",
      "\n",
      "                Current testing loss:  2.0867013931274414 \n",
      " \n",
      "...completed  11521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.3448594945826926, \n",
      "\n",
      "                Current testing accuracy:  0.263 \n",
      "\n",
      "                Current testing loss:  2.3382155895233154 \n",
      " \n",
      "...completed  11649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.552588800715636, \n",
      "\n",
      "                Current testing accuracy:  0.268 \n",
      "\n",
      "                Current testing loss:  2.1917192935943604 \n",
      " \n",
      "...completed  11777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.254681081092798, \n",
      "\n",
      "                Current testing accuracy:  0.424 \n",
      "\n",
      "                Current testing loss:  1.5719492435455322 \n",
      " \n",
      "...completed  11905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5893705633002355, \n",
      "\n",
      "                Current testing accuracy:  0.353 \n",
      "\n",
      "                Current testing loss:  2.0103213787078857 \n",
      " \n",
      "...completed  12033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.4254636219402155, \n",
      "\n",
      "                Current testing accuracy:  0.474 \n",
      "\n",
      "                Current testing loss:  1.4987963438034058 \n",
      " \n",
      "...completed  12161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.0731283261694387, \n",
      "\n",
      "                Current testing accuracy:  0.192 \n",
      "\n",
      "                Current testing loss:  2.7395503520965576 \n",
      " \n",
      "...completed  12289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.098037499927784, \n",
      "\n",
      "                Current testing accuracy:  0.173 \n",
      "\n",
      "                Current testing loss:  3.422086477279663 \n",
      " \n",
      "...completed  12417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2366552269259046, \n",
      "\n",
      "                Current testing accuracy:  0.238 \n",
      "\n",
      "                Current testing loss:  2.1313700675964355 \n",
      " \n",
      "...completed  12545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.5077344491019176, \n",
      "\n",
      "                Current testing accuracy:  0.259 \n",
      "\n",
      "                Current testing loss:  3.1624813079833984 \n",
      " \n",
      "...completed  12673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.168273062696244, \n",
      "\n",
      "                Current testing accuracy:  0.244 \n",
      "\n",
      "                Current testing loss:  2.407569646835327 \n",
      " \n",
      "...completed  12801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.0333189445351945, \n",
      "\n",
      "                Current testing accuracy:  0.461 \n",
      "\n",
      "                Current testing loss:  1.7060275077819824 \n",
      " \n",
      "...completed  12929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2201775347962744, \n",
      "\n",
      "                Current testing accuracy:  0.22 \n",
      "\n",
      "                Current testing loss:  2.670497179031372 \n",
      " \n",
      "...completed  13057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9160426709165606, \n",
      "\n",
      "                Current testing accuracy:  0.33 \n",
      "\n",
      "                Current testing loss:  2.3584980964660645 \n",
      " \n",
      "...completed  13185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2747822700154074, \n",
      "\n",
      "                Current testing accuracy:  0.214 \n",
      "\n",
      "                Current testing loss:  2.500241756439209 \n",
      " \n",
      "...completed  13313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9052949727017676, \n",
      "\n",
      "                Current testing accuracy:  0.308 \n",
      "\n",
      "                Current testing loss:  2.0679843425750732 \n",
      " \n",
      "...completed  13441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.1122852264402328, \n",
      "\n",
      "                Current testing accuracy:  0.454 \n",
      "\n",
      "                Current testing loss:  1.629886269569397 \n",
      " \n",
      "...completed  13569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.1178631984629415, \n",
      "\n",
      "                Current testing accuracy:  0.53 \n",
      "\n",
      "                Current testing loss:  1.547133445739746 \n",
      " \n",
      "...completed  13697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.725977875648141, \n",
      "\n",
      "                Current testing accuracy:  0.341 \n",
      "\n",
      "                Current testing loss:  2.521256685256958 \n",
      " \n",
      "...completed  13825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8955289247860492, \n",
      "\n",
      "                Current testing accuracy:  0.321 \n",
      "\n",
      "                Current testing loss:  2.1185824871063232 \n",
      " \n",
      "...completed  13953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.02138179987827, \n",
      "\n",
      "                Current testing accuracy:  0.416 \n",
      "\n",
      "                Current testing loss:  1.706096887588501 \n",
      " \n",
      "...completed  14081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7175249808374815, \n",
      "\n",
      "                Current testing accuracy:  0.477 \n",
      "\n",
      "                Current testing loss:  1.7469820976257324 \n",
      " \n",
      "...completed  14209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8944009671937607, \n",
      "\n",
      "                Current testing accuracy:  0.418 \n",
      "\n",
      "                Current testing loss:  1.951827883720398 \n",
      " \n",
      "...completed  14337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.776108946102795, \n",
      "\n",
      "                Current testing accuracy:  0.321 \n",
      "\n",
      "                Current testing loss:  2.0811078548431396 \n",
      " \n",
      "...completed  14465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8688832400060917, \n",
      "\n",
      "                Current testing accuracy:  0.632 \n",
      "\n",
      "                Current testing loss:  1.247835397720337 \n",
      " \n",
      "...completed  14593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6323784084792123, \n",
      "\n",
      "                Current testing accuracy:  0.48 \n",
      "\n",
      "                Current testing loss:  1.5353718996047974 \n",
      " \n",
      "...completed  14721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8849061998664745, \n",
      "\n",
      "                Current testing accuracy:  0.52 \n",
      "\n",
      "                Current testing loss:  1.6631296873092651 \n",
      " \n",
      "...completed  14849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7370781580849792, \n",
      "\n",
      "                Current testing accuracy:  0.537 \n",
      "\n",
      "                Current testing loss:  1.5156474113464355 \n",
      " \n",
      "...completed  14977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4346925127490238, \n",
      "\n",
      "                Current testing accuracy:  0.376 \n",
      "\n",
      "                Current testing loss:  1.9323413372039795 \n",
      " \n",
      "...completed  15105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6792169125055239, \n",
      "\n",
      "                Current testing accuracy:  0.179 \n",
      "\n",
      "                Current testing loss:  4.015705585479736 \n",
      " \n",
      "...completed  15233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6054244980582553, \n",
      "\n",
      "                Current testing accuracy:  0.369 \n",
      "\n",
      "                Current testing loss:  1.853664755821228 \n",
      " \n",
      "...completed  15361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6227176858903718, \n",
      "\n",
      "                Current testing accuracy:  0.643 \n",
      "\n",
      "                Current testing loss:  1.1451886892318726 \n",
      " \n",
      "...completed  15489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7341555741417505, \n",
      "\n",
      "                Current testing accuracy:  0.543 \n",
      "\n",
      "                Current testing loss:  1.4655156135559082 \n",
      " \n",
      "...completed  15617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8222644252635725, \n",
      "\n",
      "                Current testing accuracy:  0.636 \n",
      "\n",
      "                Current testing loss:  1.088464379310608 \n",
      " \n",
      "...completed  15745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7845624676883358, \n",
      "\n",
      "                Current testing accuracy:  0.379 \n",
      "\n",
      "                Current testing loss:  1.9935458898544312 \n",
      " \n",
      "...completed  15873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.099187750644532, \n",
      "\n",
      "                Current testing accuracy:  0.398 \n",
      "\n",
      "                Current testing loss:  2.242048740386963 \n",
      " \n",
      "...completed  16001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5008017758193173, \n",
      "\n",
      "                Current testing accuracy:  0.52 \n",
      "\n",
      "                Current testing loss:  1.7616645097732544 \n",
      " \n",
      "...completed  16129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9231613679247062, \n",
      "\n",
      "                Current testing accuracy:  0.404 \n",
      "\n",
      "                Current testing loss:  1.9247359037399292 \n",
      " \n",
      "...completed  16257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3272552563850013, \n",
      "\n",
      "                Current testing accuracy:  0.55 \n",
      "\n",
      "                Current testing loss:  1.3877813816070557 \n",
      " \n",
      "...completed  16385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6565272884032538, \n",
      "\n",
      "                Current testing accuracy:  0.495 \n",
      "\n",
      "                Current testing loss:  2.0360395908355713 \n",
      " \n",
      "...completed  16513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8185563153141935, \n",
      "\n",
      "                Current testing accuracy:  0.422 \n",
      "\n",
      "                Current testing loss:  1.8932712078094482 \n",
      " \n",
      "...completed  16641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.021751466339081, \n",
      "\n",
      "                Current testing accuracy:  0.276 \n",
      "\n",
      "                Current testing loss:  3.083988666534424 \n",
      " \n",
      "...completed  16769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3185442962953358, \n",
      "\n",
      "                Current testing accuracy:  0.634 \n",
      "\n",
      "                Current testing loss:  1.1695630550384521 \n",
      " \n",
      "...completed  16897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9290058808667248, \n",
      "\n",
      "                Current testing accuracy:  0.508 \n",
      "\n",
      "                Current testing loss:  1.5113434791564941 \n",
      " \n",
      "...completed  17025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5998742588483879, \n",
      "\n",
      "                Current testing accuracy:  0.556 \n",
      "\n",
      "                Current testing loss:  1.2555691003799438 \n",
      " \n",
      "...completed  17153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3439228948052815, \n",
      "\n",
      "                Current testing accuracy:  0.436 \n",
      "\n",
      "                Current testing loss:  1.6889716386795044 \n",
      " \n",
      "...completed  17281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4841257884112902, \n",
      "\n",
      "                Current testing accuracy:  0.466 \n",
      "\n",
      "                Current testing loss:  1.5647847652435303 \n",
      " \n",
      "...completed  17409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.411855800024533, \n",
      "\n",
      "                Current testing accuracy:  0.522 \n",
      "\n",
      "                Current testing loss:  1.3825401067733765 \n",
      " \n",
      "...completed  17537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7079735347374498, \n",
      "\n",
      "                Current testing accuracy:  0.464 \n",
      "\n",
      "                Current testing loss:  1.594395637512207 \n",
      " \n",
      "...completed  17665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.229961822220576, \n",
      "\n",
      "                Current testing accuracy:  0.551 \n",
      "\n",
      "                Current testing loss:  1.3997821807861328 \n",
      " \n",
      "...completed  17793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2749541531495936, \n",
      "\n",
      "                Current testing accuracy:  0.428 \n",
      "\n",
      "                Current testing loss:  1.9579848051071167 \n",
      " \n",
      "...completed  17921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7562133463733431, \n",
      "\n",
      "                Current testing accuracy:  0.54 \n",
      "\n",
      "                Current testing loss:  1.6515183448791504 \n",
      " \n",
      "...completed  18049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4398482633295089, \n",
      "\n",
      "                Current testing accuracy:  0.609 \n",
      "\n",
      "                Current testing loss:  1.3856018781661987 \n",
      " \n",
      "...completed  18177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4530765958624148, \n",
      "\n",
      "                Current testing accuracy:  0.337 \n",
      "\n",
      "                Current testing loss:  2.399567127227783 \n",
      " \n",
      "...completed  18305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2671360765958752, \n",
      "\n",
      "                Current testing accuracy:  0.417 \n",
      "\n",
      "                Current testing loss:  2.0655720233917236 \n",
      " \n",
      "...completed  18433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.2107043992826902, \n",
      "\n",
      "                Current testing accuracy:  0.378 \n",
      "\n",
      "                Current testing loss:  2.455764055252075 \n",
      " \n",
      "...completed  18561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.020966270526685, \n",
      "\n",
      "                Current testing accuracy:  0.543 \n",
      "\n",
      "                Current testing loss:  1.767783522605896 \n",
      " \n",
      "...completed  18689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6706735659908603, \n",
      "\n",
      "                Current testing accuracy:  0.405 \n",
      "\n",
      "                Current testing loss:  2.2605843544006348 \n",
      " \n",
      "...completed  18817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.8475029175560849, \n",
      "\n",
      "                Current testing accuracy:  0.508 \n",
      "\n",
      "                Current testing loss:  1.6759159564971924 \n",
      " \n",
      "...completed  18945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.1761310760208517, \n",
      "\n",
      "                Current testing accuracy:  0.615 \n",
      "\n",
      "                Current testing loss:  1.5265045166015625 \n",
      " \n",
      "...completed  19073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.094297474445682, \n",
      "\n",
      "                Current testing accuracy:  0.462 \n",
      "\n",
      "                Current testing loss:  1.7625210285186768 \n",
      " \n",
      "...completed  19201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9297259258455597, \n",
      "\n",
      "                Current testing accuracy:  0.385 \n",
      "\n",
      "                Current testing loss:  1.9948415756225586 \n",
      " \n",
      "...completed  19329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9857824663054089, \n",
      "\n",
      "                Current testing accuracy:  0.495 \n",
      "\n",
      "                Current testing loss:  1.6893093585968018 \n",
      " \n",
      "...completed  19457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5342361760815493, \n",
      "\n",
      "                Current testing accuracy:  0.342 \n",
      "\n",
      "                Current testing loss:  2.467844009399414 \n",
      " \n",
      "...completed  19585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.718261558619247, \n",
      "\n",
      "                Current testing accuracy:  0.394 \n",
      "\n",
      "                Current testing loss:  2.1051323413848877 \n",
      " \n",
      "...completed  19713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3675851151200504, \n",
      "\n",
      "                Current testing accuracy:  0.538 \n",
      "\n",
      "                Current testing loss:  1.3591406345367432 \n",
      " \n",
      "...completed  19841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  2.025488024566698, \n",
      "\n",
      "                Current testing accuracy:  0.61 \n",
      "\n",
      "                Current testing loss:  1.1513683795928955 \n",
      " \n",
      "...completed  19969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.600580978593598, \n",
      "\n",
      "                Current testing accuracy:  0.529 \n",
      "\n",
      "                Current testing loss:  1.4754403829574585 \n",
      " \n",
      "...completed  20097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7821034713700499, \n",
      "\n",
      "                Current testing accuracy:  0.642 \n",
      "\n",
      "                Current testing loss:  1.0930951833724976 \n",
      " \n",
      "...completed  20225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6940070303879224, \n",
      "\n",
      "                Current testing accuracy:  0.556 \n",
      "\n",
      "                Current testing loss:  1.3097095489501953 \n",
      " \n",
      "...completed  20353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6148192607179226, \n",
      "\n",
      "                Current testing accuracy:  0.405 \n",
      "\n",
      "                Current testing loss:  1.8890886306762695 \n",
      " \n",
      "...completed  20481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.741021978881463, \n",
      "\n",
      "                Current testing accuracy:  0.706 \n",
      "\n",
      "                Current testing loss:  1.0412653684616089 \n",
      " \n",
      "...completed  20609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3158929582794485, \n",
      "\n",
      "                Current testing accuracy:  0.594 \n",
      "\n",
      "                Current testing loss:  1.1982802152633667 \n",
      " \n",
      "...completed  20737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.533211362488629, \n",
      "\n",
      "                Current testing accuracy:  0.491 \n",
      "\n",
      "                Current testing loss:  1.4593933820724487 \n",
      " \n",
      "...completed  20865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5057580883993893, \n",
      "\n",
      "                Current testing accuracy:  0.618 \n",
      "\n",
      "                Current testing loss:  1.1302536725997925 \n",
      " \n",
      "...completed  20993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4357917796796755, \n",
      "\n",
      "                Current testing accuracy:  0.478 \n",
      "\n",
      "                Current testing loss:  1.5616803169250488 \n",
      " \n",
      "...completed  21121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5332899069967425, \n",
      "\n",
      "                Current testing accuracy:  0.695 \n",
      "\n",
      "                Current testing loss:  0.9377365708351135 \n",
      " \n",
      "...completed  21249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6822437535233803, \n",
      "\n",
      "                Current testing accuracy:  0.661 \n",
      "\n",
      "                Current testing loss:  1.1640254259109497 \n",
      " \n",
      "...completed  21377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6043454753651076, \n",
      "\n",
      "                Current testing accuracy:  0.541 \n",
      "\n",
      "                Current testing loss:  1.3478342294692993 \n",
      " \n",
      "...completed  21505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4214261014194562, \n",
      "\n",
      "                Current testing accuracy:  0.346 \n",
      "\n",
      "                Current testing loss:  2.1215248107910156 \n",
      " \n",
      "...completed  21633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3338289978246394, \n",
      "\n",
      "                Current testing accuracy:  0.448 \n",
      "\n",
      "                Current testing loss:  1.842074990272522 \n",
      " \n",
      "...completed  21761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5514000104694787, \n",
      "\n",
      "                Current testing accuracy:  0.348 \n",
      "\n",
      "                Current testing loss:  2.3412857055664062 \n",
      " \n",
      "...completed  21889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6894177286280865, \n",
      "\n",
      "                Current testing accuracy:  0.565 \n",
      "\n",
      "                Current testing loss:  1.3426368236541748 \n",
      " \n",
      "...completed  22017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4334738808158818, \n",
      "\n",
      "                Current testing accuracy:  0.431 \n",
      "\n",
      "                Current testing loss:  1.8756217956542969 \n",
      " \n",
      "...completed  22145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.671958192921693, \n",
      "\n",
      "                Current testing accuracy:  0.553 \n",
      "\n",
      "                Current testing loss:  1.3988878726959229 \n",
      " \n",
      "...completed  22273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5859802155829925, \n",
      "\n",
      "                Current testing accuracy:  0.675 \n",
      "\n",
      "                Current testing loss:  0.99604332447052 \n",
      " \n",
      "...completed  22401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6531290316270315, \n",
      "\n",
      "                Current testing accuracy:  0.653 \n",
      "\n",
      "                Current testing loss:  1.0175350904464722 \n",
      " \n",
      "...completed  22529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6307164223827044, \n",
      "\n",
      "                Current testing accuracy:  0.522 \n",
      "\n",
      "                Current testing loss:  1.3763399124145508 \n",
      " \n",
      "...completed  22657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5280229716054805, \n",
      "\n",
      "                Current testing accuracy:  0.499 \n",
      "\n",
      "                Current testing loss:  1.705710768699646 \n",
      " \n",
      "...completed  22785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3691430825595106, \n",
      "\n",
      "                Current testing accuracy:  0.643 \n",
      "\n",
      "                Current testing loss:  1.0641518831253052 \n",
      " \n",
      "...completed  22913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.527798468322544, \n",
      "\n",
      "                Current testing accuracy:  0.502 \n",
      "\n",
      "                Current testing loss:  1.7276599407196045 \n",
      " \n",
      "...completed  23041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5741200707612961, \n",
      "\n",
      "                Current testing accuracy:  0.427 \n",
      "\n",
      "                Current testing loss:  2.1814558506011963 \n",
      " \n",
      "...completed  23169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2509104545645187, \n",
      "\n",
      "                Current testing accuracy:  0.727 \n",
      "\n",
      "                Current testing loss:  0.9097192883491516 \n",
      " \n",
      "...completed  23297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.646771010416387, \n",
      "\n",
      "                Current testing accuracy:  0.626 \n",
      "\n",
      "                Current testing loss:  1.083359956741333 \n",
      " \n",
      "...completed  23425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.9522165943345726, \n",
      "\n",
      "                Current testing accuracy:  0.665 \n",
      "\n",
      "                Current testing loss:  1.0365808010101318 \n",
      " \n",
      "...completed  23553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5806417298329052, \n",
      "\n",
      "                Current testing accuracy:  0.462 \n",
      "\n",
      "                Current testing loss:  1.7946475744247437 \n",
      " \n",
      "...completed  23681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0725683515065327, \n",
      "\n",
      "                Current testing accuracy:  0.447 \n",
      "\n",
      "                Current testing loss:  1.6603953838348389 \n",
      " \n",
      "...completed  23809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5315574843534705, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  0.9384265542030334 \n",
      " \n",
      "...completed  23937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4501061308118892, \n",
      "\n",
      "                Current testing accuracy:  0.342 \n",
      "\n",
      "                Current testing loss:  2.6578354835510254 \n",
      " \n",
      "...completed  24065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2359924070181023, \n",
      "\n",
      "                Current testing accuracy:  0.54 \n",
      "\n",
      "                Current testing loss:  1.3705037832260132 \n",
      " \n",
      "...completed  24193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3914063126594556, \n",
      "\n",
      "                Current testing accuracy:  0.692 \n",
      "\n",
      "                Current testing loss:  1.0496952533721924 \n",
      " \n",
      "...completed  24321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.325524030577128, \n",
      "\n",
      "                Current testing accuracy:  0.617 \n",
      "\n",
      "                Current testing loss:  1.2248374223709106 \n",
      " \n",
      "...completed  24449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9743693219327838, \n",
      "\n",
      "                Current testing accuracy:  0.58 \n",
      "\n",
      "                Current testing loss:  1.344921350479126 \n",
      " \n",
      "...completed  24577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3184767846179284, \n",
      "\n",
      "                Current testing accuracy:  0.671 \n",
      "\n",
      "                Current testing loss:  0.9564566612243652 \n",
      " \n",
      "...completed  24705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4936433281148993, \n",
      "\n",
      "                Current testing accuracy:  0.484 \n",
      "\n",
      "                Current testing loss:  1.8406093120574951 \n",
      " \n",
      "...completed  24833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4346427013570775, \n",
      "\n",
      "                Current testing accuracy:  0.344 \n",
      "\n",
      "                Current testing loss:  2.7179441452026367 \n",
      " \n",
      "...completed  24961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.645185598200726, \n",
      "\n",
      "                Current testing accuracy:  0.469 \n",
      "\n",
      "                Current testing loss:  1.7042655944824219 \n",
      " \n",
      "...completed  25089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5350368860561048, \n",
      "\n",
      "                Current testing accuracy:  0.508 \n",
      "\n",
      "                Current testing loss:  1.8514201641082764 \n",
      " \n",
      "...completed  25217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9792431551205709, \n",
      "\n",
      "                Current testing accuracy:  0.495 \n",
      "\n",
      "                Current testing loss:  1.6023643016815186 \n",
      " \n",
      "...completed  25345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2155334630786, \n",
      "\n",
      "                Current testing accuracy:  0.679 \n",
      "\n",
      "                Current testing loss:  1.0115792751312256 \n",
      " \n",
      "...completed  25473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3601668350984681, \n",
      "\n",
      "                Current testing accuracy:  0.678 \n",
      "\n",
      "                Current testing loss:  1.0468101501464844 \n",
      " \n",
      "...completed  25601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.154892669098274, \n",
      "\n",
      "                Current testing accuracy:  0.52 \n",
      "\n",
      "                Current testing loss:  1.42026948928833 \n",
      " \n",
      "...completed  25729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4315575971671706, \n",
      "\n",
      "                Current testing accuracy:  0.619 \n",
      "\n",
      "                Current testing loss:  1.1450086832046509 \n",
      " \n",
      "...completed  25857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1655923716272127, \n",
      "\n",
      "                Current testing accuracy:  0.568 \n",
      "\n",
      "                Current testing loss:  1.3176934719085693 \n",
      " \n",
      "...completed  25985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.815925003748589, \n",
      "\n",
      "                Current testing accuracy:  0.459 \n",
      "\n",
      "                Current testing loss:  1.8006255626678467 \n",
      " \n",
      "...completed  26113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3044798800510762, \n",
      "\n",
      "                Current testing accuracy:  0.539 \n",
      "\n",
      "                Current testing loss:  1.6490222215652466 \n",
      " \n",
      "...completed  26241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3646698459640376, \n",
      "\n",
      "                Current testing accuracy:  0.511 \n",
      "\n",
      "                Current testing loss:  1.5522717237472534 \n",
      " \n",
      "...completed  26369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3312807136799165, \n",
      "\n",
      "                Current testing accuracy:  0.362 \n",
      "\n",
      "                Current testing loss:  2.3682756423950195 \n",
      " \n",
      "...completed  26497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6535496167371093, \n",
      "\n",
      "                Current testing accuracy:  0.619 \n",
      "\n",
      "                Current testing loss:  1.0936143398284912 \n",
      " \n",
      "...completed  26625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2673332296084912, \n",
      "\n",
      "                Current testing accuracy:  0.734 \n",
      "\n",
      "                Current testing loss:  0.8343526721000671 \n",
      " \n",
      "...completed  26753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5773669077537988, \n",
      "\n",
      "                Current testing accuracy:  0.675 \n",
      "\n",
      "                Current testing loss:  0.936336100101471 \n",
      " \n",
      "...completed  26881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1501707093602818, \n",
      "\n",
      "                Current testing accuracy:  0.597 \n",
      "\n",
      "                Current testing loss:  1.1765780448913574 \n",
      " \n",
      "...completed  27009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2002918741551696, \n",
      "\n",
      "                Current testing accuracy:  0.552 \n",
      "\n",
      "                Current testing loss:  1.6890711784362793 \n",
      " \n",
      "...completed  27137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5217278250277104, \n",
      "\n",
      "                Current testing accuracy:  0.544 \n",
      "\n",
      "                Current testing loss:  1.5296205282211304 \n",
      " \n",
      "...completed  27265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2817186664271674, \n",
      "\n",
      "                Current testing accuracy:  0.593 \n",
      "\n",
      "                Current testing loss:  1.3106578588485718 \n",
      " \n",
      "...completed  27393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9982656245885551, \n",
      "\n",
      "                Current testing accuracy:  0.749 \n",
      "\n",
      "                Current testing loss:  0.7616904377937317 \n",
      " \n",
      "...completed  27521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0512687658703044, \n",
      "\n",
      "                Current testing accuracy:  0.563 \n",
      "\n",
      "                Current testing loss:  1.464848279953003 \n",
      " \n",
      "...completed  27649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2026341049630105, \n",
      "\n",
      "                Current testing accuracy:  0.506 \n",
      "\n",
      "                Current testing loss:  1.8252592086791992 \n",
      " \n",
      "...completed  27777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3679020562165078, \n",
      "\n",
      "                Current testing accuracy:  0.68 \n",
      "\n",
      "                Current testing loss:  1.0126065015792847 \n",
      " \n",
      "...completed  27905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.486236558978125, \n",
      "\n",
      "                Current testing accuracy:  0.742 \n",
      "\n",
      "                Current testing loss:  0.7731810808181763 \n",
      " \n",
      "...completed  28033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4100197198877567, \n",
      "\n",
      "                Current testing accuracy:  0.593 \n",
      "\n",
      "                Current testing loss:  1.1858763694763184 \n",
      " \n",
      "...completed  28161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2431323351330832, \n",
      "\n",
      "                Current testing accuracy:  0.563 \n",
      "\n",
      "                Current testing loss:  1.1884843111038208 \n",
      " \n",
      "...completed  28289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2293968869907985, \n",
      "\n",
      "                Current testing accuracy:  0.587 \n",
      "\n",
      "                Current testing loss:  1.3918687105178833 \n",
      " \n",
      "...completed  28417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2870529144340708, \n",
      "\n",
      "                Current testing accuracy:  0.656 \n",
      "\n",
      "                Current testing loss:  1.1598598957061768 \n",
      " \n",
      "...completed  28545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3110011822707577, \n",
      "\n",
      "                Current testing accuracy:  0.629 \n",
      "\n",
      "                Current testing loss:  1.2073405981063843 \n",
      " \n",
      "...completed  28673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3018152962570184, \n",
      "\n",
      "                Current testing accuracy:  0.538 \n",
      "\n",
      "                Current testing loss:  1.6210824251174927 \n",
      " \n",
      "...completed  28801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3579371836982261, \n",
      "\n",
      "                Current testing accuracy:  0.636 \n",
      "\n",
      "                Current testing loss:  1.245340347290039 \n",
      " \n",
      "...completed  28929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6643963772490906, \n",
      "\n",
      "                Current testing accuracy:  0.327 \n",
      "\n",
      "                Current testing loss:  2.828120231628418 \n",
      " \n",
      "...completed  29057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4058616939719286, \n",
      "\n",
      "                Current testing accuracy:  0.661 \n",
      "\n",
      "                Current testing loss:  1.1486848592758179 \n",
      " \n",
      "...completed  29185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9452243257760529, \n",
      "\n",
      "                Current testing accuracy:  0.662 \n",
      "\n",
      "                Current testing loss:  1.0656840801239014 \n",
      " \n",
      "...completed  29313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2709069200280396, \n",
      "\n",
      "                Current testing accuracy:  0.666 \n",
      "\n",
      "                Current testing loss:  1.0686012506484985 \n",
      " \n",
      "...completed  29441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2670124152342055, \n",
      "\n",
      "                Current testing accuracy:  0.663 \n",
      "\n",
      "                Current testing loss:  1.1322394609451294 \n",
      " \n",
      "...completed  29569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3685218585479788, \n",
      "\n",
      "                Current testing accuracy:  0.587 \n",
      "\n",
      "                Current testing loss:  1.5076864957809448 \n",
      " \n",
      "...completed  29697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3280388781468773, \n",
      "\n",
      "                Current testing accuracy:  0.77 \n",
      "\n",
      "                Current testing loss:  0.8006487488746643 \n",
      " \n",
      "...completed  29825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1761027320265782, \n",
      "\n",
      "                Current testing accuracy:  0.545 \n",
      "\n",
      "                Current testing loss:  1.5006111860275269 \n",
      " \n",
      "...completed  29953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.647549678449927, \n",
      "\n",
      "                Current testing accuracy:  0.703 \n",
      "\n",
      "                Current testing loss:  1.1470493078231812 \n",
      " \n",
      "...completed  30081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4034005562206744, \n",
      "\n",
      "                Current testing accuracy:  0.576 \n",
      "\n",
      "                Current testing loss:  1.4410662651062012 \n",
      " \n",
      "...completed  30209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9945091012802436, \n",
      "\n",
      "                Current testing accuracy:  0.637 \n",
      "\n",
      "                Current testing loss:  1.1121879816055298 \n",
      " \n",
      "...completed  30337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.223911137922002, \n",
      "\n",
      "                Current testing accuracy:  0.696 \n",
      "\n",
      "                Current testing loss:  0.9242022633552551 \n",
      " \n",
      "...completed  30465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2310367881405, \n",
      "\n",
      "                Current testing accuracy:  0.599 \n",
      "\n",
      "                Current testing loss:  1.246107578277588 \n",
      " \n",
      "...completed  30593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.489432365658999, \n",
      "\n",
      "                Current testing accuracy:  0.519 \n",
      "\n",
      "                Current testing loss:  1.6802170276641846 \n",
      " \n",
      "...completed  30721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0428546059171708, \n",
      "\n",
      "                Current testing accuracy:  0.617 \n",
      "\n",
      "                Current testing loss:  1.2029552459716797 \n",
      " \n",
      "...completed  30849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.328981700717776, \n",
      "\n",
      "                Current testing accuracy:  0.604 \n",
      "\n",
      "                Current testing loss:  1.31472647190094 \n",
      " \n",
      "...completed  30977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3229377844001817, \n",
      "\n",
      "                Current testing accuracy:  0.733 \n",
      "\n",
      "                Current testing loss:  0.8059448003768921 \n",
      " \n",
      "...completed  31105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1628962768718338, \n",
      "\n",
      "                Current testing accuracy:  0.67 \n",
      "\n",
      "                Current testing loss:  1.2340279817581177 \n",
      " \n",
      "...completed  31233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4528517157989427, \n",
      "\n",
      "                Current testing accuracy:  0.647 \n",
      "\n",
      "                Current testing loss:  1.0715335607528687 \n",
      " \n",
      "...completed  31361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0096427046254917, \n",
      "\n",
      "                Current testing accuracy:  0.524 \n",
      "\n",
      "                Current testing loss:  1.3783589601516724 \n",
      " \n",
      "...completed  31489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1283560197149851, \n",
      "\n",
      "                Current testing accuracy:  0.687 \n",
      "\n",
      "                Current testing loss:  1.0020203590393066 \n",
      " \n",
      "...completed  31617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2086385061583798, \n",
      "\n",
      "                Current testing accuracy:  0.622 \n",
      "\n",
      "                Current testing loss:  1.1173208951950073 \n",
      " \n",
      "...completed  31745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.6962649151407732, \n",
      "\n",
      "                Current testing accuracy:  0.637 \n",
      "\n",
      "                Current testing loss:  1.2949007749557495 \n",
      " \n",
      "...completed  31873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2889374705360126, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.7551093697547913 \n",
      " \n",
      "...completed  32001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1839039343351985, \n",
      "\n",
      "                Current testing accuracy:  0.646 \n",
      "\n",
      "                Current testing loss:  1.0586051940917969 \n",
      " \n",
      "...completed  32129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0573524288872704, \n",
      "\n",
      "                Current testing accuracy:  0.661 \n",
      "\n",
      "                Current testing loss:  1.0678210258483887 \n",
      " \n",
      "...completed  32257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8652384731540224, \n",
      "\n",
      "                Current testing accuracy:  0.685 \n",
      "\n",
      "                Current testing loss:  1.0131391286849976 \n",
      " \n",
      "...completed  32385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.271531290137176, \n",
      "\n",
      "                Current testing accuracy:  0.691 \n",
      "\n",
      "                Current testing loss:  0.9514980316162109 \n",
      " \n",
      "...completed  32513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8625595240318376, \n",
      "\n",
      "                Current testing accuracy:  0.666 \n",
      "\n",
      "                Current testing loss:  1.0536696910858154 \n",
      " \n",
      "...completed  32641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3796637386944326, \n",
      "\n",
      "                Current testing accuracy:  0.742 \n",
      "\n",
      "                Current testing loss:  0.9054133296012878 \n",
      " \n",
      "...completed  32769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1790410829620441, \n",
      "\n",
      "                Current testing accuracy:  0.638 \n",
      "\n",
      "                Current testing loss:  1.1734447479248047 \n",
      " \n",
      "...completed  32897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.111861780289324, \n",
      "\n",
      "                Current testing accuracy:  0.731 \n",
      "\n",
      "                Current testing loss:  0.9340934157371521 \n",
      " \n",
      "...completed  33025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.988319201764341, \n",
      "\n",
      "                Current testing accuracy:  0.749 \n",
      "\n",
      "                Current testing loss:  0.8092184066772461 \n",
      " \n",
      "...completed  33153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0444037708016936, \n",
      "\n",
      "                Current testing accuracy:  0.66 \n",
      "\n",
      "                Current testing loss:  1.0363656282424927 \n",
      " \n",
      "...completed  33281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1411456596554785, \n",
      "\n",
      "                Current testing accuracy:  0.694 \n",
      "\n",
      "                Current testing loss:  1.0550742149353027 \n",
      " \n",
      "...completed  33409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.041578767496489, \n",
      "\n",
      "                Current testing accuracy:  0.701 \n",
      "\n",
      "                Current testing loss:  0.930000364780426 \n",
      " \n",
      "...completed  33537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2355811641076642, \n",
      "\n",
      "                Current testing accuracy:  0.591 \n",
      "\n",
      "                Current testing loss:  1.4903967380523682 \n",
      " \n",
      "...completed  33665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2969588144686401, \n",
      "\n",
      "                Current testing accuracy:  0.675 \n",
      "\n",
      "                Current testing loss:  0.9238306879997253 \n",
      " \n",
      "...completed  33793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.153000184246288, \n",
      "\n",
      "                Current testing accuracy:  0.557 \n",
      "\n",
      "                Current testing loss:  1.524043321609497 \n",
      " \n",
      "...completed  33921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3910593075220383, \n",
      "\n",
      "                Current testing accuracy:  0.542 \n",
      "\n",
      "                Current testing loss:  1.4368386268615723 \n",
      " \n",
      "...completed  34049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.7163698406602634, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.696158230304718 \n",
      " \n",
      "...completed  34177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.071672805812966, \n",
      "\n",
      "                Current testing accuracy:  0.751 \n",
      "\n",
      "                Current testing loss:  0.8517275452613831 \n",
      " \n",
      "...completed  34305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9084831326590006, \n",
      "\n",
      "                Current testing accuracy:  0.659 \n",
      "\n",
      "                Current testing loss:  1.0406628847122192 \n",
      " \n",
      "...completed  34433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9896499223608943, \n",
      "\n",
      "                Current testing accuracy:  0.721 \n",
      "\n",
      "                Current testing loss:  0.8735339641571045 \n",
      " \n",
      "...completed  34561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9556456071502062, \n",
      "\n",
      "                Current testing accuracy:  0.657 \n",
      "\n",
      "                Current testing loss:  1.2136223316192627 \n",
      " \n",
      "...completed  34689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9890497276832377, \n",
      "\n",
      "                Current testing accuracy:  0.616 \n",
      "\n",
      "                Current testing loss:  1.2449101209640503 \n",
      " \n",
      "...completed  34817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0750504434677595, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  1.0880610942840576 \n",
      " \n",
      "...completed  34945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5071294246835194, \n",
      "\n",
      "                Current testing accuracy:  0.792 \n",
      "\n",
      "                Current testing loss:  0.659164547920227 \n",
      " \n",
      "...completed  35073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9343902813639033, \n",
      "\n",
      "                Current testing accuracy:  0.654 \n",
      "\n",
      "                Current testing loss:  1.2219239473342896 \n",
      " \n",
      "...completed  35201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.023970876067125, \n",
      "\n",
      "                Current testing accuracy:  0.739 \n",
      "\n",
      "                Current testing loss:  0.8679381608963013 \n",
      " \n",
      "...completed  35329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0472809567227728, \n",
      "\n",
      "                Current testing accuracy:  0.767 \n",
      "\n",
      "                Current testing loss:  0.7362958192825317 \n",
      " \n",
      "...completed  35457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0264159280063723, \n",
      "\n",
      "                Current testing accuracy:  0.799 \n",
      "\n",
      "                Current testing loss:  0.6612153053283691 \n",
      " \n",
      "...completed  35585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3434748313999876, \n",
      "\n",
      "                Current testing accuracy:  0.626 \n",
      "\n",
      "                Current testing loss:  1.3962079286575317 \n",
      " \n",
      "...completed  35713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1954102852847086, \n",
      "\n",
      "                Current testing accuracy:  0.705 \n",
      "\n",
      "                Current testing loss:  1.014901876449585 \n",
      " \n",
      "...completed  35841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3158438891466844, \n",
      "\n",
      "                Current testing accuracy:  0.682 \n",
      "\n",
      "                Current testing loss:  1.0600781440734863 \n",
      " \n",
      "...completed  35969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.235243408309998, \n",
      "\n",
      "                Current testing accuracy:  0.734 \n",
      "\n",
      "                Current testing loss:  0.8719943165779114 \n",
      " \n",
      "...completed  36097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.272383326483661, \n",
      "\n",
      "                Current testing accuracy:  0.632 \n",
      "\n",
      "                Current testing loss:  1.405643343925476 \n",
      " \n",
      "...completed  36225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7978182079502854, \n",
      "\n",
      "                Current testing accuracy:  0.72 \n",
      "\n",
      "                Current testing loss:  0.8982208371162415 \n",
      " \n",
      "...completed  36353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8514278180120911, \n",
      "\n",
      "                Current testing accuracy:  0.708 \n",
      "\n",
      "                Current testing loss:  1.0030219554901123 \n",
      " \n",
      "...completed  36481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0673485604959296, \n",
      "\n",
      "                Current testing accuracy:  0.641 \n",
      "\n",
      "                Current testing loss:  1.3137098550796509 \n",
      " \n",
      "...completed  36609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9386623505707234, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.7747305631637573 \n",
      " \n",
      "...completed  36737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2439147727895374, \n",
      "\n",
      "                Current testing accuracy:  0.732 \n",
      "\n",
      "                Current testing loss:  0.7960142493247986 \n",
      " \n",
      "...completed  36865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1232930329679363, \n",
      "\n",
      "                Current testing accuracy:  0.751 \n",
      "\n",
      "                Current testing loss:  0.7944260835647583 \n",
      " \n",
      "...completed  36993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9736070452012129, \n",
      "\n",
      "                Current testing accuracy:  0.75 \n",
      "\n",
      "                Current testing loss:  0.7401831746101379 \n",
      " \n",
      "...completed  37121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1300751425417275, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  0.8665966987609863 \n",
      " \n",
      "...completed  37249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.379889880068319, \n",
      "\n",
      "                Current testing accuracy:  0.597 \n",
      "\n",
      "                Current testing loss:  1.4815077781677246 \n",
      " \n",
      "...completed  37377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2528776849387668, \n",
      "\n",
      "                Current testing accuracy:  0.66 \n",
      "\n",
      "                Current testing loss:  1.1026921272277832 \n",
      " \n",
      "...completed  37505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1429044447838805, \n",
      "\n",
      "                Current testing accuracy:  0.8 \n",
      "\n",
      "                Current testing loss:  0.6549254059791565 \n",
      " \n",
      "...completed  37633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0478378021513208, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.7152040004730225 \n",
      " \n",
      "...completed  37761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1243669459385046, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  0.9003294706344604 \n",
      " \n",
      "...completed  37889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1198878358788988, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.8207573294639587 \n",
      " \n",
      "...completed  38017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9768892319999196, \n",
      "\n",
      "                Current testing accuracy:  0.588 \n",
      "\n",
      "                Current testing loss:  1.4218560457229614 \n",
      " \n",
      "...completed  38145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.225823010982289, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  0.905363142490387 \n",
      " \n",
      "...completed  38273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.24844551532113, \n",
      "\n",
      "                Current testing accuracy:  0.773 \n",
      "\n",
      "                Current testing loss:  0.7253289222717285 \n",
      " \n",
      "...completed  38401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0258883611225542, \n",
      "\n",
      "                Current testing accuracy:  0.645 \n",
      "\n",
      "                Current testing loss:  1.1716396808624268 \n",
      " \n",
      "...completed  38529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.859506090093936, \n",
      "\n",
      "                Current testing accuracy:  0.752 \n",
      "\n",
      "                Current testing loss:  0.7613711357116699 \n",
      " \n",
      "...completed  38657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2595809368036726, \n",
      "\n",
      "                Current testing accuracy:  0.832 \n",
      "\n",
      "                Current testing loss:  0.5513008832931519 \n",
      " \n",
      "...completed  38785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0422058547617468, \n",
      "\n",
      "                Current testing accuracy:  0.622 \n",
      "\n",
      "                Current testing loss:  1.367301106452942 \n",
      " \n",
      "...completed  38913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0626366360469888, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  1.1051931381225586 \n",
      " \n",
      "...completed  39041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3321182574122838, \n",
      "\n",
      "                Current testing accuracy:  0.518 \n",
      "\n",
      "                Current testing loss:  1.738444447517395 \n",
      " \n",
      "...completed  39169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7742276910172166, \n",
      "\n",
      "                Current testing accuracy:  0.695 \n",
      "\n",
      "                Current testing loss:  0.9741286635398865 \n",
      " \n",
      "...completed  39297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.826140365490275, \n",
      "\n",
      "                Current testing accuracy:  0.661 \n",
      "\n",
      "                Current testing loss:  1.034469485282898 \n",
      " \n",
      "...completed  39425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.250663926938584, \n",
      "\n",
      "                Current testing accuracy:  0.694 \n",
      "\n",
      "                Current testing loss:  0.9626694321632385 \n",
      " \n",
      "...completed  39553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2021333594988448, \n",
      "\n",
      "                Current testing accuracy:  0.732 \n",
      "\n",
      "                Current testing loss:  0.8016287088394165 \n",
      " \n",
      "...completed  39681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0754704149489456, \n",
      "\n",
      "                Current testing accuracy:  0.711 \n",
      "\n",
      "                Current testing loss:  0.9691113829612732 \n",
      " \n",
      "...completed  39809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9800136660557488, \n",
      "\n",
      "                Current testing accuracy:  0.711 \n",
      "\n",
      "                Current testing loss:  0.9493952989578247 \n",
      " \n",
      "...completed  39937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9412817297476579, \n",
      "\n",
      "                Current testing accuracy:  0.684 \n",
      "\n",
      "                Current testing loss:  1.0251367092132568 \n",
      " \n",
      "...completed  40065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3092362997064555, \n",
      "\n",
      "                Current testing accuracy:  0.727 \n",
      "\n",
      "                Current testing loss:  1.0144728422164917 \n",
      " \n",
      "...completed  40193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0213394273453131, \n",
      "\n",
      "                Current testing accuracy:  0.765 \n",
      "\n",
      "                Current testing loss:  0.7474063634872437 \n",
      " \n",
      "...completed  40321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1183443484783169, \n",
      "\n",
      "                Current testing accuracy:  0.635 \n",
      "\n",
      "                Current testing loss:  1.314656376838684 \n",
      " \n",
      "...completed  40449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.690455701709439, \n",
      "\n",
      "                Current testing accuracy:  0.706 \n",
      "\n",
      "                Current testing loss:  0.9305192828178406 \n",
      " \n",
      "...completed  40577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.105465699629093, \n",
      "\n",
      "                Current testing accuracy:  0.641 \n",
      "\n",
      "                Current testing loss:  1.241657018661499 \n",
      " \n",
      "...completed  40705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1013056503817893, \n",
      "\n",
      "                Current testing accuracy:  0.617 \n",
      "\n",
      "                Current testing loss:  1.2463676929473877 \n",
      " \n",
      "...completed  40833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.5092336771460282, \n",
      "\n",
      "                Current testing accuracy:  0.631 \n",
      "\n",
      "                Current testing loss:  1.4371042251586914 \n",
      " \n",
      "...completed  40961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0420225952026385, \n",
      "\n",
      "                Current testing accuracy:  0.7 \n",
      "\n",
      "                Current testing loss:  1.032456636428833 \n",
      " \n",
      "...completed  41089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.15960535433571, \n",
      "\n",
      "                Current testing accuracy:  0.788 \n",
      "\n",
      "                Current testing loss:  0.7691518068313599 \n",
      " \n",
      "...completed  41217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9406355018374626, \n",
      "\n",
      "                Current testing accuracy:  0.69 \n",
      "\n",
      "                Current testing loss:  1.1104521751403809 \n",
      " \n",
      "...completed  41345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0223319825161843, \n",
      "\n",
      "                Current testing accuracy:  0.716 \n",
      "\n",
      "                Current testing loss:  1.013997197151184 \n",
      " \n",
      "...completed  41473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0488879371006448, \n",
      "\n",
      "                Current testing accuracy:  0.637 \n",
      "\n",
      "                Current testing loss:  1.4445089101791382 \n",
      " \n",
      "...completed  41601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.241592562758683, \n",
      "\n",
      "                Current testing accuracy:  0.736 \n",
      "\n",
      "                Current testing loss:  0.8625162839889526 \n",
      " \n",
      "...completed  41729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2709877104248548, \n",
      "\n",
      "                Current testing accuracy:  0.58 \n",
      "\n",
      "                Current testing loss:  1.4156216382980347 \n",
      " \n",
      "...completed  41857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3053151750143321, \n",
      "\n",
      "                Current testing accuracy:  0.759 \n",
      "\n",
      "                Current testing loss:  0.8087244629859924 \n",
      " \n",
      "...completed  41985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8597650122837077, \n",
      "\n",
      "                Current testing accuracy:  0.65 \n",
      "\n",
      "                Current testing loss:  1.2249207496643066 \n",
      " \n",
      "...completed  42113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2253333617925364, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8580569624900818 \n",
      " \n",
      "...completed  42241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3036388706081536, \n",
      "\n",
      "                Current testing accuracy:  0.668 \n",
      "\n",
      "                Current testing loss:  1.227953314781189 \n",
      " \n",
      "...completed  42369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8607165049205034, \n",
      "\n",
      "                Current testing accuracy:  0.723 \n",
      "\n",
      "                Current testing loss:  0.9383342266082764 \n",
      " \n",
      "...completed  42497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5844088637909977, \n",
      "\n",
      "                Current testing accuracy:  0.726 \n",
      "\n",
      "                Current testing loss:  0.9538847804069519 \n",
      " \n",
      "...completed  42625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2817968444364851, \n",
      "\n",
      "                Current testing accuracy:  0.622 \n",
      "\n",
      "                Current testing loss:  1.2518479824066162 \n",
      " \n",
      "...completed  42753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0776097556126985, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  0.8953083753585815 \n",
      " \n",
      "...completed  42881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0572640723051006, \n",
      "\n",
      "                Current testing accuracy:  0.733 \n",
      "\n",
      "                Current testing loss:  1.02243173122406 \n",
      " \n",
      "...completed  43009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.801536924289401, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.727310061454773 \n",
      " \n",
      "...completed  43137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8467569997910545, \n",
      "\n",
      "                Current testing accuracy:  0.775 \n",
      "\n",
      "                Current testing loss:  0.8027193546295166 \n",
      " \n",
      "...completed  43265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.019726415715457, \n",
      "\n",
      "                Current testing accuracy:  0.767 \n",
      "\n",
      "                Current testing loss:  0.8046261668205261 \n",
      " \n",
      "...completed  43393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3339122787880555, \n",
      "\n",
      "                Current testing accuracy:  0.713 \n",
      "\n",
      "                Current testing loss:  0.9714052081108093 \n",
      " \n",
      "...completed  43521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2209320906492849, \n",
      "\n",
      "                Current testing accuracy:  0.623 \n",
      "\n",
      "                Current testing loss:  1.3866503238677979 \n",
      " \n",
      "...completed  43649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1103341400984306, \n",
      "\n",
      "                Current testing accuracy:  0.707 \n",
      "\n",
      "                Current testing loss:  0.98091721534729 \n",
      " \n",
      "...completed  43777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.987257147963021, \n",
      "\n",
      "                Current testing accuracy:  0.726 \n",
      "\n",
      "                Current testing loss:  0.9501310586929321 \n",
      " \n",
      "...completed  43905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3813498243946256, \n",
      "\n",
      "                Current testing accuracy:  0.694 \n",
      "\n",
      "                Current testing loss:  1.1264770030975342 \n",
      " \n",
      "...completed  44033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2928271887345488, \n",
      "\n",
      "                Current testing accuracy:  0.599 \n",
      "\n",
      "                Current testing loss:  1.2526568174362183 \n",
      " \n",
      "...completed  44161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2608730025041375, \n",
      "\n",
      "                Current testing accuracy:  0.684 \n",
      "\n",
      "                Current testing loss:  1.0896300077438354 \n",
      " \n",
      "...completed  44289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9800179991906219, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  0.8846126794815063 \n",
      " \n",
      "...completed  44417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8745431829103154, \n",
      "\n",
      "                Current testing accuracy:  0.764 \n",
      "\n",
      "                Current testing loss:  0.8021618723869324 \n",
      " \n",
      "...completed  44545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9691991536798739, \n",
      "\n",
      "                Current testing accuracy:  0.767 \n",
      "\n",
      "                Current testing loss:  0.8096385598182678 \n",
      " \n",
      "...completed  44673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1317206059296439, \n",
      "\n",
      "                Current testing accuracy:  0.654 \n",
      "\n",
      "                Current testing loss:  1.0860724449157715 \n",
      " \n",
      "...completed  44801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.925792999818519, \n",
      "\n",
      "                Current testing accuracy:  0.69 \n",
      "\n",
      "                Current testing loss:  1.0682131052017212 \n",
      " \n",
      "...completed  44929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8033682984308683, \n",
      "\n",
      "                Current testing accuracy:  0.699 \n",
      "\n",
      "                Current testing loss:  1.0352237224578857 \n",
      " \n",
      "...completed  45057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3122910934498009, \n",
      "\n",
      "                Current testing accuracy:  0.816 \n",
      "\n",
      "                Current testing loss:  0.5845133066177368 \n",
      " \n",
      "...completed  45185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0809553778186638, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.7626925706863403 \n",
      " \n",
      "...completed  45313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8835853397134947, \n",
      "\n",
      "                Current testing accuracy:  0.699 \n",
      "\n",
      "                Current testing loss:  0.9297450184822083 \n",
      " \n",
      "...completed  45441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8382834237385168, \n",
      "\n",
      "                Current testing accuracy:  0.668 \n",
      "\n",
      "                Current testing loss:  0.9995123147964478 \n",
      " \n",
      "...completed  45569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.240336623014187, \n",
      "\n",
      "                Current testing accuracy:  0.725 \n",
      "\n",
      "                Current testing loss:  0.9353002309799194 \n",
      " \n",
      "...completed  45697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0544902139674832, \n",
      "\n",
      "                Current testing accuracy:  0.718 \n",
      "\n",
      "                Current testing loss:  0.8858683109283447 \n",
      " \n",
      "...completed  45825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0391856635978187, \n",
      "\n",
      "                Current testing accuracy:  0.796 \n",
      "\n",
      "                Current testing loss:  0.7024438977241516 \n",
      " \n",
      "...completed  45953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7477688644755212, \n",
      "\n",
      "                Current testing accuracy:  0.751 \n",
      "\n",
      "                Current testing loss:  0.8021082878112793 \n",
      " \n",
      "...completed  46081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8766547502348931, \n",
      "\n",
      "                Current testing accuracy:  0.721 \n",
      "\n",
      "                Current testing loss:  0.8871396780014038 \n",
      " \n",
      "...completed  46209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1028124752511062, \n",
      "\n",
      "                Current testing accuracy:  0.71 \n",
      "\n",
      "                Current testing loss:  1.0740752220153809 \n",
      " \n",
      "...completed  46337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8672088227639989, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  0.9546248912811279 \n",
      " \n",
      "...completed  46465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0513929699577673, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  0.983969509601593 \n",
      " \n",
      "...completed  46593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1798445021758428, \n",
      "\n",
      "                Current testing accuracy:  0.785 \n",
      "\n",
      "                Current testing loss:  0.6928489208221436 \n",
      " \n",
      "...completed  46721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9103397606476022, \n",
      "\n",
      "                Current testing accuracy:  0.774 \n",
      "\n",
      "                Current testing loss:  0.7442940473556519 \n",
      " \n",
      "...completed  46849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7220225701080167, \n",
      "\n",
      "                Current testing accuracy:  0.774 \n",
      "\n",
      "                Current testing loss:  0.7457816004753113 \n",
      " \n",
      "...completed  46977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1713838843689928, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  0.8279982805252075 \n",
      " \n",
      "...completed  47105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9059080890511488, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.8126627206802368 \n",
      " \n",
      "...completed  47233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.161110477712807, \n",
      "\n",
      "                Current testing accuracy:  0.688 \n",
      "\n",
      "                Current testing loss:  1.0668971538543701 \n",
      " \n",
      "...completed  47361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9610852095562663, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.8764929175376892 \n",
      " \n",
      "...completed  47489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1568236795324474, \n",
      "\n",
      "                Current testing accuracy:  0.738 \n",
      "\n",
      "                Current testing loss:  0.8559229969978333 \n",
      " \n",
      "...completed  47617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8182284445163646, \n",
      "\n",
      "                Current testing accuracy:  0.756 \n",
      "\n",
      "                Current testing loss:  0.7911362648010254 \n",
      " \n",
      "...completed  47745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1352232767408523, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.6802865862846375 \n",
      " \n",
      "...completed  47873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9435149227514898, \n",
      "\n",
      "                Current testing accuracy:  0.718 \n",
      "\n",
      "                Current testing loss:  0.9620407819747925 \n",
      " \n",
      "...completed  48001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.187501064730391, \n",
      "\n",
      "                Current testing accuracy:  0.684 \n",
      "\n",
      "                Current testing loss:  1.3066887855529785 \n",
      " \n",
      "...completed  48129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9866149150966379, \n",
      "\n",
      "                Current testing accuracy:  0.802 \n",
      "\n",
      "                Current testing loss:  0.6661202907562256 \n",
      " \n",
      "...completed  48257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8845903109963134, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.748672366142273 \n",
      " \n",
      "...completed  48385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.113628505550821, \n",
      "\n",
      "                Current testing accuracy:  0.626 \n",
      "\n",
      "                Current testing loss:  1.3126513957977295 \n",
      " \n",
      "...completed  48513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9960049343896666, \n",
      "\n",
      "                Current testing accuracy:  0.676 \n",
      "\n",
      "                Current testing loss:  1.3203288316726685 \n",
      " \n",
      "...completed  48641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2869664913895917, \n",
      "\n",
      "                Current testing accuracy:  0.744 \n",
      "\n",
      "                Current testing loss:  0.8896468877792358 \n",
      " \n",
      "...completed  48769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8910081517149209, \n",
      "\n",
      "                Current testing accuracy:  0.769 \n",
      "\n",
      "                Current testing loss:  0.7320122122764587 \n",
      " \n",
      "...completed  48897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.269977900556114, \n",
      "\n",
      "                Current testing accuracy:  0.791 \n",
      "\n",
      "                Current testing loss:  0.7275816798210144 \n",
      " \n",
      "...completed  49025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.4561171838350284, \n",
      "\n",
      "                Current testing accuracy:  0.785 \n",
      "\n",
      "                Current testing loss:  0.7407651543617249 \n",
      " \n",
      "...completed  49153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0429630181433394, \n",
      "\n",
      "                Current testing accuracy:  0.685 \n",
      "\n",
      "                Current testing loss:  1.0138400793075562 \n",
      " \n",
      "...completed  49281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0487062476547067, \n",
      "\n",
      "                Current testing accuracy:  0.815 \n",
      "\n",
      "                Current testing loss:  0.6126987338066101 \n",
      " \n",
      "...completed  49409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1285897442235324, \n",
      "\n",
      "                Current testing accuracy:  0.772 \n",
      "\n",
      "                Current testing loss:  0.7848514318466187 \n",
      " \n",
      "...completed  49537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1518491366191626, \n",
      "\n",
      "                Current testing accuracy:  0.688 \n",
      "\n",
      "                Current testing loss:  1.181931972503662 \n",
      " \n",
      "...completed  49665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8918636655469072, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.8017090559005737 \n",
      " \n",
      "...completed  49793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9770672823611619, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.8391170501708984 \n",
      " \n",
      "...completed  49921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9373545942398422, \n",
      "\n",
      "                Current testing accuracy:  0.705 \n",
      "\n",
      "                Current testing loss:  0.9734053015708923 \n",
      " \n",
      "...completed  50049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8660966185142183, \n",
      "\n",
      "                Current testing accuracy:  0.754 \n",
      "\n",
      "                Current testing loss:  0.8506090044975281 \n",
      " \n",
      "...completed  50177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3913790905954495, \n",
      "\n",
      "                Current testing accuracy:  0.754 \n",
      "\n",
      "                Current testing loss:  0.8090481758117676 \n",
      " \n",
      "...completed  50305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0167989344858341, \n",
      "\n",
      "                Current testing accuracy:  0.715 \n",
      "\n",
      "                Current testing loss:  0.9949955940246582 \n",
      " \n",
      "...completed  50433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2805788914602916, \n",
      "\n",
      "                Current testing accuracy:  0.599 \n",
      "\n",
      "                Current testing loss:  1.4716246128082275 \n",
      " \n",
      "...completed  50561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1958204749839698, \n",
      "\n",
      "                Current testing accuracy:  0.677 \n",
      "\n",
      "                Current testing loss:  1.0937875509262085 \n",
      " \n",
      "...completed  50689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9355088441122814, \n",
      "\n",
      "                Current testing accuracy:  0.658 \n",
      "\n",
      "                Current testing loss:  1.3175867795944214 \n",
      " \n",
      "...completed  50817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2130612407347452, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  1.1019130945205688 \n",
      " \n",
      "...completed  50945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0277075308209476, \n",
      "\n",
      "                Current testing accuracy:  0.464 \n",
      "\n",
      "                Current testing loss:  2.0106041431427 \n",
      " \n",
      "...completed  51073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0053064005609826, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.923778772354126 \n",
      " \n",
      "...completed  51201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9243328722168371, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.8467655181884766 \n",
      " \n",
      "...completed  51329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0953898798064274, \n",
      "\n",
      "                Current testing accuracy:  0.827 \n",
      "\n",
      "                Current testing loss:  0.5635995268821716 \n",
      " \n",
      "...completed  51457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8210875100214481, \n",
      "\n",
      "                Current testing accuracy:  0.736 \n",
      "\n",
      "                Current testing loss:  0.9312089681625366 \n",
      " \n",
      "...completed  51585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8592606530983815, \n",
      "\n",
      "                Current testing accuracy:  0.474 \n",
      "\n",
      "                Current testing loss:  2.1791892051696777 \n",
      " \n",
      "...completed  51713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8742310671251765, \n",
      "\n",
      "                Current testing accuracy:  0.735 \n",
      "\n",
      "                Current testing loss:  0.8943145871162415 \n",
      " \n",
      "...completed  51841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7426516323055594, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.8403341174125671 \n",
      " \n",
      "...completed  51969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6323931014550439, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.7147373557090759 \n",
      " \n",
      "...completed  52097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1329434842733406, \n",
      "\n",
      "                Current testing accuracy:  0.718 \n",
      "\n",
      "                Current testing loss:  1.046581745147705 \n",
      " \n",
      "...completed  52225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.081828903753017, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.8162050843238831 \n",
      " \n",
      "...completed  52353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8203016449816403, \n",
      "\n",
      "                Current testing accuracy:  0.754 \n",
      "\n",
      "                Current testing loss:  0.8018979430198669 \n",
      " \n",
      "...completed  52481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9282934541121985, \n",
      "\n",
      "                Current testing accuracy:  0.746 \n",
      "\n",
      "                Current testing loss:  0.9098772406578064 \n",
      " \n",
      "...completed  52609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0107149727920728, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.7964701652526855 \n",
      " \n",
      "...completed  52737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.15963884320783, \n",
      "\n",
      "                Current testing accuracy:  0.725 \n",
      "\n",
      "                Current testing loss:  0.982187032699585 \n",
      " \n",
      "...completed  52865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7822679727963191, \n",
      "\n",
      "                Current testing accuracy:  0.688 \n",
      "\n",
      "                Current testing loss:  1.0931518077850342 \n",
      " \n",
      "...completed  52993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1568126045335276, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8173073530197144 \n",
      " \n",
      "...completed  53121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.116479965310333, \n",
      "\n",
      "                Current testing accuracy:  0.726 \n",
      "\n",
      "                Current testing loss:  0.9961944222450256 \n",
      " \n",
      "...completed  53249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8824335656657709, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.8142272233963013 \n",
      " \n",
      "...completed  53377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8769106109014224, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  1.148382544517517 \n",
      " \n",
      "...completed  53505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.002888912633182, \n",
      "\n",
      "                Current testing accuracy:  0.775 \n",
      "\n",
      "                Current testing loss:  0.75949627161026 \n",
      " \n",
      "...completed  53633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8458370614188482, \n",
      "\n",
      "                Current testing accuracy:  0.804 \n",
      "\n",
      "                Current testing loss:  0.7002682089805603 \n",
      " \n",
      "...completed  53761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.788711420554371, \n",
      "\n",
      "                Current testing accuracy:  0.734 \n",
      "\n",
      "                Current testing loss:  0.9755586981773376 \n",
      " \n",
      "...completed  53889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9941743805756111, \n",
      "\n",
      "                Current testing accuracy:  0.8 \n",
      "\n",
      "                Current testing loss:  0.6732536554336548 \n",
      " \n",
      "...completed  54017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8703799504477843, \n",
      "\n",
      "                Current testing accuracy:  0.746 \n",
      "\n",
      "                Current testing loss:  0.8516390323638916 \n",
      " \n",
      "...completed  54145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7671162388109991, \n",
      "\n",
      "                Current testing accuracy:  0.7 \n",
      "\n",
      "                Current testing loss:  1.050014615058899 \n",
      " \n",
      "...completed  54273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1699354619860003, \n",
      "\n",
      "                Current testing accuracy:  0.795 \n",
      "\n",
      "                Current testing loss:  0.7068294286727905 \n",
      " \n",
      "...completed  54401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7874627933687106, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.8305509090423584 \n",
      " \n",
      "...completed  54529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6615169117548021, \n",
      "\n",
      "                Current testing accuracy:  0.725 \n",
      "\n",
      "                Current testing loss:  0.9732840061187744 \n",
      " \n",
      "...completed  54657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8487219795333161, \n",
      "\n",
      "                Current testing accuracy:  0.794 \n",
      "\n",
      "                Current testing loss:  0.7864652276039124 \n",
      " \n",
      "...completed  54785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1136561463409755, \n",
      "\n",
      "                Current testing accuracy:  0.756 \n",
      "\n",
      "                Current testing loss:  0.8343742489814758 \n",
      " \n",
      "...completed  54913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8227640466019608, \n",
      "\n",
      "                Current testing accuracy:  0.695 \n",
      "\n",
      "                Current testing loss:  1.1033806800842285 \n",
      " \n",
      "...completed  55041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.068128562473575, \n",
      "\n",
      "                Current testing accuracy:  0.798 \n",
      "\n",
      "                Current testing loss:  0.6466104984283447 \n",
      " \n",
      "...completed  55169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1867389731914155, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.7900967597961426 \n",
      " \n",
      "...completed  55297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9247819350252939, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8915719389915466 \n",
      " \n",
      "...completed  55425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7751849943674074, \n",
      "\n",
      "                Current testing accuracy:  0.819 \n",
      "\n",
      "                Current testing loss:  0.5971309542655945 \n",
      " \n",
      "...completed  55553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9384365802283519, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.8251571655273438 \n",
      " \n",
      "...completed  55681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0582128135289715, \n",
      "\n",
      "                Current testing accuracy:  0.747 \n",
      "\n",
      "                Current testing loss:  0.8677630424499512 \n",
      " \n",
      "...completed  55809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1692278849569107, \n",
      "\n",
      "                Current testing accuracy:  0.811 \n",
      "\n",
      "                Current testing loss:  0.6523266434669495 \n",
      " \n",
      "...completed  55937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1168476936139058, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8698708415031433 \n",
      " \n",
      "...completed  56065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0245641895942912, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.6060857176780701 \n",
      " \n",
      "...completed  56193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0161745062702887, \n",
      "\n",
      "                Current testing accuracy:  0.772 \n",
      "\n",
      "                Current testing loss:  0.7477411031723022 \n",
      " \n",
      "...completed  56321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1139104078632087, \n",
      "\n",
      "                Current testing accuracy:  0.754 \n",
      "\n",
      "                Current testing loss:  0.7802406549453735 \n",
      " \n",
      "...completed  56449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9109465403928212, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.7279035449028015 \n",
      " \n",
      "...completed  56577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.917732962284628, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.8728782534599304 \n",
      " \n",
      "...completed  56705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7198424000409673, \n",
      "\n",
      "                Current testing accuracy:  0.646 \n",
      "\n",
      "                Current testing loss:  1.210986614227295 \n",
      " \n",
      "...completed  56833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3418488659068046, \n",
      "\n",
      "                Current testing accuracy:  0.719 \n",
      "\n",
      "                Current testing loss:  0.9851939678192139 \n",
      " \n",
      "...completed  56961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8559439764685521, \n",
      "\n",
      "                Current testing accuracy:  0.728 \n",
      "\n",
      "                Current testing loss:  0.9180278182029724 \n",
      " \n",
      "...completed  57089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1664643594504387, \n",
      "\n",
      "                Current testing accuracy:  0.832 \n",
      "\n",
      "                Current testing loss:  0.5926369428634644 \n",
      " \n",
      "...completed  57217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.914633246508922, \n",
      "\n",
      "                Current testing accuracy:  0.828 \n",
      "\n",
      "                Current testing loss:  0.593554675579071 \n",
      " \n",
      "...completed  57345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.882867974253827, \n",
      "\n",
      "                Current testing accuracy:  0.671 \n",
      "\n",
      "                Current testing loss:  1.1277676820755005 \n",
      " \n",
      "...completed  57473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.138063725699503, \n",
      "\n",
      "                Current testing accuracy:  0.715 \n",
      "\n",
      "                Current testing loss:  1.0939396619796753 \n",
      " \n",
      "...completed  57601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3268230269898282, \n",
      "\n",
      "                Current testing accuracy:  0.707 \n",
      "\n",
      "                Current testing loss:  0.9916451573371887 \n",
      " \n",
      "...completed  57729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6974596536499149, \n",
      "\n",
      "                Current testing accuracy:  0.609 \n",
      "\n",
      "                Current testing loss:  1.558039903640747 \n",
      " \n",
      "...completed  57857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9861792287869378, \n",
      "\n",
      "                Current testing accuracy:  0.793 \n",
      "\n",
      "                Current testing loss:  0.6874174475669861 \n",
      " \n",
      "...completed  57985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7551083564037224, \n",
      "\n",
      "                Current testing accuracy:  0.808 \n",
      "\n",
      "                Current testing loss:  0.6325914263725281 \n",
      " \n",
      "...completed  58113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7279539422874359, \n",
      "\n",
      "                Current testing accuracy:  0.695 \n",
      "\n",
      "                Current testing loss:  0.9976333379745483 \n",
      " \n",
      "...completed  58241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7145494623109698, \n",
      "\n",
      "                Current testing accuracy:  0.726 \n",
      "\n",
      "                Current testing loss:  0.9593989253044128 \n",
      " \n",
      "...completed  58369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0306381584425637, \n",
      "\n",
      "                Current testing accuracy:  0.617 \n",
      "\n",
      "                Current testing loss:  1.3645867109298706 \n",
      " \n",
      "...completed  58497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8583825827067812, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  0.9035946726799011 \n",
      " \n",
      "...completed  58625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1443162061752545, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  1.0455613136291504 \n",
      " \n",
      "...completed  58753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.022854945408767, \n",
      "\n",
      "                Current testing accuracy:  0.791 \n",
      "\n",
      "                Current testing loss:  0.7091443538665771 \n",
      " \n",
      "...completed  58881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9581445001508722, \n",
      "\n",
      "                Current testing accuracy:  0.722 \n",
      "\n",
      "                Current testing loss:  0.9179469347000122 \n",
      " \n",
      "...completed  59009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.00648918929042, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8241239786148071 \n",
      " \n",
      "...completed  59137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.038949318526683, \n",
      "\n",
      "                Current testing accuracy:  0.736 \n",
      "\n",
      "                Current testing loss:  0.8422315716743469 \n",
      " \n",
      "...completed  59265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2462302410735226, \n",
      "\n",
      "                Current testing accuracy:  0.712 \n",
      "\n",
      "                Current testing loss:  0.9581857919692993 \n",
      " \n",
      "...completed  59393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0531642154767695, \n",
      "\n",
      "                Current testing accuracy:  0.632 \n",
      "\n",
      "                Current testing loss:  1.3395963907241821 \n",
      " \n",
      "...completed  59521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.842353542607924, \n",
      "\n",
      "                Current testing accuracy:  0.775 \n",
      "\n",
      "                Current testing loss:  0.8357599973678589 \n",
      " \n",
      "...completed  59649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0476541438463052, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.9210953712463379 \n",
      " \n",
      "...completed  59777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0271926005875862, \n",
      "\n",
      "                Current testing accuracy:  0.765 \n",
      "\n",
      "                Current testing loss:  0.8927894830703735 \n",
      " \n",
      "...completed  59905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.037648226377673, \n",
      "\n",
      "                Current testing accuracy:  0.797 \n",
      "\n",
      "                Current testing loss:  0.6960724592208862 \n",
      " \n",
      "...completed  60033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9533316409723582, \n",
      "\n",
      "                Current testing accuracy:  0.718 \n",
      "\n",
      "                Current testing loss:  1.0814950466156006 \n",
      " \n",
      "...completed  60161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.918592569207739, \n",
      "\n",
      "                Current testing accuracy:  0.707 \n",
      "\n",
      "                Current testing loss:  0.9842125773429871 \n",
      " \n",
      "...completed  60289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9156591136015724, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.7586045265197754 \n",
      " \n",
      "...completed  60417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.158198616949214, \n",
      "\n",
      "                Current testing accuracy:  0.802 \n",
      "\n",
      "                Current testing loss:  0.6517930030822754 \n",
      " \n",
      "...completed  60545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0364082113328124, \n",
      "\n",
      "                Current testing accuracy:  0.781 \n",
      "\n",
      "                Current testing loss:  0.8029415011405945 \n",
      " \n",
      "...completed  60673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3997794236451977, \n",
      "\n",
      "                Current testing accuracy:  0.738 \n",
      "\n",
      "                Current testing loss:  0.8999881744384766 \n",
      " \n",
      "...completed  60801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7709827522294779, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.8202998638153076 \n",
      " \n",
      "...completed  60929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0297822409034723, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.6547696590423584 \n",
      " \n",
      "...completed  61057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8082266801625009, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.6527553200721741 \n",
      " \n",
      "...completed  61185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7730159782852295, \n",
      "\n",
      "                Current testing accuracy:  0.72 \n",
      "\n",
      "                Current testing loss:  1.05906081199646 \n",
      " \n",
      "...completed  61313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1299019054876758, \n",
      "\n",
      "                Current testing accuracy:  0.72 \n",
      "\n",
      "                Current testing loss:  1.1139512062072754 \n",
      " \n",
      "...completed  61441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6158050330118705, \n",
      "\n",
      "                Current testing accuracy:  0.685 \n",
      "\n",
      "                Current testing loss:  1.118011713027954 \n",
      " \n",
      "...completed  61569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8249712134366041, \n",
      "\n",
      "                Current testing accuracy:  0.753 \n",
      "\n",
      "                Current testing loss:  0.9287630319595337 \n",
      " \n",
      "...completed  61697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8058067824939137, \n",
      "\n",
      "                Current testing accuracy:  0.795 \n",
      "\n",
      "                Current testing loss:  0.7281274199485779 \n",
      " \n",
      "...completed  61825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6966414304701356, \n",
      "\n",
      "                Current testing accuracy:  0.77 \n",
      "\n",
      "                Current testing loss:  0.8457027673721313 \n",
      " \n",
      "...completed  61953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9691929745948027, \n",
      "\n",
      "                Current testing accuracy:  0.723 \n",
      "\n",
      "                Current testing loss:  0.9775000214576721 \n",
      " \n",
      "...completed  62081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8570493242424959, \n",
      "\n",
      "                Current testing accuracy:  0.841 \n",
      "\n",
      "                Current testing loss:  0.5415975451469421 \n",
      " \n",
      "...completed  62209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8344049800414082, \n",
      "\n",
      "                Current testing accuracy:  0.728 \n",
      "\n",
      "                Current testing loss:  0.9132315516471863 \n",
      " \n",
      "...completed  62337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9804909377341744, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.9769561886787415 \n",
      " \n",
      "...completed  62465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.125931736740533, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.8934475183486938 \n",
      " \n",
      "...completed  62593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7704199603595638, \n",
      "\n",
      "                Current testing accuracy:  0.716 \n",
      "\n",
      "                Current testing loss:  1.0115914344787598 \n",
      " \n",
      "...completed  62721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6869914571575038, \n",
      "\n",
      "                Current testing accuracy:  0.787 \n",
      "\n",
      "                Current testing loss:  0.7748335599899292 \n",
      " \n",
      "...completed  62849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.111459026796803, \n",
      "\n",
      "                Current testing accuracy:  0.674 \n",
      "\n",
      "                Current testing loss:  1.0129233598709106 \n",
      " \n",
      "...completed  62977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9622062771093818, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.7610952258110046 \n",
      " \n",
      "...completed  63105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8955968722494845, \n",
      "\n",
      "                Current testing accuracy:  0.514 \n",
      "\n",
      "                Current testing loss:  1.8747512102127075 \n",
      " \n",
      "...completed  63233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0025615300007829, \n",
      "\n",
      "                Current testing accuracy:  0.77 \n",
      "\n",
      "                Current testing loss:  0.8150576949119568 \n",
      " \n",
      "...completed  63361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.083091389659467, \n",
      "\n",
      "                Current testing accuracy:  0.64 \n",
      "\n",
      "                Current testing loss:  1.1504600048065186 \n",
      " \n",
      "...completed  63489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1002579541388968, \n",
      "\n",
      "                Current testing accuracy:  0.715 \n",
      "\n",
      "                Current testing loss:  1.072887659072876 \n",
      " \n",
      "...completed  63617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9453505282736212, \n",
      "\n",
      "                Current testing accuracy:  0.774 \n",
      "\n",
      "                Current testing loss:  0.7560566663742065 \n",
      " \n",
      "...completed  63745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0195729933419795, \n",
      "\n",
      "                Current testing accuracy:  0.747 \n",
      "\n",
      "                Current testing loss:  1.0189650058746338 \n",
      " \n",
      "...completed  63873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0960150264350386, \n",
      "\n",
      "                Current testing accuracy:  0.7 \n",
      "\n",
      "                Current testing loss:  1.0810832977294922 \n",
      " \n",
      "...completed  64001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0529779523879625, \n",
      "\n",
      "                Current testing accuracy:  0.673 \n",
      "\n",
      "                Current testing loss:  1.2545976638793945 \n",
      " \n",
      "...completed  64129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.014450892267643, \n",
      "\n",
      "                Current testing accuracy:  0.716 \n",
      "\n",
      "                Current testing loss:  1.0735963582992554 \n",
      " \n",
      "...completed  64257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9809521066077398, \n",
      "\n",
      "                Current testing accuracy:  0.791 \n",
      "\n",
      "                Current testing loss:  0.6834434866905212 \n",
      " \n",
      "...completed  64385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7503646754283722, \n",
      "\n",
      "                Current testing accuracy:  0.788 \n",
      "\n",
      "                Current testing loss:  0.681827187538147 \n",
      " \n",
      "...completed  64513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8336518891647806, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.8740782737731934 \n",
      " \n",
      "...completed  64641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7601060430992304, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  1.1417455673217773 \n",
      " \n",
      "...completed  64769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0849051392905729, \n",
      "\n",
      "                Current testing accuracy:  0.811 \n",
      "\n",
      "                Current testing loss:  0.6253092885017395 \n",
      " \n",
      "...completed  64897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6860675148854938, \n",
      "\n",
      "                Current testing accuracy:  0.834 \n",
      "\n",
      "                Current testing loss:  0.5702813863754272 \n",
      " \n",
      "...completed  65025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.173988335148088, \n",
      "\n",
      "                Current testing accuracy:  0.614 \n",
      "\n",
      "                Current testing loss:  1.5908753871917725 \n",
      " \n",
      "...completed  65153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3649759076925383, \n",
      "\n",
      "                Current testing accuracy:  0.87 \n",
      "\n",
      "                Current testing loss:  0.5046035051345825 \n",
      " \n",
      "...completed  65281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.813269956884362, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.6426299214363098 \n",
      " \n",
      "...completed  65409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8920300407638884, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.9363458156585693 \n",
      " \n",
      "...completed  65537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8851094386751175, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.7224831581115723 \n",
      " \n",
      "...completed  65665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5071584401167186, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.7960643172264099 \n",
      " \n",
      "...completed  65793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9852911729619647, \n",
      "\n",
      "                Current testing accuracy:  0.792 \n",
      "\n",
      "                Current testing loss:  0.7207394242286682 \n",
      " \n",
      "...completed  65921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0351959443578878, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.7274124622344971 \n",
      " \n",
      "...completed  66049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8983914095668268, \n",
      "\n",
      "                Current testing accuracy:  0.737 \n",
      "\n",
      "                Current testing loss:  0.907889723777771 \n",
      " \n",
      "...completed  66177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7477786374272313, \n",
      "\n",
      "                Current testing accuracy:  0.618 \n",
      "\n",
      "                Current testing loss:  1.2448889017105103 \n",
      " \n",
      "...completed  66305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.730215759163583, \n",
      "\n",
      "                Current testing accuracy:  0.641 \n",
      "\n",
      "                Current testing loss:  1.2221542596817017 \n",
      " \n",
      "...completed  66433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8790577437375822, \n",
      "\n",
      "                Current testing accuracy:  0.792 \n",
      "\n",
      "                Current testing loss:  0.8129646182060242 \n",
      " \n",
      "...completed  66561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7953003927822522, \n",
      "\n",
      "                Current testing accuracy:  0.629 \n",
      "\n",
      "                Current testing loss:  1.3474040031433105 \n",
      " \n",
      "...completed  66689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9209149526268994, \n",
      "\n",
      "                Current testing accuracy:  0.752 \n",
      "\n",
      "                Current testing loss:  0.8653932809829712 \n",
      " \n",
      "...completed  66817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.09142768255564, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.7820357084274292 \n",
      " \n",
      "...completed  66945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0691755722253475, \n",
      "\n",
      "                Current testing accuracy:  0.806 \n",
      "\n",
      "                Current testing loss:  0.6612570881843567 \n",
      " \n",
      "...completed  67073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2986202566244103, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  1.0587196350097656 \n",
      " \n",
      "...completed  67201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1313429602737628, \n",
      "\n",
      "                Current testing accuracy:  0.765 \n",
      "\n",
      "                Current testing loss:  0.8981034755706787 \n",
      " \n",
      "...completed  67329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.080317325389295, \n",
      "\n",
      "                Current testing accuracy:  0.827 \n",
      "\n",
      "                Current testing loss:  0.5755190253257751 \n",
      " \n",
      "...completed  67457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1643068016805813, \n",
      "\n",
      "                Current testing accuracy:  0.806 \n",
      "\n",
      "                Current testing loss:  0.6686309576034546 \n",
      " \n",
      "...completed  67585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9487256697081499, \n",
      "\n",
      "                Current testing accuracy:  0.698 \n",
      "\n",
      "                Current testing loss:  1.1355823278427124 \n",
      " \n",
      "...completed  67713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9311225220786206, \n",
      "\n",
      "                Current testing accuracy:  0.82 \n",
      "\n",
      "                Current testing loss:  0.6024040579795837 \n",
      " \n",
      "...completed  67841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8505877803654407, \n",
      "\n",
      "                Current testing accuracy:  0.721 \n",
      "\n",
      "                Current testing loss:  0.9918959140777588 \n",
      " \n",
      "...completed  67969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7023278115812195, \n",
      "\n",
      "                Current testing accuracy:  0.735 \n",
      "\n",
      "                Current testing loss:  0.9910269975662231 \n",
      " \n",
      "...completed  68097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7472798075104734, \n",
      "\n",
      "                Current testing accuracy:  0.801 \n",
      "\n",
      "                Current testing loss:  0.6784690022468567 \n",
      " \n",
      "...completed  68225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9001475828245873, \n",
      "\n",
      "                Current testing accuracy:  0.817 \n",
      "\n",
      "                Current testing loss:  0.6169494390487671 \n",
      " \n",
      "...completed  68353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0829770511156198, \n",
      "\n",
      "                Current testing accuracy:  0.846 \n",
      "\n",
      "                Current testing loss:  0.5358055233955383 \n",
      " \n",
      "...completed  68481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8080536527813464, \n",
      "\n",
      "                Current testing accuracy:  0.813 \n",
      "\n",
      "                Current testing loss:  0.6501474976539612 \n",
      " \n",
      "...completed  68609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.942001891376762, \n",
      "\n",
      "                Current testing accuracy:  0.681 \n",
      "\n",
      "                Current testing loss:  1.291391134262085 \n",
      " \n",
      "...completed  68737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1292514084188237, \n",
      "\n",
      "                Current testing accuracy:  0.795 \n",
      "\n",
      "                Current testing loss:  0.745720624923706 \n",
      " \n",
      "...completed  68865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6429334077440974, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.7570988535881042 \n",
      " \n",
      "...completed  68993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7091656611454038, \n",
      "\n",
      "                Current testing accuracy:  0.799 \n",
      "\n",
      "                Current testing loss:  0.7135258316993713 \n",
      " \n",
      "...completed  69121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8829098823822044, \n",
      "\n",
      "                Current testing accuracy:  0.806 \n",
      "\n",
      "                Current testing loss:  0.6448990106582642 \n",
      " \n",
      "...completed  69249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7865218390393949, \n",
      "\n",
      "                Current testing accuracy:  0.785 \n",
      "\n",
      "                Current testing loss:  0.7368694543838501 \n",
      " \n",
      "...completed  69377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2357786070245549, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.9851381182670593 \n",
      " \n",
      "...completed  69505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0111642575458326, \n",
      "\n",
      "                Current testing accuracy:  0.86 \n",
      "\n",
      "                Current testing loss:  0.5108258724212646 \n",
      " \n",
      "...completed  69633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9476745344343627, \n",
      "\n",
      "                Current testing accuracy:  0.825 \n",
      "\n",
      "                Current testing loss:  0.6107935309410095 \n",
      " \n",
      "...completed  69761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0771999294096481, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.8475995063781738 \n",
      " \n",
      "...completed  69889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8588633637968641, \n",
      "\n",
      "                Current testing accuracy:  0.829 \n",
      "\n",
      "                Current testing loss:  0.5346583127975464 \n",
      " \n",
      "...completed  70017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9210657916507277, \n",
      "\n",
      "                Current testing accuracy:  0.719 \n",
      "\n",
      "                Current testing loss:  0.9646368622779846 \n",
      " \n",
      "...completed  70145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8705751357850975, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.871725857257843 \n",
      " \n",
      "...completed  70273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.001702087815026, \n",
      "\n",
      "                Current testing accuracy:  0.765 \n",
      "\n",
      "                Current testing loss:  0.7974156737327576 \n",
      " \n",
      "...completed  70401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5936587345861337, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.7705150842666626 \n",
      " \n",
      "...completed  70529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7985010514264808, \n",
      "\n",
      "                Current testing accuracy:  0.778 \n",
      "\n",
      "                Current testing loss:  0.8434632420539856 \n",
      " \n",
      "...completed  70657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0056687975484238, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  1.0508228540420532 \n",
      " \n",
      "...completed  70785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7989888308177626, \n",
      "\n",
      "                Current testing accuracy:  0.772 \n",
      "\n",
      "                Current testing loss:  0.8308576345443726 \n",
      " \n",
      "...completed  70913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8528725306902238, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.901470422744751 \n",
      " \n",
      "...completed  71041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9374411613224858, \n",
      "\n",
      "                Current testing accuracy:  0.709 \n",
      "\n",
      "                Current testing loss:  0.9571473598480225 \n",
      " \n",
      "...completed  71169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8407762396775063, \n",
      "\n",
      "                Current testing accuracy:  0.82 \n",
      "\n",
      "                Current testing loss:  0.5904150605201721 \n",
      " \n",
      "...completed  71297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8349931945707052, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.9823869466781616 \n",
      " \n",
      "...completed  71425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0844618766009368, \n",
      "\n",
      "                Current testing accuracy:  0.554 \n",
      "\n",
      "                Current testing loss:  1.6457772254943848 \n",
      " \n",
      "...completed  71553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8872350491308434, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  0.9905014038085938 \n",
      " \n",
      "...completed  71681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2649600327704853, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.9689087867736816 \n",
      " \n",
      "...completed  71809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9124348906385267, \n",
      "\n",
      "                Current testing accuracy:  0.481 \n",
      "\n",
      "                Current testing loss:  2.229734182357788 \n",
      " \n",
      "...completed  71937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3014131063498127, \n",
      "\n",
      "                Current testing accuracy:  0.753 \n",
      "\n",
      "                Current testing loss:  0.830302357673645 \n",
      " \n",
      "...completed  72065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9144413437178569, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.7948765754699707 \n",
      " \n",
      "...completed  72193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1177682161663647, \n",
      "\n",
      "                Current testing accuracy:  0.829 \n",
      "\n",
      "                Current testing loss:  0.5857832431793213 \n",
      " \n",
      "...completed  72321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1137932947625087, \n",
      "\n",
      "                Current testing accuracy:  0.695 \n",
      "\n",
      "                Current testing loss:  1.2249044179916382 \n",
      " \n",
      "...completed  72449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2293192150834202, \n",
      "\n",
      "                Current testing accuracy:  0.73 \n",
      "\n",
      "                Current testing loss:  1.0877774953842163 \n",
      " \n",
      "...completed  72577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7853941541439724, \n",
      "\n",
      "                Current testing accuracy:  0.641 \n",
      "\n",
      "                Current testing loss:  1.2985786199569702 \n",
      " \n",
      "...completed  72705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1207967215872534, \n",
      "\n",
      "                Current testing accuracy:  0.739 \n",
      "\n",
      "                Current testing loss:  0.9524351954460144 \n",
      " \n",
      "...completed  72833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0075614340921915, \n",
      "\n",
      "                Current testing accuracy:  0.769 \n",
      "\n",
      "                Current testing loss:  0.7530921697616577 \n",
      " \n",
      "...completed  72961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1008426344606521, \n",
      "\n",
      "                Current testing accuracy:  0.715 \n",
      "\n",
      "                Current testing loss:  1.072062373161316 \n",
      " \n",
      "...completed  73089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8523837502808591, \n",
      "\n",
      "                Current testing accuracy:  0.685 \n",
      "\n",
      "                Current testing loss:  1.1694834232330322 \n",
      " \n",
      "...completed  73217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6754752438774076, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.8351196050643921 \n",
      " \n",
      "...completed  73345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9348101883899371, \n",
      "\n",
      "                Current testing accuracy:  0.815 \n",
      "\n",
      "                Current testing loss:  0.6249337196350098 \n",
      " \n",
      "...completed  73473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7034993751724166, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.7229191660881042 \n",
      " \n",
      "...completed  73601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8031326643731322, \n",
      "\n",
      "                Current testing accuracy:  0.753 \n",
      "\n",
      "                Current testing loss:  0.8727226853370667 \n",
      " \n",
      "...completed  73729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8585205107993694, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  0.9640925526618958 \n",
      " \n",
      "...completed  73857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7969623031849928, \n",
      "\n",
      "                Current testing accuracy:  0.764 \n",
      "\n",
      "                Current testing loss:  0.7720213532447815 \n",
      " \n",
      "...completed  73985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.763045195882496, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.7276800274848938 \n",
      " \n",
      "...completed  74113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9307748372020512, \n",
      "\n",
      "                Current testing accuracy:  0.847 \n",
      "\n",
      "                Current testing loss:  0.528460681438446 \n",
      " \n",
      "...completed  74241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1755634513929145, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.7167219519615173 \n",
      " \n",
      "...completed  74369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7903550790511922, \n",
      "\n",
      "                Current testing accuracy:  0.714 \n",
      "\n",
      "                Current testing loss:  0.9453917145729065 \n",
      " \n",
      "...completed  74497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7952780285438621, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.8271337151527405 \n",
      " \n",
      "...completed  74625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.018999896952053, \n",
      "\n",
      "                Current testing accuracy:  0.83 \n",
      "\n",
      "                Current testing loss:  0.5933466553688049 \n",
      " \n",
      "...completed  74753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9588200634980026, \n",
      "\n",
      "                Current testing accuracy:  0.745 \n",
      "\n",
      "                Current testing loss:  0.8702905178070068 \n",
      " \n",
      "...completed  74881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9143158746681896, \n",
      "\n",
      "                Current testing accuracy:  0.697 \n",
      "\n",
      "                Current testing loss:  1.1671606302261353 \n",
      " \n",
      "...completed  75009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9157483956740009, \n",
      "\n",
      "                Current testing accuracy:  0.768 \n",
      "\n",
      "                Current testing loss:  0.7478788495063782 \n",
      " \n",
      "...completed  75137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8534305051087099, \n",
      "\n",
      "                Current testing accuracy:  0.839 \n",
      "\n",
      "                Current testing loss:  0.539107620716095 \n",
      " \n",
      "...completed  75265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1107539924538763, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.864585816860199 \n",
      " \n",
      "...completed  75393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1276798426097994, \n",
      "\n",
      "                Current testing accuracy:  0.734 \n",
      "\n",
      "                Current testing loss:  0.9341070055961609 \n",
      " \n",
      "...completed  75521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0145212008958637, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.8538548350334167 \n",
      " \n",
      "...completed  75649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7226230856808895, \n",
      "\n",
      "                Current testing accuracy:  0.831 \n",
      "\n",
      "                Current testing loss:  0.5858534574508667 \n",
      " \n",
      "...completed  75777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8537964600386552, \n",
      "\n",
      "                Current testing accuracy:  0.747 \n",
      "\n",
      "                Current testing loss:  0.8940877914428711 \n",
      " \n",
      "...completed  75905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7396304814559747, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  0.9017438888549805 \n",
      " \n",
      "...completed  76033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0533924091265776, \n",
      "\n",
      "                Current testing accuracy:  0.724 \n",
      "\n",
      "                Current testing loss:  1.1297820806503296 \n",
      " \n",
      "...completed  76161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8122406395400317, \n",
      "\n",
      "                Current testing accuracy:  0.787 \n",
      "\n",
      "                Current testing loss:  0.7138978242874146 \n",
      " \n",
      "...completed  76289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8537099507004449, \n",
      "\n",
      "                Current testing accuracy:  0.816 \n",
      "\n",
      "                Current testing loss:  0.6696931719779968 \n",
      " \n",
      "...completed  76417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8303307872585708, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.8213326334953308 \n",
      " \n",
      "...completed  76545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6433974606531185, \n",
      "\n",
      "                Current testing accuracy:  0.793 \n",
      "\n",
      "                Current testing loss:  0.7410157322883606 \n",
      " \n",
      "...completed  76673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9657872008473625, \n",
      "\n",
      "                Current testing accuracy:  0.622 \n",
      "\n",
      "                Current testing loss:  1.4339078664779663 \n",
      " \n",
      "...completed  76801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8238868433345079, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.8111767172813416 \n",
      " \n",
      "...completed  76929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3320163951330808, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.7262373566627502 \n",
      " \n",
      "...completed  77057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1459228033692739, \n",
      "\n",
      "                Current testing accuracy:  0.794 \n",
      "\n",
      "                Current testing loss:  0.742674708366394 \n",
      " \n",
      "...completed  77185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2306345496664333, \n",
      "\n",
      "                Current testing accuracy:  0.758 \n",
      "\n",
      "                Current testing loss:  0.8100016117095947 \n",
      " \n",
      "...completed  77313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9647294995792226, \n",
      "\n",
      "                Current testing accuracy:  0.768 \n",
      "\n",
      "                Current testing loss:  0.7776243090629578 \n",
      " \n",
      "...completed  77441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.757964061107856, \n",
      "\n",
      "                Current testing accuracy:  0.747 \n",
      "\n",
      "                Current testing loss:  0.8887828588485718 \n",
      " \n",
      "...completed  77569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9038585533246364, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.6685259938240051 \n",
      " \n",
      "...completed  77697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7541937691520069, \n",
      "\n",
      "                Current testing accuracy:  0.745 \n",
      "\n",
      "                Current testing loss:  0.8727393746376038 \n",
      " \n",
      "...completed  77825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8785014724214524, \n",
      "\n",
      "                Current testing accuracy:  0.744 \n",
      "\n",
      "                Current testing loss:  0.9189335703849792 \n",
      " \n",
      "...completed  77953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7783538653698476, \n",
      "\n",
      "                Current testing accuracy:  0.673 \n",
      "\n",
      "                Current testing loss:  1.2223923206329346 \n",
      " \n",
      "...completed  78081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0138965894364969, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.7705640196800232 \n",
      " \n",
      "...completed  78209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.894069515024337, \n",
      "\n",
      "                Current testing accuracy:  0.581 \n",
      "\n",
      "                Current testing loss:  1.7861038446426392 \n",
      " \n",
      "...completed  78337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0636188097600021, \n",
      "\n",
      "                Current testing accuracy:  0.76 \n",
      "\n",
      "                Current testing loss:  0.8984381556510925 \n",
      " \n",
      "...completed  78465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0316642640827234, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.8891847729682922 \n",
      " \n",
      "...completed  78593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1742998905628497, \n",
      "\n",
      "                Current testing accuracy:  0.853 \n",
      "\n",
      "                Current testing loss:  0.527514636516571 \n",
      " \n",
      "...completed  78721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9018691664591487, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.6544946432113647 \n",
      " \n",
      "...completed  78849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1193166552985083, \n",
      "\n",
      "                Current testing accuracy:  0.674 \n",
      "\n",
      "                Current testing loss:  1.2827401161193848 \n",
      " \n",
      "...completed  78977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9348562554239317, \n",
      "\n",
      "                Current testing accuracy:  0.713 \n",
      "\n",
      "                Current testing loss:  0.9611141085624695 \n",
      " \n",
      "...completed  79105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6143211136753752, \n",
      "\n",
      "                Current testing accuracy:  0.836 \n",
      "\n",
      "                Current testing loss:  0.571865439414978 \n",
      " \n",
      "...completed  79233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9568649942327285, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.634117066860199 \n",
      " \n",
      "...completed  79361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8083942954841845, \n",
      "\n",
      "                Current testing accuracy:  0.795 \n",
      "\n",
      "                Current testing loss:  0.7362484931945801 \n",
      " \n",
      "...completed  79489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7816844230580138, \n",
      "\n",
      "                Current testing accuracy:  0.812 \n",
      "\n",
      "                Current testing loss:  0.6674983501434326 \n",
      " \n",
      "...completed  79617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7208676650326176, \n",
      "\n",
      "                Current testing accuracy:  0.809 \n",
      "\n",
      "                Current testing loss:  0.6429346203804016 \n",
      " \n",
      "...completed  79745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7359322330410176, \n",
      "\n",
      "                Current testing accuracy:  0.809 \n",
      "\n",
      "                Current testing loss:  0.6879523396492004 \n",
      " \n",
      "...completed  79873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0862329110471585, \n",
      "\n",
      "                Current testing accuracy:  0.807 \n",
      "\n",
      "                Current testing loss:  0.8748161196708679 \n",
      " \n",
      "...completed  80001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7842158350249497, \n",
      "\n",
      "                Current testing accuracy:  0.679 \n",
      "\n",
      "                Current testing loss:  1.2661001682281494 \n",
      " \n",
      "...completed  80129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9347714470307125, \n",
      "\n",
      "                Current testing accuracy:  0.828 \n",
      "\n",
      "                Current testing loss:  0.6204622983932495 \n",
      " \n",
      "...completed  80257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8576576416507735, \n",
      "\n",
      "                Current testing accuracy:  0.811 \n",
      "\n",
      "                Current testing loss:  0.6937097311019897 \n",
      " \n",
      "...completed  80385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6670910146506637, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.7661820650100708 \n",
      " \n",
      "...completed  80513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9710264848630743, \n",
      "\n",
      "                Current testing accuracy:  0.692 \n",
      "\n",
      "                Current testing loss:  1.0610045194625854 \n",
      " \n",
      "...completed  80641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.010835883249644, \n",
      "\n",
      "                Current testing accuracy:  0.756 \n",
      "\n",
      "                Current testing loss:  0.9508906006813049 \n",
      " \n",
      "...completed  80769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.032844439185574, \n",
      "\n",
      "                Current testing accuracy:  0.835 \n",
      "\n",
      "                Current testing loss:  0.5757347345352173 \n",
      " \n",
      "...completed  80897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.84540964072478, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.9385790228843689 \n",
      " \n",
      "...completed  81025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9314643895960639, \n",
      "\n",
      "                Current testing accuracy:  0.85 \n",
      "\n",
      "                Current testing loss:  0.5550858378410339 \n",
      " \n",
      "...completed  81153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6859289181181865, \n",
      "\n",
      "                Current testing accuracy:  0.77 \n",
      "\n",
      "                Current testing loss:  0.8597941994667053 \n",
      " \n",
      "...completed  81281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7303138582434086, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.734775185585022 \n",
      " \n",
      "...completed  81409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0400144771310416, \n",
      "\n",
      "                Current testing accuracy:  0.864 \n",
      "\n",
      "                Current testing loss:  0.49503880739212036 \n",
      " \n",
      "...completed  81537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8311150668707352, \n",
      "\n",
      "                Current testing accuracy:  0.823 \n",
      "\n",
      "                Current testing loss:  0.6483028531074524 \n",
      " \n",
      "...completed  81665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7626842535001799, \n",
      "\n",
      "                Current testing accuracy:  0.732 \n",
      "\n",
      "                Current testing loss:  0.9744799733161926 \n",
      " \n",
      "...completed  81793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.20800989832934, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.7875213623046875 \n",
      " \n",
      "...completed  81921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7177088308965693, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.9306982159614563 \n",
      " \n",
      "...completed  82049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7879564974556619, \n",
      "\n",
      "                Current testing accuracy:  0.778 \n",
      "\n",
      "                Current testing loss:  0.7384822964668274 \n",
      " \n",
      "...completed  82177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.812347909547652, \n",
      "\n",
      "                Current testing accuracy:  0.737 \n",
      "\n",
      "                Current testing loss:  0.9280111193656921 \n",
      " \n",
      "...completed  82305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9269895502219683, \n",
      "\n",
      "                Current testing accuracy:  0.822 \n",
      "\n",
      "                Current testing loss:  0.6180033087730408 \n",
      " \n",
      "...completed  82433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7390866810843875, \n",
      "\n",
      "                Current testing accuracy:  0.727 \n",
      "\n",
      "                Current testing loss:  1.1917661428451538 \n",
      " \n",
      "...completed  82561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7770546377466374, \n",
      "\n",
      "                Current testing accuracy:  0.857 \n",
      "\n",
      "                Current testing loss:  0.5204423666000366 \n",
      " \n",
      "...completed  82689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8085966287337527, \n",
      "\n",
      "                Current testing accuracy:  0.823 \n",
      "\n",
      "                Current testing loss:  0.6394118666648865 \n",
      " \n",
      "...completed  82817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8375973935595029, \n",
      "\n",
      "                Current testing accuracy:  0.801 \n",
      "\n",
      "                Current testing loss:  0.6887353658676147 \n",
      " \n",
      "...completed  82945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8402781593525024, \n",
      "\n",
      "                Current testing accuracy:  0.771 \n",
      "\n",
      "                Current testing loss:  0.8194502592086792 \n",
      " \n",
      "...completed  83073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8849420913726185, \n",
      "\n",
      "                Current testing accuracy:  0.833 \n",
      "\n",
      "                Current testing loss:  0.5772004127502441 \n",
      " \n",
      "...completed  83201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.686814721811138, \n",
      "\n",
      "                Current testing accuracy:  0.703 \n",
      "\n",
      "                Current testing loss:  1.0710116624832153 \n",
      " \n",
      "...completed  83329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.746695734248707, \n",
      "\n",
      "                Current testing accuracy:  0.616 \n",
      "\n",
      "                Current testing loss:  1.4801868200302124 \n",
      " \n",
      "...completed  83457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7795363238053632, \n",
      "\n",
      "                Current testing accuracy:  0.754 \n",
      "\n",
      "                Current testing loss:  0.92681485414505 \n",
      " \n",
      "...completed  83585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8380952637310042, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.9791271686553955 \n",
      " \n",
      "...completed  83713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9942814880805457, \n",
      "\n",
      "                Current testing accuracy:  0.637 \n",
      "\n",
      "                Current testing loss:  1.4025657176971436 \n",
      " \n",
      "...completed  83841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8245827882786951, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.7035980820655823 \n",
      " \n",
      "...completed  83969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.774425584899701, \n",
      "\n",
      "                Current testing accuracy:  0.794 \n",
      "\n",
      "                Current testing loss:  0.7477392554283142 \n",
      " \n",
      "...completed  84097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6517564266829723, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.787837564945221 \n",
      " \n",
      "...completed  84225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8857003274236699, \n",
      "\n",
      "                Current testing accuracy:  0.728 \n",
      "\n",
      "                Current testing loss:  1.0101619958877563 \n",
      " \n",
      "...completed  84353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9490667965968522, \n",
      "\n",
      "                Current testing accuracy:  0.731 \n",
      "\n",
      "                Current testing loss:  0.9169742465019226 \n",
      " \n",
      "...completed  84481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8823668271641072, \n",
      "\n",
      "                Current testing accuracy:  0.74 \n",
      "\n",
      "                Current testing loss:  0.88286954164505 \n",
      " \n",
      "...completed  84609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0092281888029948, \n",
      "\n",
      "                Current testing accuracy:  0.725 \n",
      "\n",
      "                Current testing loss:  1.134232997894287 \n",
      " \n",
      "...completed  84737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2277669373714684, \n",
      "\n",
      "                Current testing accuracy:  0.708 \n",
      "\n",
      "                Current testing loss:  1.3236743211746216 \n",
      " \n",
      "...completed  84865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0368914366431472, \n",
      "\n",
      "                Current testing accuracy:  0.709 \n",
      "\n",
      "                Current testing loss:  0.9570392370223999 \n",
      " \n",
      "...completed  84993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7419836064594536, \n",
      "\n",
      "                Current testing accuracy:  0.809 \n",
      "\n",
      "                Current testing loss:  0.6854341626167297 \n",
      " \n",
      "...completed  85121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0801915223982093, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.9328420758247375 \n",
      " \n",
      "...completed  85249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9395878617302147, \n",
      "\n",
      "                Current testing accuracy:  0.785 \n",
      "\n",
      "                Current testing loss:  0.7521151304244995 \n",
      " \n",
      "...completed  85377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.727779348731044, \n",
      "\n",
      "                Current testing accuracy:  0.744 \n",
      "\n",
      "                Current testing loss:  0.9010125398635864 \n",
      " \n",
      "...completed  85505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7404333455284071, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  0.8969497680664062 \n",
      " \n",
      "...completed  85633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5630332115107408, \n",
      "\n",
      "                Current testing accuracy:  0.827 \n",
      "\n",
      "                Current testing loss:  0.5948296189308167 \n",
      " \n",
      "...completed  85761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1864198783668891, \n",
      "\n",
      "                Current testing accuracy:  0.652 \n",
      "\n",
      "                Current testing loss:  1.319413661956787 \n",
      " \n",
      "...completed  85889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9040375476354665, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.9556131958961487 \n",
      " \n",
      "...completed  86017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0353152355010522, \n",
      "\n",
      "                Current testing accuracy:  0.812 \n",
      "\n",
      "                Current testing loss:  0.6662687659263611 \n",
      " \n",
      "...completed  86145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.802138381613952, \n",
      "\n",
      "                Current testing accuracy:  0.821 \n",
      "\n",
      "                Current testing loss:  0.5824490785598755 \n",
      " \n",
      "...completed  86273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6507336885760573, \n",
      "\n",
      "                Current testing accuracy:  0.728 \n",
      "\n",
      "                Current testing loss:  0.9499982595443726 \n",
      " \n",
      "...completed  86401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5690883184452389, \n",
      "\n",
      "                Current testing accuracy:  0.84 \n",
      "\n",
      "                Current testing loss:  0.5859072804450989 \n",
      " \n",
      "...completed  86529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7833970048566457, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.8012308478355408 \n",
      " \n",
      "...completed  86657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6134820100689877, \n",
      "\n",
      "                Current testing accuracy:  0.711 \n",
      "\n",
      "                Current testing loss:  1.0862654447555542 \n",
      " \n",
      "...completed  86785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7904215898482918, \n",
      "\n",
      "                Current testing accuracy:  0.808 \n",
      "\n",
      "                Current testing loss:  0.6858255863189697 \n",
      " \n",
      "...completed  86913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7424312714837265, \n",
      "\n",
      "                Current testing accuracy:  0.762 \n",
      "\n",
      "                Current testing loss:  0.8573140501976013 \n",
      " \n",
      "...completed  87041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0224923907687753, \n",
      "\n",
      "                Current testing accuracy:  0.842 \n",
      "\n",
      "                Current testing loss:  0.5496655106544495 \n",
      " \n",
      "...completed  87169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1215130489962806, \n",
      "\n",
      "                Current testing accuracy:  0.689 \n",
      "\n",
      "                Current testing loss:  1.1909677982330322 \n",
      " \n",
      "...completed  87297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9568567568735844, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.8733054399490356 \n",
      " \n",
      "...completed  87425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9026286303141102, \n",
      "\n",
      "                Current testing accuracy:  0.712 \n",
      "\n",
      "                Current testing loss:  1.1612061262130737 \n",
      " \n",
      "...completed  87553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7114898676086356, \n",
      "\n",
      "                Current testing accuracy:  0.829 \n",
      "\n",
      "                Current testing loss:  0.6241054534912109 \n",
      " \n",
      "...completed  87681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5319087922391983, \n",
      "\n",
      "                Current testing accuracy:  0.808 \n",
      "\n",
      "                Current testing loss:  0.6416363716125488 \n",
      " \n",
      "...completed  87809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0782473126869405, \n",
      "\n",
      "                Current testing accuracy:  0.709 \n",
      "\n",
      "                Current testing loss:  1.1001126766204834 \n",
      " \n",
      "...completed  87937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9894813080611549, \n",
      "\n",
      "                Current testing accuracy:  0.863 \n",
      "\n",
      "                Current testing loss:  0.4984540045261383 \n",
      " \n",
      "...completed  88065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9749151949468575, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  1.0652384757995605 \n",
      " \n",
      "...completed  88193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9821774749900527, \n",
      "\n",
      "                Current testing accuracy:  0.71 \n",
      "\n",
      "                Current testing loss:  1.116505742073059 \n",
      " \n",
      "...completed  88321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6294509475489107, \n",
      "\n",
      "                Current testing accuracy:  0.858 \n",
      "\n",
      "                Current testing loss:  0.5462164282798767 \n",
      " \n",
      "...completed  88449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8913766825121243, \n",
      "\n",
      "                Current testing accuracy:  0.826 \n",
      "\n",
      "                Current testing loss:  0.6369022727012634 \n",
      " \n",
      "...completed  88577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.844233464196676, \n",
      "\n",
      "                Current testing accuracy:  0.834 \n",
      "\n",
      "                Current testing loss:  0.6113761067390442 \n",
      " \n",
      "...completed  88705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8629449685415924, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.713947594165802 \n",
      " \n",
      "...completed  88833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8878185057902002, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.9004521369934082 \n",
      " \n",
      "...completed  88961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8143700548419304, \n",
      "\n",
      "                Current testing accuracy:  0.79 \n",
      "\n",
      "                Current testing loss:  0.7442865967750549 \n",
      " \n",
      "...completed  89089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6921856125554786, \n",
      "\n",
      "                Current testing accuracy:  0.829 \n",
      "\n",
      "                Current testing loss:  0.5878925919532776 \n",
      " \n",
      "...completed  89217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.709618893078634, \n",
      "\n",
      "                Current testing accuracy:  0.847 \n",
      "\n",
      "                Current testing loss:  0.5525490045547485 \n",
      " \n",
      "...completed  89345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.957568992912829, \n",
      "\n",
      "                Current testing accuracy:  0.731 \n",
      "\n",
      "                Current testing loss:  0.9024259448051453 \n",
      " \n",
      "...completed  89473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8539697575294731, \n",
      "\n",
      "                Current testing accuracy:  0.736 \n",
      "\n",
      "                Current testing loss:  0.9735482931137085 \n",
      " \n",
      "...completed  89601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0465890326014602, \n",
      "\n",
      "                Current testing accuracy:  0.796 \n",
      "\n",
      "                Current testing loss:  0.8325133323669434 \n",
      " \n",
      "...completed  89729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7774940335700213, \n",
      "\n",
      "                Current testing accuracy:  0.865 \n",
      "\n",
      "                Current testing loss:  0.5014492869377136 \n",
      " \n",
      "...completed  89857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7971823931470468, \n",
      "\n",
      "                Current testing accuracy:  0.829 \n",
      "\n",
      "                Current testing loss:  0.6138694882392883 \n",
      " \n",
      "...completed  89985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8290402796809317, \n",
      "\n",
      "                Current testing accuracy:  0.8 \n",
      "\n",
      "                Current testing loss:  0.7072893381118774 \n",
      " \n",
      "...completed  90113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9997380315939854, \n",
      "\n",
      "                Current testing accuracy:  0.784 \n",
      "\n",
      "                Current testing loss:  0.7790924310684204 \n",
      " \n",
      "...completed  90241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6864435712009573, \n",
      "\n",
      "                Current testing accuracy:  0.702 \n",
      "\n",
      "                Current testing loss:  1.2826496362686157 \n",
      " \n",
      "...completed  90369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6523896994010272, \n",
      "\n",
      "                Current testing accuracy:  0.787 \n",
      "\n",
      "                Current testing loss:  0.7359509468078613 \n",
      " \n",
      "...completed  90497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2194290376766224, \n",
      "\n",
      "                Current testing accuracy:  0.822 \n",
      "\n",
      "                Current testing loss:  0.6285455226898193 \n",
      " \n",
      "...completed  90625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9019262148475384, \n",
      "\n",
      "                Current testing accuracy:  0.799 \n",
      "\n",
      "                Current testing loss:  0.7266650795936584 \n",
      " \n",
      "...completed  90753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8613200749524008, \n",
      "\n",
      "                Current testing accuracy:  0.82 \n",
      "\n",
      "                Current testing loss:  0.6900481581687927 \n",
      " \n",
      "...completed  90881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9802308782558793, \n",
      "\n",
      "                Current testing accuracy:  0.823 \n",
      "\n",
      "                Current testing loss:  0.5985664129257202 \n",
      " \n",
      "...completed  91009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0521302410280242, \n",
      "\n",
      "                Current testing accuracy:  0.761 \n",
      "\n",
      "                Current testing loss:  0.8837382197380066 \n",
      " \n",
      "...completed  91137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0123975782767012, \n",
      "\n",
      "                Current testing accuracy:  0.737 \n",
      "\n",
      "                Current testing loss:  1.2801166772842407 \n",
      " \n",
      "...completed  91265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.744504010520675, \n",
      "\n",
      "                Current testing accuracy:  0.796 \n",
      "\n",
      "                Current testing loss:  0.6532282829284668 \n",
      " \n",
      "...completed  91393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6936996094802543, \n",
      "\n",
      "                Current testing accuracy:  0.835 \n",
      "\n",
      "                Current testing loss:  0.5378590226173401 \n",
      " \n",
      "...completed  91521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0502620667435998, \n",
      "\n",
      "                Current testing accuracy:  0.732 \n",
      "\n",
      "                Current testing loss:  0.9317607283592224 \n",
      " \n",
      "...completed  91649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6553864066536361, \n",
      "\n",
      "                Current testing accuracy:  0.779 \n",
      "\n",
      "                Current testing loss:  0.7626562714576721 \n",
      " \n",
      "...completed  91777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6904204309734199, \n",
      "\n",
      "                Current testing accuracy:  0.788 \n",
      "\n",
      "                Current testing loss:  0.8320889472961426 \n",
      " \n",
      "...completed  91905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8087213640377158, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.7349851131439209 \n",
      " \n",
      "...completed  92033  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8348670710527486, \n",
      "\n",
      "                Current testing accuracy:  0.843 \n",
      "\n",
      "                Current testing loss:  0.5523156523704529 \n",
      " \n",
      "...completed  92161  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7688627508453703, \n",
      "\n",
      "                Current testing accuracy:  0.783 \n",
      "\n",
      "                Current testing loss:  0.8406018614768982 \n",
      " \n",
      "...completed  92289  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7167241513484823, \n",
      "\n",
      "                Current testing accuracy:  0.759 \n",
      "\n",
      "                Current testing loss:  0.926277220249176 \n",
      " \n",
      "...completed  92417  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.717940838908163, \n",
      "\n",
      "                Current testing accuracy:  0.717 \n",
      "\n",
      "                Current testing loss:  1.0181734561920166 \n",
      " \n",
      "...completed  92545  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7671623845710727, \n",
      "\n",
      "                Current testing accuracy:  0.713 \n",
      "\n",
      "                Current testing loss:  1.1293591260910034 \n",
      " \n",
      "...completed  92673  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9383527040350828, \n",
      "\n",
      "                Current testing accuracy:  0.788 \n",
      "\n",
      "                Current testing loss:  0.7443831562995911 \n",
      " \n",
      "...completed  92801  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7490717587842433, \n",
      "\n",
      "                Current testing accuracy:  0.791 \n",
      "\n",
      "                Current testing loss:  0.7302169799804688 \n",
      " \n",
      "...completed  92929  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0012528865381771, \n",
      "\n",
      "                Current testing accuracy:  0.769 \n",
      "\n",
      "                Current testing loss:  0.8037063479423523 \n",
      " \n",
      "...completed  93057  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5057582837824195, \n",
      "\n",
      "                Current testing accuracy:  0.805 \n",
      "\n",
      "                Current testing loss:  0.6868056058883667 \n",
      " \n",
      "...completed  93185  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0470324107289244, \n",
      "\n",
      "                Current testing accuracy:  0.744 \n",
      "\n",
      "                Current testing loss:  0.8938314318656921 \n",
      " \n",
      "...completed  93313  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3399795556752003, \n",
      "\n",
      "                Current testing accuracy:  0.839 \n",
      "\n",
      "                Current testing loss:  0.5389965176582336 \n",
      " \n",
      "...completed  93441  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.537323237486651, \n",
      "\n",
      "                Current testing accuracy:  0.67 \n",
      "\n",
      "                Current testing loss:  1.2564878463745117 \n",
      " \n",
      "...completed  93569  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6668355124393175, \n",
      "\n",
      "                Current testing accuracy:  0.822 \n",
      "\n",
      "                Current testing loss:  0.5972696542739868 \n",
      " \n",
      "...completed  93697  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.289415424659957, \n",
      "\n",
      "                Current testing accuracy:  0.8 \n",
      "\n",
      "                Current testing loss:  0.7630860209465027 \n",
      " \n",
      "...completed  93825  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1269348752345998, \n",
      "\n",
      "                Current testing accuracy:  0.764 \n",
      "\n",
      "                Current testing loss:  0.9466816186904907 \n",
      " \n",
      "...completed  93953  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7019954095789012, \n",
      "\n",
      "                Current testing accuracy:  0.841 \n",
      "\n",
      "                Current testing loss:  0.5666266083717346 \n",
      " \n",
      "...completed  94081  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.08600247305624, \n",
      "\n",
      "                Current testing accuracy:  0.746 \n",
      "\n",
      "                Current testing loss:  0.9569931030273438 \n",
      " \n",
      "...completed  94209  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9563550984759885, \n",
      "\n",
      "                Current testing accuracy:  0.834 \n",
      "\n",
      "                Current testing loss:  0.5901427865028381 \n",
      " \n",
      "...completed  94337  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5349582492117761, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.8349343538284302 \n",
      " \n",
      "...completed  94465  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8766619563036586, \n",
      "\n",
      "                Current testing accuracy:  0.808 \n",
      "\n",
      "                Current testing loss:  0.654521107673645 \n",
      " \n",
      "...completed  94593  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8036688678267749, \n",
      "\n",
      "                Current testing accuracy:  0.744 \n",
      "\n",
      "                Current testing loss:  1.002732515335083 \n",
      " \n",
      "...completed  94721  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.823784484726998, \n",
      "\n",
      "                Current testing accuracy:  0.866 \n",
      "\n",
      "                Current testing loss:  0.5015421509742737 \n",
      " \n",
      "...completed  94849  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9731731406314355, \n",
      "\n",
      "                Current testing accuracy:  0.819 \n",
      "\n",
      "                Current testing loss:  0.6543247103691101 \n",
      " \n",
      "...completed  94977  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9227742447485454, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  0.9477071762084961 \n",
      " \n",
      "...completed  95105  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8209523564947387, \n",
      "\n",
      "                Current testing accuracy:  0.721 \n",
      "\n",
      "                Current testing loss:  1.0403072834014893 \n",
      " \n",
      "...completed  95233  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6920323140468518, \n",
      "\n",
      "                Current testing accuracy:  0.78 \n",
      "\n",
      "                Current testing loss:  0.8033467531204224 \n",
      " \n",
      "...completed  95361  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8759142159684943, \n",
      "\n",
      "                Current testing accuracy:  0.777 \n",
      "\n",
      "                Current testing loss:  0.8269397616386414 \n",
      " \n",
      "...completed  95489  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8647635740062185, \n",
      "\n",
      "                Current testing accuracy:  0.852 \n",
      "\n",
      "                Current testing loss:  0.5321516394615173 \n",
      " \n",
      "...completed  95617  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6989862563867675, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  0.8766629695892334 \n",
      " \n",
      "...completed  95745  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1537929041265915, \n",
      "\n",
      "                Current testing accuracy:  0.84 \n",
      "\n",
      "                Current testing loss:  0.5917333960533142 \n",
      " \n",
      "...completed  95873  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7548071468782735, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  1.0928186178207397 \n",
      " \n",
      "...completed  96001  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2498494663788584, \n",
      "\n",
      "                Current testing accuracy:  0.8 \n",
      "\n",
      "                Current testing loss:  0.6815310716629028 \n",
      " \n",
      "...completed  96129  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7354100719980661, \n",
      "\n",
      "                Current testing accuracy:  0.854 \n",
      "\n",
      "                Current testing loss:  0.5352759957313538 \n",
      " \n",
      "...completed  96257  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8494755918757844, \n",
      "\n",
      "                Current testing accuracy:  0.815 \n",
      "\n",
      "                Current testing loss:  0.755562961101532 \n",
      " \n",
      "...completed  96385  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8480337656530144, \n",
      "\n",
      "                Current testing accuracy:  0.785 \n",
      "\n",
      "                Current testing loss:  0.8212080597877502 \n",
      " \n",
      "...completed  96513  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5309495889853224, \n",
      "\n",
      "                Current testing accuracy:  0.833 \n",
      "\n",
      "                Current testing loss:  0.5977705121040344 \n",
      " \n",
      "...completed  96641  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0710673460612092, \n",
      "\n",
      "                Current testing accuracy:  0.799 \n",
      "\n",
      "                Current testing loss:  0.7088912725448608 \n",
      " \n",
      "...completed  96769  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7715380886491373, \n",
      "\n",
      "                Current testing accuracy:  0.698 \n",
      "\n",
      "                Current testing loss:  1.1027685403823853 \n",
      " \n",
      "...completed  96897  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8417646684864799, \n",
      "\n",
      "                Current testing accuracy:  0.851 \n",
      "\n",
      "                Current testing loss:  0.518566906452179 \n",
      " \n",
      "...completed  97025  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1553584897176084, \n",
      "\n",
      "                Current testing accuracy:  0.712 \n",
      "\n",
      "                Current testing loss:  1.1075881719589233 \n",
      " \n",
      "...completed  97153  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9755138326723554, \n",
      "\n",
      "                Current testing accuracy:  0.804 \n",
      "\n",
      "                Current testing loss:  0.6997723579406738 \n",
      " \n",
      "...completed  97281  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8606614610791752, \n",
      "\n",
      "                Current testing accuracy:  0.743 \n",
      "\n",
      "                Current testing loss:  1.0009735822677612 \n",
      " \n",
      "...completed  97409  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9185889974636394, \n",
      "\n",
      "                Current testing accuracy:  0.839 \n",
      "\n",
      "                Current testing loss:  0.5986316204071045 \n",
      " \n",
      "...completed  97537  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5381492424853969, \n",
      "\n",
      "                Current testing accuracy:  0.808 \n",
      "\n",
      "                Current testing loss:  0.6886195540428162 \n",
      " \n",
      "...completed  97665  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.928557077719482, \n",
      "\n",
      "                Current testing accuracy:  0.778 \n",
      "\n",
      "                Current testing loss:  0.7777791023254395 \n",
      " \n",
      "...completed  97793  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7759419730404709, \n",
      "\n",
      "                Current testing accuracy:  0.742 \n",
      "\n",
      "                Current testing loss:  1.0033262968063354 \n",
      " \n",
      "...completed  97921  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1120432931201671, \n",
      "\n",
      "                Current testing accuracy:  0.836 \n",
      "\n",
      "                Current testing loss:  0.573331892490387 \n",
      " \n",
      "...completed  98049  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7537586832681975, \n",
      "\n",
      "                Current testing accuracy:  0.767 \n",
      "\n",
      "                Current testing loss:  0.8613120913505554 \n",
      " \n",
      "...completed  98177  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7629212313023133, \n",
      "\n",
      "                Current testing accuracy:  0.769 \n",
      "\n",
      "                Current testing loss:  0.8698651790618896 \n",
      " \n",
      "...completed  98305  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5161461876399487, \n",
      "\n",
      "                Current testing accuracy:  0.84 \n",
      "\n",
      "                Current testing loss:  0.6073365211486816 \n",
      " \n",
      "...completed  98433  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8272642451488676, \n",
      "\n",
      "                Current testing accuracy:  0.668 \n",
      "\n",
      "                Current testing loss:  1.4168747663497925 \n",
      " \n",
      "...completed  98561  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6457138563814624, \n",
      "\n",
      "                Current testing accuracy:  0.681 \n",
      "\n",
      "                Current testing loss:  1.3663043975830078 \n",
      " \n",
      "...completed  98689  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1541563214148851, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.8466248512268066 \n",
      " \n",
      "...completed  98817  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9503556677637808, \n",
      "\n",
      "                Current testing accuracy:  0.837 \n",
      "\n",
      "                Current testing loss:  0.5843237042427063 \n",
      " \n",
      "...completed  98945  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8272274638569995, \n",
      "\n",
      "                Current testing accuracy:  0.833 \n",
      "\n",
      "                Current testing loss:  0.6481008529663086 \n",
      " \n",
      "...completed  99073  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8043988632654866, \n",
      "\n",
      "                Current testing accuracy:  0.768 \n",
      "\n",
      "                Current testing loss:  0.9140938520431519 \n",
      " \n",
      "...completed  99201  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7798911812316511, \n",
      "\n",
      "                Current testing accuracy:  0.797 \n",
      "\n",
      "                Current testing loss:  0.8005274534225464 \n",
      " \n",
      "...completed  99329  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9207094784035306, \n",
      "\n",
      "                Current testing accuracy:  0.823 \n",
      "\n",
      "                Current testing loss:  0.6172895431518555 \n",
      " \n",
      "...completed  99457  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8512383486656594, \n",
      "\n",
      "                Current testing accuracy:  0.817 \n",
      "\n",
      "                Current testing loss:  0.6363763213157654 \n",
      " \n",
      "...completed  99585  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6408971230031246, \n",
      "\n",
      "                Current testing accuracy:  0.729 \n",
      "\n",
      "                Current testing loss:  1.0450260639190674 \n",
      " \n",
      "...completed  99713  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7386697773187176, \n",
      "\n",
      "                Current testing accuracy:  0.822 \n",
      "\n",
      "                Current testing loss:  0.6036171317100525 \n",
      " \n",
      "...completed  99841  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7703039258470774, \n",
      "\n",
      "                Current testing accuracy:  0.817 \n",
      "\n",
      "                Current testing loss:  0.6282764077186584 \n",
      " \n",
      "...completed  99969  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0110290235118242, \n",
      "\n",
      "                Current testing accuracy:  0.737 \n",
      "\n",
      "                Current testing loss:  1.0864999294281006 \n",
      " \n",
      "...completed  100097  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7991505661608027, \n",
      "\n",
      "                Current testing accuracy:  0.833 \n",
      "\n",
      "                Current testing loss:  0.644790768623352 \n",
      " \n",
      "...completed  100225  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7125883996511178, \n",
      "\n",
      "                Current testing accuracy:  0.707 \n",
      "\n",
      "                Current testing loss:  1.1211810111999512 \n",
      " \n",
      "...completed  100353  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8055025277451073, \n",
      "\n",
      "                Current testing accuracy:  0.765 \n",
      "\n",
      "                Current testing loss:  0.8410617113113403 \n",
      " \n",
      "...completed  100481  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6374955157379381, \n",
      "\n",
      "                Current testing accuracy:  0.845 \n",
      "\n",
      "                Current testing loss:  0.5685759782791138 \n",
      " \n",
      "...completed  100609  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7852967373283288, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.840076208114624 \n",
      " \n",
      "...completed  100737  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1415032202930355, \n",
      "\n",
      "                Current testing accuracy:  0.757 \n",
      "\n",
      "                Current testing loss:  0.9034379124641418 \n",
      " \n",
      "...completed  100865  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.880197062299878, \n",
      "\n",
      "                Current testing accuracy:  0.665 \n",
      "\n",
      "                Current testing loss:  1.400475025177002 \n",
      " \n",
      "...completed  100993  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0008812156504374, \n",
      "\n",
      "                Current testing accuracy:  0.846 \n",
      "\n",
      "                Current testing loss:  0.5530051589012146 \n",
      " \n",
      "...completed  101121  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7261038796404318, \n",
      "\n",
      "                Current testing accuracy:  0.843 \n",
      "\n",
      "                Current testing loss:  0.5558565855026245 \n",
      " \n",
      "...completed  101249  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.2044080046367585, \n",
      "\n",
      "                Current testing accuracy:  0.78 \n",
      "\n",
      "                Current testing loss:  0.8261319398880005 \n",
      " \n",
      "...completed  101377  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7987979619594627, \n",
      "\n",
      "                Current testing accuracy:  0.822 \n",
      "\n",
      "                Current testing loss:  0.5879433751106262 \n",
      " \n",
      "...completed  101505  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6640395218442863, \n",
      "\n",
      "                Current testing accuracy:  0.833 \n",
      "\n",
      "                Current testing loss:  0.6324344873428345 \n",
      " \n",
      "...completed  101633  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7330619427657954, \n",
      "\n",
      "                Current testing accuracy:  0.83 \n",
      "\n",
      "                Current testing loss:  0.5731832385063171 \n",
      " \n",
      "...completed  101761  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8406053599983707, \n",
      "\n",
      "                Current testing accuracy:  0.732 \n",
      "\n",
      "                Current testing loss:  1.0763051509857178 \n",
      " \n",
      "...completed  101889  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8664016861204125, \n",
      "\n",
      "                Current testing accuracy:  0.817 \n",
      "\n",
      "                Current testing loss:  0.7044426202774048 \n",
      " \n",
      "...completed  102017  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8599049984909966, \n",
      "\n",
      "                Current testing accuracy:  0.81 \n",
      "\n",
      "                Current testing loss:  0.6898457407951355 \n",
      " \n",
      "...completed  102145  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6250779139821692, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.9330876469612122 \n",
      " \n",
      "...completed  102273  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8158156150926175, \n",
      "\n",
      "                Current testing accuracy:  0.73 \n",
      "\n",
      "                Current testing loss:  1.0427076816558838 \n",
      " \n",
      "...completed  102401  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7110486126798232, \n",
      "\n",
      "                Current testing accuracy:  0.844 \n",
      "\n",
      "                Current testing loss:  0.5761827826499939 \n",
      " \n",
      "...completed  102529  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7376647371742402, \n",
      "\n",
      "                Current testing accuracy:  0.828 \n",
      "\n",
      "                Current testing loss:  0.6510889530181885 \n",
      " \n",
      "...completed  102657  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7236722234771875, \n",
      "\n",
      "                Current testing accuracy:  0.83 \n",
      "\n",
      "                Current testing loss:  0.5976999998092651 \n",
      " \n",
      "...completed  102785  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8601093913462545, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.8377633094787598 \n",
      " \n",
      "...completed  102913  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7278098425833193, \n",
      "\n",
      "                Current testing accuracy:  0.766 \n",
      "\n",
      "                Current testing loss:  0.9529487490653992 \n",
      " \n",
      "...completed  103041  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7451609755805173, \n",
      "\n",
      "                Current testing accuracy:  0.848 \n",
      "\n",
      "                Current testing loss:  0.5331307649612427 \n",
      " \n",
      "...completed  103169  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6354546777978114, \n",
      "\n",
      "                Current testing accuracy:  0.836 \n",
      "\n",
      "                Current testing loss:  0.6245230436325073 \n",
      " \n",
      "...completed  103297  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.896918874640656, \n",
      "\n",
      "                Current testing accuracy:  0.701 \n",
      "\n",
      "                Current testing loss:  1.1278254985809326 \n",
      " \n",
      "...completed  103425  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.214163853195363, \n",
      "\n",
      "                Current testing accuracy:  0.679 \n",
      "\n",
      "                Current testing loss:  0.990287721157074 \n",
      " \n",
      "...completed  103553  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6980100231279125, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.6883306503295898 \n",
      " \n",
      "...completed  103681  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7740784444712645, \n",
      "\n",
      "                Current testing accuracy:  0.734 \n",
      "\n",
      "                Current testing loss:  1.0296626091003418 \n",
      " \n",
      "...completed  103809  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0387461023937643, \n",
      "\n",
      "                Current testing accuracy:  0.775 \n",
      "\n",
      "                Current testing loss:  0.8707095980644226 \n",
      " \n",
      "...completed  103937  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8520022934171525, \n",
      "\n",
      "                Current testing accuracy:  0.793 \n",
      "\n",
      "                Current testing loss:  0.7691105008125305 \n",
      " \n",
      "...completed  104065  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9762626822137381, \n",
      "\n",
      "                Current testing accuracy:  0.748 \n",
      "\n",
      "                Current testing loss:  0.9577921032905579 \n",
      " \n",
      "...completed  104193  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6577135173646451, \n",
      "\n",
      "                Current testing accuracy:  0.745 \n",
      "\n",
      "                Current testing loss:  0.8924260139465332 \n",
      " \n",
      "...completed  104321  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.878415753350831, \n",
      "\n",
      "                Current testing accuracy:  0.804 \n",
      "\n",
      "                Current testing loss:  0.7507867217063904 \n",
      " \n",
      "...completed  104449  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8098103225728615, \n",
      "\n",
      "                Current testing accuracy:  0.826 \n",
      "\n",
      "                Current testing loss:  0.5830265879631042 \n",
      " \n",
      "...completed  104577  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6479618666416829, \n",
      "\n",
      "                Current testing accuracy:  0.755 \n",
      "\n",
      "                Current testing loss:  0.8443983197212219 \n",
      " \n",
      "...completed  104705  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8776083706884534, \n",
      "\n",
      "                Current testing accuracy:  0.722 \n",
      "\n",
      "                Current testing loss:  0.9442381262779236 \n",
      " \n",
      "...completed  104833  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.5922287989766204, \n",
      "\n",
      "                Current testing accuracy:  0.673 \n",
      "\n",
      "                Current testing loss:  1.1283156871795654 \n",
      " \n",
      "...completed  104961  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8067008286577861, \n",
      "\n",
      "                Current testing accuracy:  0.79 \n",
      "\n",
      "                Current testing loss:  0.7352458238601685 \n",
      " \n",
      "...completed  105089  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0513451086846821, \n",
      "\n",
      "                Current testing accuracy:  0.82 \n",
      "\n",
      "                Current testing loss:  0.6419162750244141 \n",
      " \n",
      "...completed  105217  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7167704416315814, \n",
      "\n",
      "                Current testing accuracy:  0.772 \n",
      "\n",
      "                Current testing loss:  0.840684711933136 \n",
      " \n",
      "...completed  105345  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8632784547751642, \n",
      "\n",
      "                Current testing accuracy:  0.741 \n",
      "\n",
      "                Current testing loss:  0.9302315711975098 \n",
      " \n",
      "...completed  105473  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8711006260848637, \n",
      "\n",
      "                Current testing accuracy:  0.812 \n",
      "\n",
      "                Current testing loss:  0.6834733486175537 \n",
      " \n",
      "...completed  105601  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9379400115239542, \n",
      "\n",
      "                Current testing accuracy:  0.764 \n",
      "\n",
      "                Current testing loss:  0.8443506956100464 \n",
      " \n",
      "...completed  105729  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1472578280365637, \n",
      "\n",
      "                Current testing accuracy:  0.7 \n",
      "\n",
      "                Current testing loss:  1.3685002326965332 \n",
      " \n",
      "...completed  105857  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8107630639999357, \n",
      "\n",
      "                Current testing accuracy:  0.72 \n",
      "\n",
      "                Current testing loss:  1.164734125137329 \n",
      " \n",
      "...completed  105985  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8680575711265328, \n",
      "\n",
      "                Current testing accuracy:  0.791 \n",
      "\n",
      "                Current testing loss:  0.7212981581687927 \n",
      " \n",
      "...completed  106113  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9613359141302595, \n",
      "\n",
      "                Current testing accuracy:  0.789 \n",
      "\n",
      "                Current testing loss:  0.8420328497886658 \n",
      " \n",
      "...completed  106241  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8799797725828036, \n",
      "\n",
      "                Current testing accuracy:  0.786 \n",
      "\n",
      "                Current testing loss:  0.8523220419883728 \n",
      " \n",
      "...completed  106369  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0052714271764847, \n",
      "\n",
      "                Current testing accuracy:  0.776 \n",
      "\n",
      "                Current testing loss:  0.8003868460655212 \n",
      " \n",
      "...completed  106497  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.1373855988661834, \n",
      "\n",
      "                Current testing accuracy:  0.802 \n",
      "\n",
      "                Current testing loss:  0.6760338544845581 \n",
      " \n",
      "...completed  106625  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.3296235633674742, \n",
      "\n",
      "                Current testing accuracy:  0.802 \n",
      "\n",
      "                Current testing loss:  0.7074371576309204 \n",
      " \n",
      "...completed  106753  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8830447024229808, \n",
      "\n",
      "                Current testing accuracy:  0.778 \n",
      "\n",
      "                Current testing loss:  0.8092398047447205 \n",
      " \n",
      "...completed  106881  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7611300895915818, \n",
      "\n",
      "                Current testing accuracy:  0.824 \n",
      "\n",
      "                Current testing loss:  0.6180089116096497 \n",
      " \n",
      "...completed  107009  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7515347566931996, \n",
      "\n",
      "                Current testing accuracy:  0.803 \n",
      "\n",
      "                Current testing loss:  0.7164696455001831 \n",
      " \n",
      "...completed  107137  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.7682884682536422, \n",
      "\n",
      "                Current testing accuracy:  0.658 \n",
      "\n",
      "                Current testing loss:  1.7896870374679565 \n",
      " \n",
      "...completed  107265  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.9336781004190442, \n",
      "\n",
      "                Current testing accuracy:  0.841 \n",
      "\n",
      "                Current testing loss:  0.5904838442802429 \n",
      " \n",
      "...completed  107393  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.6940826540357348, \n",
      "\n",
      "                Current testing accuracy:  0.806 \n",
      "\n",
      "                Current testing loss:  0.8417122960090637 \n",
      " \n",
      "...completed  107521  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  1.0733066243027944, \n",
      "\n",
      "                Current testing accuracy:  0.7 \n",
      "\n",
      "                Current testing loss:  1.0828579664230347 \n",
      " \n",
      "...completed  107649  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.8688241976600417, \n",
      "\n",
      "                Current testing accuracy:  0.79 \n",
      "\n",
      "                Current testing loss:  0.7020519375801086 \n",
      " \n",
      "...completed  107777  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.735490909220637, \n",
      "\n",
      "                Current testing accuracy:  0.827 \n",
      "\n",
      "                Current testing loss:  0.6127563714981079 \n",
      " \n",
      "...completed  107905  iterations of training. \n",
      "\n",
      "                Current training cross_entropy loss:  0.45164653984762104, \n",
      "\n",
      "                Current testing accuracy:  0.778 \n",
      "\n",
      "                Current testing loss:  0.8099610805511475 \n",
      " \n",
      "...Converge at 107905 iterations of training.\n"
     ]
    }
   ],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "netffa_online = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_online_ce, test_loss_ffa_online_ce, \n",
    " losses_ffa_online_mse, test_loss_ffa_online_mse,\n",
    " accuracy_ffa_online) = netffa_online.train_online(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    max_it=150000, conv_loss=0.50, \n",
    "    report_rate=batchsize, lr=0.01,\n",
    "    model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "844 844 844 844 844\n"
     ]
    }
   ],
   "source": [
    "print(len(losses_ffa_online_ce), \n",
    "      len(test_loss_ffa_online_ce),\n",
    "      len(losses_ffa_online_mse),\n",
    "      len(test_loss_ffa_online_mse),\n",
    "      len(accuracy_ffa_online)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_online_ce.npy', np.asarray(losses_ffa_online_ce))\n",
    "np.save('results/netffa/test_loss_ffa_online_ce.npy', np.asarray(test_loss_ffa_online_ce))\n",
    "np.save('results/netffa/losses_ffa_online_mse.npy', np.asarray(losses_ffa_online_mse))\n",
    "np.save('results/netffa/test_loss_ffa_online_mse.npy', np.asarray(test_loss_ffa_online_mse))\n",
    "np.save('results/netffa/accuracy_ffa_online.npy', np.asarray(accuracy_ffa_online))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "device: cpu\n",
      "input:\n",
      "  path: datasets\n",
      "  batch_size: 128\n",
      "model:\n",
      "  peer_normalization: 0.03\n",
      "  momentum: 0.9\n",
      "  hidden_dim: 500\n",
      "  num_layers: 2\n",
      "training:\n",
      "  epochs: 100\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0\n",
      "  momentum: 0\n",
      "  downstream_learning_rate: 0.001\n",
      "  downstream_weight_decay: 0\n",
      "  val_idx: 0\n",
      "  final_test: true\n",
      "\n",
      "FF_model(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  )\n",
      "  (ff_loss): BCEWithLogitsLoss()\n",
      "  (linear_classifier): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=10, bias=False)\n",
      "  )\n",
      "  (classification_loss): CrossEntropyLoss()\n",
      ") \n",
      "\n",
      "...completed  0  epochs of training. \n",
      "\n",
      "            Current innate loss:  54.250599748599605, \n",
      "\n",
      "            Current training cross_entropy loss:  1.1063182309547566, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.121723175048828, \n",
      "   \n",
      "            Current testing accuracy:  0.384 \n",
      "         \n",
      "            \n",
      "...completed  1  epochs of training. \n",
      "\n",
      "            Current innate loss:  38.19058132467803, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7683097876562095, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.2204933166503906, \n",
      "   \n",
      "            Current testing accuracy:  0.396 \n",
      "         \n",
      "            \n",
      "...completed  2  epochs of training. \n",
      "\n",
      "            Current innate loss:  29.883563592567207, \n",
      "\n",
      "            Current training cross_entropy loss:  0.605814536073193, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.4040873050689697, \n",
      "   \n",
      "            Current testing accuracy:  0.397 \n",
      "         \n",
      "            \n",
      "...completed  3  epochs of training. \n",
      "\n",
      "            Current innate loss:  24.439759585057725, \n",
      "\n",
      "            Current training cross_entropy loss:  0.5103917722561344, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.4496915340423584, \n",
      "   \n",
      "            Current testing accuracy:  0.398 \n",
      "         \n",
      "            \n",
      "...completed  4  epochs of training. \n",
      "\n",
      "            Current innate loss:  20.75711267038902, \n",
      "\n",
      "            Current training cross_entropy loss:  0.44739979212143405, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.5698604583740234, \n",
      "   \n",
      "            Current testing accuracy:  0.398 \n",
      "         \n",
      "            \n",
      "...completed  5  epochs of training. \n",
      "\n",
      "            Current innate loss:  18.07232374107122, \n",
      "\n",
      "            Current training cross_entropy loss:  0.40209265108033243, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.6686747074127197, \n",
      "   \n",
      "            Current testing accuracy:  0.4 \n",
      "         \n",
      "            \n",
      "...completed  6  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.919218144008514, \n",
      "\n",
      "            Current training cross_entropy loss:  0.36797631704500533, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.7232718467712402, \n",
      "   \n",
      "            Current testing accuracy:  0.4 \n",
      "         \n",
      "            \n",
      "...completed  7  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.29416673584199, \n",
      "\n",
      "            Current training cross_entropy loss:  0.341077593785728, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.792142629623413, \n",
      "   \n",
      "            Current testing accuracy:  0.402 \n",
      "         \n",
      "            \n",
      "...completed  8  epochs of training. \n",
      "\n",
      "            Current innate loss:  12.909620828880286, \n",
      "\n",
      "            Current training cross_entropy loss:  0.3194835749605839, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.840909719467163, \n",
      "   \n",
      "            Current testing accuracy:  0.402 \n",
      "         \n",
      "            \n",
      "...completed  9  epochs of training. \n",
      "\n",
      "            Current innate loss:  11.765612033324212, \n",
      "\n",
      "            Current training cross_entropy loss:  0.3016494975558349, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.8214688301086426, \n",
      "   \n",
      "            Current testing accuracy:  0.402 \n",
      "         \n",
      "            \n",
      "...completed  10  epochs of training. \n",
      "\n",
      "            Current innate loss:  10.931047843059263, \n",
      "\n",
      "            Current training cross_entropy loss:  0.28626595335717525, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.928504467010498, \n",
      "   \n",
      "            Current testing accuracy:  0.403 \n",
      "         \n",
      "            \n",
      "...completed  11  epochs of training. \n",
      "\n",
      "            Current innate loss:  10.129487243452058, \n",
      "\n",
      "            Current training cross_entropy loss:  0.2732500908028635, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.9024829864501953, \n",
      "   \n",
      "            Current testing accuracy:  0.403 \n",
      "         \n",
      "            \n",
      "...completed  12  epochs of training. \n",
      "\n",
      "            Current innate loss:  9.51345326384459, \n",
      "\n",
      "            Current training cross_entropy loss:  0.2616977377127673, \n",
      "\n",
      "            Current testing cross_entropy loss:  3.9906492233276367, \n",
      "   \n",
      "            Current testing accuracy:  0.403 \n",
      "         \n",
      "            \n",
      "...completed  13  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.09211480946093, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4153754736451652, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.632002830505371, \n",
      "   \n",
      "            Current testing accuracy:  0.553 \n",
      "         \n",
      "            \n",
      "...completed  14  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.61105221956209, \n",
      "\n",
      "            Current training cross_entropy loss:  0.44871279127787767, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.6583468914031982, \n",
      "   \n",
      "            Current testing accuracy:  0.506 \n",
      "         \n",
      "            \n",
      "...completed  15  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.54435052091269, \n",
      "\n",
      "            Current training cross_entropy loss:  0.45464996512336053, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.7938874959945679, \n",
      "   \n",
      "            Current testing accuracy:  0.517 \n",
      "         \n",
      "            \n",
      "...completed  16  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.110868415708914, \n",
      "\n",
      "            Current training cross_entropy loss:  0.45286825285520654, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.8353869915008545, \n",
      "   \n",
      "            Current testing accuracy:  0.519 \n",
      "         \n",
      "            \n",
      "...completed  17  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.500798697527578, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4480556417325623, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.9023358821868896, \n",
      "   \n",
      "            Current testing accuracy:  0.519 \n",
      "         \n",
      "            \n",
      "...completed  18  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.898352728819757, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4418423967556837, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.9444282054901123, \n",
      "   \n",
      "            Current testing accuracy:  0.529 \n",
      "         \n",
      "            \n",
      "...completed  19  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.336558305726939, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4348940533390309, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.9761000871658325, \n",
      "   \n",
      "            Current testing accuracy:  0.532 \n",
      "         \n",
      "            \n",
      "...completed  20  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.75663834751032, \n",
      "\n",
      "            Current training cross_entropy loss:  0.42799715860729004, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.999545693397522, \n",
      "   \n",
      "            Current testing accuracy:  0.537 \n",
      "         \n",
      "            \n",
      "...completed  21  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.19223086002875, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4210480215878988, \n",
      "\n",
      "            Current testing cross_entropy loss:  2.0323550701141357, \n",
      "   \n",
      "            Current testing accuracy:  0.538 \n",
      "         \n",
      "            \n",
      "...completed  22  epochs of training. \n",
      "\n",
      "            Current innate loss:  12.68994063608129, \n",
      "\n",
      "            Current training cross_entropy loss:  0.41423835832402095, \n",
      "\n",
      "            Current testing cross_entropy loss:  2.06111478805542, \n",
      "   \n",
      "            Current testing accuracy:  0.537 \n",
      "         \n",
      "            \n",
      "...completed  23  epochs of training. \n",
      "\n",
      "            Current innate loss:  12.210954088378449, \n",
      "\n",
      "            Current training cross_entropy loss:  0.4075793293890352, \n",
      "\n",
      "            Current testing cross_entropy loss:  2.1114015579223633, \n",
      "   \n",
      "            Current testing accuracy:  0.536 \n",
      "         \n",
      "            \n",
      "...completed  24  epochs of training. \n",
      "\n",
      "            Current innate loss:  11.76981039461925, \n",
      "\n",
      "            Current training cross_entropy loss:  0.40105334778855567, \n",
      "\n",
      "            Current testing cross_entropy loss:  2.120497226715088, \n",
      "   \n",
      "            Current testing accuracy:  0.538 \n",
      "         \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "net_ffa_nonstat = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_nonstat_ce, test_loss_ffa_nonstat_ce, \n",
    " losses_ffa_nonstat_mse, test_loss_ffa_nonstat_mse,\n",
    " accuracy_ffa_nonstat) = net_ffa_nonstat.train_nonstationary(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    epochs=numepochs, model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4841 25 4841 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(losses_ffa_nonstat_ce), \n",
    "      len(test_loss_ffa_nonstat_ce),\n",
    "      len(losses_ffa_nonstat_mse),\n",
    "      len(test_loss_ffa_nonstat_mse),\n",
    "      len(accuracy_ffa_nonstat)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_nonstat_ce.npy', np.asarray(losses_ffa_nonstat_ce))\n",
    "np.save('results/netffa/test_loss_ffa_nonstat_ce.npy', np.asarray(test_loss_ffa_nonstat_ce))\n",
    "np.save('results/netffa/losses_ffa_nonstat_mse.npy', np.asarray(losses_ffa_nonstat_mse))\n",
    "np.save('results/netffa/test_loss_ffa_nonstat_mse.npy', np.asarray(test_loss_ffa_nonstat_mse))\n",
    "np.save('results/netffa/accuracy_ffa_nonstat.npy', np.asarray(accuracy_ffa_nonstat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 42\n",
      "device: cpu\n",
      "input:\n",
      "  path: datasets\n",
      "  batch_size: 128\n",
      "model:\n",
      "  peer_normalization: 0.03\n",
      "  momentum: 0.9\n",
      "  hidden_dim: 500\n",
      "  num_layers: 2\n",
      "training:\n",
      "  epochs: 100\n",
      "  learning_rate: 0.001\n",
      "  weight_decay: 0\n",
      "  momentum: 0\n",
      "  downstream_learning_rate: 0.001\n",
      "  downstream_weight_decay: 0\n",
      "  val_idx: 0\n",
      "  final_test: true\n",
      "\n",
      "FF_model(\n",
      "  (model): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "  )\n",
      "  (ff_loss): BCEWithLogitsLoss()\n",
      "  (linear_classifier): Sequential(\n",
      "    (0): Linear(in_features=500, out_features=10, bias=False)\n",
      "  )\n",
      "  (classification_loss): CrossEntropyLoss()\n",
      ") \n",
      "\n",
      "...completed  0  epochs of training. \n",
      "\n",
      "            Current innate loss:  47.83585045154278, \n",
      "\n",
      "            Current training cross_entropy loss:  2.082044208049774, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.601974368095398, \n",
      "   \n",
      "            Current testing accuracy:  0.706 \n",
      "         \n",
      "            \n",
      "...completed  1  epochs of training. \n",
      "\n",
      "            Current innate loss:  43.026067212911755, \n",
      "\n",
      "            Current training cross_entropy loss:  1.8250050297150244, \n",
      "\n",
      "            Current testing cross_entropy loss:  1.0120466947555542, \n",
      "   \n",
      "            Current testing accuracy:  0.756 \n",
      "         \n",
      "            \n",
      "...completed  2  epochs of training. \n",
      "\n",
      "            Current innate loss:  38.39896525684585, \n",
      "\n",
      "            Current training cross_entropy loss:  1.5996860942270001, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.7651218771934509, \n",
      "   \n",
      "            Current testing accuracy:  0.793 \n",
      "         \n",
      "            \n",
      "...completed  3  epochs of training. \n",
      "\n",
      "            Current innate loss:  35.197245308069085, \n",
      "\n",
      "            Current training cross_entropy loss:  1.431257771834349, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.6279633045196533, \n",
      "   \n",
      "            Current testing accuracy:  0.826 \n",
      "         \n",
      "            \n",
      "...completed  4  epochs of training. \n",
      "\n",
      "            Current innate loss:  32.331414269667405, \n",
      "\n",
      "            Current training cross_entropy loss:  1.3045746279068482, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.5567597150802612, \n",
      "   \n",
      "            Current testing accuracy:  0.841 \n",
      "         \n",
      "            \n",
      "...completed  5  epochs of training. \n",
      "\n",
      "            Current innate loss:  29.826282320674668, \n",
      "\n",
      "            Current training cross_entropy loss:  1.2072035091809736, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.5015517473220825, \n",
      "   \n",
      "            Current testing accuracy:  0.854 \n",
      "         \n",
      "            \n",
      "...completed  6  epochs of training. \n",
      "\n",
      "            Current innate loss:  27.675512602041056, \n",
      "\n",
      "            Current training cross_entropy loss:  1.1298233476641415, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.4660837650299072, \n",
      "   \n",
      "            Current testing accuracy:  0.863 \n",
      "         \n",
      "            \n",
      "...completed  7  epochs of training. \n",
      "\n",
      "            Current innate loss:  25.893254466393056, \n",
      "\n",
      "            Current training cross_entropy loss:  1.0667121291447144, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.44494205713272095, \n",
      "   \n",
      "            Current testing accuracy:  0.871 \n",
      "         \n",
      "            \n",
      "...completed  8  epochs of training. \n",
      "\n",
      "            Current innate loss:  24.34041057733389, \n",
      "\n",
      "            Current training cross_entropy loss:  1.0141427609485778, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.42658939957618713, \n",
      "   \n",
      "            Current testing accuracy:  0.873 \n",
      "         \n",
      "            \n",
      "...completed  9  epochs of training. \n",
      "\n",
      "            Current innate loss:  22.985449744126736, \n",
      "\n",
      "            Current training cross_entropy loss:  0.9696412145556548, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.4110877215862274, \n",
      "   \n",
      "            Current testing accuracy:  0.876 \n",
      "         \n",
      "            \n",
      "...completed  10  epochs of training. \n",
      "\n",
      "            Current innate loss:  21.78733462698254, \n",
      "\n",
      "            Current training cross_entropy loss:  0.9315475093248563, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3993780314922333, \n",
      "   \n",
      "            Current testing accuracy:  0.879 \n",
      "         \n",
      "            \n",
      "...completed  11  epochs of training. \n",
      "\n",
      "            Current innate loss:  20.722088516981174, \n",
      "\n",
      "            Current training cross_entropy loss:  0.8983522961728084, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.38786250352859497, \n",
      "   \n",
      "            Current testing accuracy:  0.882 \n",
      "         \n",
      "            \n",
      "...completed  12  epochs of training. \n",
      "\n",
      "            Current innate loss:  19.78800420413121, \n",
      "\n",
      "            Current training cross_entropy loss:  0.8691781898515935, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3804551959037781, \n",
      "   \n",
      "            Current testing accuracy:  0.885 \n",
      "         \n",
      "            \n",
      "...completed  13  epochs of training. \n",
      "\n",
      "            Current innate loss:  18.943191408368694, \n",
      "\n",
      "            Current training cross_entropy loss:  0.8432661240845373, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3748491406440735, \n",
      "   \n",
      "            Current testing accuracy:  0.889 \n",
      "         \n",
      "            \n",
      "...completed  14  epochs of training. \n",
      "\n",
      "            Current innate loss:  18.16662462625748, \n",
      "\n",
      "            Current training cross_entropy loss:  0.820084464718134, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3714127838611603, \n",
      "   \n",
      "            Current testing accuracy:  0.888 \n",
      "         \n",
      "            \n",
      "...completed  15  epochs of training. \n",
      "\n",
      "            Current innate loss:  17.464312970867525, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7992526859045028, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3643338978290558, \n",
      "   \n",
      "            Current testing accuracy:  0.887 \n",
      "         \n",
      "            \n",
      "...completed  16  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.81666714260481, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7803800278434566, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3630030155181885, \n",
      "   \n",
      "            Current testing accuracy:  0.89 \n",
      "         \n",
      "            \n",
      "...completed  17  epochs of training. \n",
      "\n",
      "            Current innate loss:  16.213235322600415, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7632058865409291, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.35846978425979614, \n",
      "   \n",
      "            Current testing accuracy:  0.886 \n",
      "         \n",
      "            \n",
      "...completed  18  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.678244680335165, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7474212700900761, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.35456979274749756, \n",
      "   \n",
      "            Current testing accuracy:  0.892 \n",
      "         \n",
      "            \n",
      "...completed  19  epochs of training. \n",
      "\n",
      "            Current innate loss:  15.181424534137433, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7328190839405243, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3510766625404358, \n",
      "   \n",
      "            Current testing accuracy:  0.891 \n",
      "         \n",
      "            \n",
      "...completed  20  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.720349944030845, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7193363414579259, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.34417617321014404, \n",
      "   \n",
      "            Current testing accuracy:  0.897 \n",
      "         \n",
      "            \n",
      "...completed  21  epochs of training. \n",
      "\n",
      "            Current innate loss:  14.275276849069796, \n",
      "\n",
      "            Current training cross_entropy loss:  0.7068869544423265, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.342999666929245, \n",
      "   \n",
      "            Current testing accuracy:  0.893 \n",
      "         \n",
      "            \n",
      "...completed  22  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.86029407976729, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6952743929531529, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.33870282769203186, \n",
      "   \n",
      "            Current testing accuracy:  0.895 \n",
      "         \n",
      "            \n",
      "...completed  23  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.490610339664496, \n",
      "\n",
      "            Current training cross_entropy loss:  0.684340869810464, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.33776533603668213, \n",
      "   \n",
      "            Current testing accuracy:  0.9 \n",
      "         \n",
      "            \n",
      "...completed  24  epochs of training. \n",
      "\n",
      "            Current innate loss:  13.127237348177495, \n",
      "\n",
      "            Current training cross_entropy loss:  0.6741762727315609, \n",
      "\n",
      "            Current testing cross_entropy loss:  0.3330245316028595, \n",
      "   \n",
      "            Current testing accuracy:  0.897 \n",
      "         \n",
      "            \n"
     ]
    }
   ],
   "source": [
    "if GlobalHydra().is_initialized():\n",
    "    GlobalHydra().clear()\n",
    "net_ffa_noisy = net_ff_model.net_FF_model(rng)\n",
    "(losses_ffa_noisy_ce, test_loss_ffa_noisy_ce, \n",
    " losses_ffa_noisy_mse, test_loss_ffa_noisy_mse,\n",
    " accuracy_ffa_noisy) = net_ffa_noisy.train_noisydata(\n",
    "    train_images, train_labels, \n",
    "    test_images[:, indices], test_labels[:, indices],\n",
    "    epochs=numepochs, model='ff_com', return_loss='cross_entropy'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9750 25 9750 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(losses_ffa_noisy_ce), \n",
    "      len(test_loss_ffa_noisy_ce),\n",
    "      len(losses_ffa_noisy_mse),\n",
    "      len(test_loss_ffa_noisy_mse),\n",
    "      len(accuracy_ffa_noisy)\n",
    "      )\n",
    "np.save('results/netffa/losses_ffa_noisy_ce.npy', np.asarray(losses_ffa_noisy_ce))\n",
    "np.save('results/netffa/test_loss_ffa_noisy_ce.npy', np.asarray(test_loss_ffa_noisy_ce))\n",
    "np.save('results/netffa/losses_ffa_noisy_mse.npy', np.asarray(losses_ffa_noisy_mse))\n",
    "np.save('results/netffa/test_loss_ffa_noisy_mse.npy', np.asarray(test_loss_ffa_noisy_mse))\n",
    "np.save('results/netffa/accuracy_ffa_noisy.npy', np.asarray(accuracy_ffa_noisy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/test/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_test = data[0]\n",
    "accuracy_node_perturb_test = data[1]\n",
    "test_losses_node_perturb_test = data[2]\n",
    "snr_node_perturb_test = data[3]\n",
    "cosine_similarity_node_perturb_test = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "# create a network and train it using node perturbation\n",
    "# with contextlib.redirect_stdout(io.StringIO()):\n",
    "#     netnodeperturb = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "#     (losses_np_normal, accuracy_np_normal, test_loss_np_normal, snr_np_normal, cosine_similarity_np_normal) = \\\n",
    "#         netnodeperturb.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "#                              learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, report=report, report_rate=rep_rate)\n",
    "\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/normal/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_normal = data[0]\n",
    "accuracy_node_perturb_normal = data[1]\n",
    "test_losses_node_perturb_normal = data[2]\n",
    "snr_node_perturb_normal = data[3]\n",
    "cosine_similarity_node_perturb_normal = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "# with contextlib.redirect_stdout(io.StringIO()):\n",
    "#     netnodeperturb_online = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "#     (losses_np_online, accuracy_np_online, test_loss_np_online, snr_np_online, cosine_similarity_np_online) = \\\n",
    "#         netnodeperturb_online.train_online(rng_bp2, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "#                       learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-4, algorithm='node_perturb', noise=noise, \\\n",
    "#                       report=report, report_rate=batchsize)\n",
    "\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/online/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_online = data[0]\n",
    "accuracy_node_perturb_online = data[1]\n",
    "test_losses_node_perturb_online = data[2]\n",
    "snr_node_perturb_online = data[3]\n",
    "cosine_similarity_node_perturb_online = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "# with contextlib.redirect_stdout(io.StringIO()):\n",
    "#     nodeperturb_noisy = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "#     (losses_np_noisy, accuracy_np_noisy, test_loss_np_noisy, snr_np_noisy, cosine_similarity_np_noisy) = \\\n",
    "#         nodeperturb_noisy.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "#                         learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, \\\n",
    "#                         noise_type='gauss',report=report, report_rate=rep_rate)\n",
    "\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/noisy/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_noisy = data[0]\n",
    "accuracy_node_perturb_noisy = data[1]\n",
    "test_losses_node_perturb_noisy = data[2]\n",
    "snr_node_perturb_noisy = data[3]\n",
    "cosine_similarity_node_perturb_noisy = data[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "# with contextlib.redirect_stdout(io.StringIO()):\n",
    "#     nodeperturb_nonstat = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "#     (losses_np_nonstat, accuracy_np_nonstat, test_loss_np_nonstat, snr_np_nonstat, cosine_similarity_np_nonstat) = \\\n",
    "#         nodeperturb_nonstat.train_nonstat_data(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "#                         learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, \\\n",
    "#                         report=report, report_rate=1)\n",
    "\n",
    "# to load the files again, in the main doc:\n",
    "filenames= [\"losses_node_perturb\", \"accuracy_node_perturb\", \"test_losses_node_perturb\", \"snr_node_perturb\", \"cosine_similarity_node_perturb\"]\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, name in enumerate(filenames):\n",
    "  data.append(np.fromfile(f\"data/node_perturb/non-stat/{filenames[i]}.csv\", dtype=float, sep=\",\"))\n",
    "\n",
    "losses_node_perturb_non_stat = data[0]\n",
    "accuracy_node_perturb_non_stat = data[1]\n",
    "test_losses_node_perturb_non_stat = data[2]\n",
    "snr_node_perturb_non_stat = data[3]\n",
    "cosine_similarity_node_perturb_non_stat = data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolen-Pollack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "netkolepoll = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_normal, accuracy_kp_normal, test_loss_kp_normal, snr_kp_normal, cosine_similarity_kp_normal) = \\\n",
    "    netkolepoll.train(rng_kp, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)\n",
    "\n",
    "rng = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "net_kp_online = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_online, accuracy_kp_online, test_loss_kp_online, snr_kp_online, cosine_similarity_kp_online) = \\\n",
    "    net_kp_online.train_online(rng, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-1, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "net_kp_noisy = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_noisy, accuracy_kp_noisy, test_loss_kp_noisy, snr_kp_noisy, cosine_similarity_kp_noisy) = \\\n",
    "    net_kp_noisy.train(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_kp_nonstat = KolenPollackMLP(rng, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_nonstat, accuracy_kp_nonstat, test_loss_kp_nonstat, snr_kp_nonstat, cosine_similarity_kp_nonstat) = \\\n",
    "    net_kp_nonstat.train_nonstat_data(rng, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if run without node perturb and ffa\n",
    "# FFA\n",
    "snr_ffa_normal, cosine_similarity_ffa_normal = [0], [0]\n",
    "snr_ffa_online, cosine_similarity_ffa_online = [0], [0]\n",
    "snr_ffa_noisy, cosine_similarity_ffa_noisy = [0], [0]\n",
    "snr_ffa_nonstat, cosine_similarity_ffa_nonstat = [0], [0]\n",
    "\n",
    "# Node Perturb\n",
    "losses_np_normal, accuracy_np_normal, test_loss_np_normal, snr_np_normal, cosine_similarity_np_normal = [0], [0], [0], [0], [0]\n",
    "losses_np_online, accuracy_np_online, test_loss_np_online, snr_np_online, cosine_similarity_np_online = [0], [0], [0], [0], [0]\n",
    "losses_np_noisy, accuracy_np_noisy, test_loss_np_noisy, snr_np_noisy, cosine_similarity_np_noisy = [0], [0], [0], [0], [0]\n",
    "losses_np_nonstat, accuracy_np_nonstat, test_loss_np_nonstat, snr_np_nonstat, cosine_similarity_np_nonstat = [0], [0], [0], [0], [0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays\n",
    "# normal \n",
    "tr_loss_normal = [losses_bp_normal, losses_ffa_normal_ce, losses_np_normal, losses_kp_normal]\n",
    "te_acc_normal = [accuracy_bp_normal, accuracy_ffa_normal, accuracy_np_normal, accuracy_kp_normal]\n",
    "te_loss_normal = [test_loss_bp_normal, test_loss_ffa_normal_ce, test_loss_np_normal, test_loss_kp_normal]\n",
    "snr_normal = [snr_bp_normal, snr_ffa_normal, snr_np_normal, snr_kp_normal]\n",
    "cosine_similarity_normal = [cosine_similarity_bp_normal, cosine_similarity_ffa_normal, cosine_similarity_np_normal, cosine_similarity_kp_normal]\n",
    "\n",
    "# online\n",
    "# Calculate the moving average\n",
    "window_size = 100\n",
    "losses_bp_online_mean = uniform_filter1d(losses_bp_online, size=window_size)\n",
    "losses_ffa_online_mean = uniform_filter1d(losses_ffa_online_ce, size=window_size)\n",
    "losses_np_online_mean = uniform_filter1d(losses_np_online, size=window_size)\n",
    "losses_kp_online_mean = uniform_filter1d(losses_kp_online, size=window_size)\n",
    "tr_loss_online_mean = [losses_bp_online_mean, losses_ffa_online_mean, losses_np_online_mean, losses_kp_online_mean]\n",
    "\n",
    "tr_loss_online = [losses_bp_online, losses_ffa_online_ce, losses_np_online, losses_kp_online]\n",
    "te_acc_online = [accuracy_bp_online, accuracy_ffa_online, accuracy_np_online, accuracy_kp_online]\n",
    "te_loss_online = [test_loss_bp_online, test_loss_ffa_online_ce, test_loss_np_online, test_loss_kp_online]\n",
    "snr_online = [snr_bp_online, snr_ffa_online, snr_np_online, snr_kp_online]\n",
    "cosine_similarity_online = [cosine_similarity_bp_online, cosine_similarity_ffa_online, cosine_similarity_np_online, cosine_similarity_kp_online]\n",
    "\n",
    "# noisy\n",
    "tr_loss_noisy = [losses_bp_noisy, losses_ffa_noisy_ce, losses_np_noisy, losses_kp_noisy]\n",
    "te_acc_noisy = [accuracy_bp_noisy, accuracy_ffa_noisy, accuracy_np_noisy, accuracy_kp_noisy]\n",
    "te_loss_noisy = [test_loss_bp_noisy, test_loss_ffa_noisy_ce, test_loss_np_noisy, test_loss_kp_noisy]\n",
    "snr_noisy = [snr_bp_noisy, snr_ffa_noisy, snr_np_noisy, snr_kp_noisy]\n",
    "cosine_similarity_noisy = [cosine_similarity_bp_noisy, cosine_similarity_ffa_noisy, cosine_similarity_np_noisy, cosine_similarity_kp_noisy]\n",
    "\n",
    "# nonstat\n",
    "tr_loss_nonstat = [losses_bp_nonstat, losses_ffa_nonstat, losses_np_nonstat, losses_kp_nonstat]\n",
    "te_acc_nonstat = [accuracy_bp_nonstat, accuracy_ffa_nonstat, accuracy_np_nonstat, accuracy_kp_nonstat]\n",
    "te_loss_nonstat = [test_loss_bp_nonstat, test_loss_ffa_nonstat_ce, test_loss_np_nonstat, test_loss_kp_nonstat]\n",
    "snr_nonstat = [snr_bp_nonstat, snr_ffa_nonstat, snr_np_nonstat, snr_kp_nonstat]\n",
    "cosine_similarity_nonstat = [cosine_similarity_bp_nonstat, cosine_similarity_ffa_nonstat, cosine_similarity_np_nonstat, cosine_similarity_kp_nonstat]\n",
    "\n",
    "# algorithms\n",
    "# algos = ['normal', 'online', 'noisy', 'nonstat']\n",
    "algos = ['normal', 'noisy', 'nonstat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "for i, algo in enumerate(algos):\n",
    "    if algo == 'normal':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_normal, te_acc_normal, te_loss_normal, snr_normal, cosine_similarity_normal\n",
    "    # elif algo == 'online':\n",
    "    #     tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_online, te_acc_online, te_loss_online, snr_online, cosine_similarity_online\n",
    "    elif algo == 'noisy':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_noisy, te_acc_noisy, te_loss_noisy, snr_noisy, cosine_similarity_noisy\n",
    "    elif algo == 'nonstat':\n",
    "        tr_loss, te_acc, te_loss, snr, cos_sim = tr_loss_nonstat, te_acc_nonstat, te_loss_nonstat, snr_nonstat, cosine_similarity_nonstat\n",
    "        \n",
    "    # plot\n",
    "    plt.figure(figsize=(30, 5))\n",
    "    plt.subplot(151)\n",
    "\n",
    "    plt.plot(tr_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(tr_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(tr_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(tr_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    \n",
    "    plt.xlabel(\"Updates (every batch)\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training loss\")\n",
    "\n",
    "    plt.subplot(152)\n",
    "    plt.plot(te_acc[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_acc[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_acc[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_acc[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Performance over time\")\n",
    "\n",
    "    plt.subplot(153)\n",
    "    plt.plot(te_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Test loss\")\n",
    "\n",
    "    plt.subplot(154)\n",
    "    with plt.xkcd():\n",
    "            x = [0, 1, 2, 3]\n",
    "            snr_vals = [snr[1], snr[2], snr[3], snr[0]]\n",
    "            colors = ['gold', 'c', 'k', 'r']\n",
    "            labels = ['FFA', 'Node Perturbation', 'Kolen Pollack', 'Backprop']\n",
    "            plt.bar(x, snr_vals, color=colors, tick_label=labels)\n",
    "            plt.xticks(rotation=90)\n",
    "            plt.ylabel('SNR')\n",
    "            plt.xlabel('Algorithm')\n",
    "            plt.title('Gradient SNR')\n",
    "\n",
    "    plt.subplot(155)\n",
    "    with plt.xkcd():\n",
    "        plt.plot(cos_sim[0], label=\"Backprop\", color='r')\n",
    "        plt.plot(cos_sim[1], label=\"FFA\", color='gold')\n",
    "        plt.plot(cos_sim[2], label=\"Node Perturbation\", color='c')\n",
    "        plt.plot(cos_sim[3], label=\"Kolen-Pollack\", color='k')\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Cosine Sim\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Cosine Similarity to Backprop\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning separately becuase of different lenghts and additional smoothing operation\n",
    "# plot\n",
    "plt.figure(figsize=(30, 5))\n",
    "plt.subplot(151)\n",
    "\n",
    "plt.plot(tr_loss_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(tr_loss_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(tr_loss_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(tr_loss_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "\n",
    "plt.xlabel(\"Updates (every batch)\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Training loss\")\n",
    "\n",
    "plt.subplot(152)\n",
    "plt.plot(te_acc_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(te_acc_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(te_acc_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(te_acc_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Performance over time\")\n",
    "\n",
    "plt.subplot(153)\n",
    "plt.plot(te_loss_online[0], label=\"Backprop\", color='r')\n",
    "plt.plot(te_loss_online[1], label=\"FFA\", color='gold')\n",
    "plt.plot(te_loss_online[2], label=\"Node Perturbation\", color='c')\n",
    "plt.plot(te_loss_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.legend()\n",
    "plt.title(\"Test loss\")\n",
    "\n",
    "plt.subplot(154)\n",
    "with plt.xkcd():\n",
    "        x = [0, 1, 2, 3]\n",
    "        snr_vals = [snr_online[1], snr_online[2], snr_online[3], snr_online[0]]\n",
    "        colors = ['gold', 'c', 'k', 'r']\n",
    "        labels = ['FFA', 'Node Perturbation', 'Kolen Pollack', 'Backprop']\n",
    "        plt.bar(x, snr_vals, color=colors, tick_label=labels)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.ylabel('SNR')\n",
    "        plt.xlabel('Algorithm')\n",
    "        plt.title('Gradient SNR')\n",
    "\n",
    "plt.subplot(155)\n",
    "with plt.xkcd():\n",
    "    plt.plot(cosine_similarity_online[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(cosine_similarity_online[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(cosine_similarity_online[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(cosine_similarity_online[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Cosine Sim\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Cosine Similarity to Backprop\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
