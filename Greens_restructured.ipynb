{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Much code taken from Neuromatch NeuroAI 2024 Microlearning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "from IPython.display import Image, SVG, display\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import torch\n",
    "import torchvision\n",
    "import contextlib\n",
    "import io\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "## Plotting and metrics imports\n",
    "from metrics import get_plotting_color, plot_examples, plot_class_distribution, plot_results, plot_scores_per_class, plot_weights\n",
    "\n",
    "## Other functions imports\n",
    "from helpers import sigmoid, ReLU, add_bias, create_batches, calculate_accuracy, calculate_cosine_similarity, calculate_grad_snr\n",
    "\n",
    "## MLP imports\n",
    "from MLP import MLP, NodePerturbMLP, KolenPollackMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST function\n",
    "def download_mnist(train_prop=0.8, keep_prop=0.5):\n",
    "\n",
    "  valid_prop = 1 - train_prop\n",
    "\n",
    "  discard_prop = 1 - keep_prop\n",
    "\n",
    "  transform = torchvision.transforms.Compose(\n",
    "      [torchvision.transforms.ToTensor(),\n",
    "      torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "      )\n",
    "\n",
    "\n",
    "  with contextlib.redirect_stdout(io.StringIO()): #to suppress output\n",
    "    \n",
    "    rng_data = np.random.default_rng(seed=42)\n",
    "    train_num = 50000\n",
    "    shuffled_train_idx = rng_data.permutation(train_num)\n",
    "\n",
    "    full_train_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=True, download=True, transform=transform)\n",
    "    full_test_set = torchvision.datasets.MNIST(\n",
    "          root=\"./data/\", train=False, download=True, transform=transform)\n",
    "    \n",
    "    full_train_images = full_train_set.data.numpy().astype(float) / 255\n",
    "    train_images = full_train_images[shuffled_train_idx[:train_num]].reshape((-1, 784)).T.copy()\n",
    "    valid_images = full_train_images[shuffled_train_idx[train_num:]].reshape((-1, 784)).T.copy()\n",
    "    test_images = (full_test_set.data.numpy().astype(float) / 255).reshape((-1, 784)).T\n",
    "\n",
    "    full_train_labels = torch.nn.functional.one_hot(full_train_set.targets, num_classes=10).numpy()\n",
    "    train_labels = full_train_labels[shuffled_train_idx[:train_num]].T.copy()\n",
    "    valid_labels = full_train_labels[shuffled_train_idx[train_num:]].T.copy()\n",
    "    test_labels = torch.nn.functional.one_hot(full_test_set.targets, num_classes=10).numpy().T\n",
    "\n",
    "    train_set, valid_set, _ = torch.utils.data.random_split(\n",
    "      full_train_set, [train_prop * keep_prop, valid_prop * keep_prop, discard_prop])\n",
    "    test_set, _ = torch.utils.data.random_split(\n",
    "      full_test_set, [keep_prop, discard_prop])\n",
    "\n",
    "  print(\"Number of examples retained:\")\n",
    "  print(f\"  {len(train_set)} (training)\")\n",
    "  print(f\"  {len(valid_set)} (validation)\")\n",
    "  print(f\"  {len(test_set)} (test)\")\n",
    "\n",
    "  return train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set, train_images, valid_images, test_images, train_labels, valid_labels, test_labels = download_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS\n",
    "NUM_INPUTS = 784\n",
    "NUM_OUTPUTS = 10\n",
    "numhidden = 500\n",
    "batchsize = 128\n",
    "initweight = 0.1\n",
    "learnrate = 0.001\n",
    "noise = 0.1\n",
    "numepochs = 25\n",
    "numrepeats = 1\n",
    "numbatches = int(train_images.shape[1] / batchsize)\n",
    "numupdates = numepochs * numbatches\n",
    "activation = 'sigmoid'\n",
    "report = True\n",
    "rep_rate = 1\n",
    "seed = 12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "rng_bp2 = np.random.default_rng(seed=seed)\n",
    "\n",
    "# select 1000 random images to test the accuracy on\n",
    "indices = rng_bp2.choice(range(test_images.shape[1]), size=(1000,), replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal learning\n",
    "netbackprop = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_backprop, accuracy_backprop, test_loss_backprop, snr_backprop, cosine_similarity_backprop) = \\\n",
    "    netbackprop.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online learning\n",
    "net_bp_online = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_online, accuracy_bp_online, test_loss_bp_online, snr_bp_online, cosine_similarity_bp_online) = \\\n",
    "    net_bp_online.train_online(rng_bp2, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-1, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "# create a network and train it using backprop\n",
    "netbackprop_noisy = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_noisy, accuracy_bp_noisy, test_loss_bp_noisy, snr_bp_noisy, cosine_similarity_bp_noisy) = \\\n",
    "    netbackprop_noisy.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_bp_nonstat = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_bp_nonstat, accuracy_bp_nonstat, test_loss_bp_nonstat, _) = \\\n",
    "    net_bp_nonstat.train_nonstat_data(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='backprop', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal learning\n",
    "# create a network and train it using ffa\n",
    "netffa = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_ffa, accuracy_ffa, test_loss_ffa, _) = \\\n",
    "    netffa.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='ffa', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "net_ffa_online = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_ffa_online, accuracy_ffa_online, test_loss_ffa_online, _) = \\\n",
    "    net_ffa_online.train_online(rng_bp2, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-4, algorithm='ffa', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a network and train it using ffa\n",
    "net_ffa_noisy = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_ffa_noisy, accuracy_ffa_noisy, test_loss_ffa_noisy, _) = \\\n",
    "    net_ffa_noisy.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='ffa', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_ffa_nonstat = MLP(rng_bp2, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_ffa_nonstat, accuracy_ffa_nonstat, test_loss_ffa_nonstat, _) = \\\n",
    "    net_ffa_nonstat.train_nonstat_data(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='ffa', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "# create a network and train it using node perturbation\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    netnodeperturb = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "    (losses_node_perturb, accuracy_node_perturb, test_loss_node_perturb, snr_node_perturb) = \\\n",
    "        netnodeperturb.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                             learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    netnodeperturb_online = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "    (losses_np_online, accuracy_np_online, test_loss_np_online, _) = \\\n",
    "        netnodeperturb_online.train_online(rng_bp2, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-4, algorithm='node_perturb', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    nodeperturb_noisy = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "    (losses_np_noisy, accuracy_np_noisy, test_loss_np_noisy, _) = \\\n",
    "        nodeperturb_noisy.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                        learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, \\\n",
    "                        noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "with contextlib.redirect_stdout(io.StringIO()):\n",
    "    nodeperturb_nonstat = NodePerturbMLP(rng_bp2, numhidden, num_inputs = 784, sigma=initweight, activation=activation)\n",
    "    (losses_np_nonstat, accuracy_np_nonstat, test_loss_np_nonstat, _) = \\\n",
    "        nodeperturb_nonstat.train_nonstat_data(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                        learning_rate=learnrate, batch_size=batchsize, algorithm='node_perturb', noise=noise, \\\n",
    "                        report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolen-Pollack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normal Learning\n",
    "netkolepoll = KolenPollackMLP(rng_kp, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kolepoll, accuracy_kolepoll, test_loss_kolepoll, _) = \\\n",
    "    netkolepoll.train(rng_kp, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=rep_rate)\n",
    "\n",
    "rng_bp2 = np.random.default_rng(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Online Learning\n",
    "net_kp_online = KolenPollackMLP(rng_kp, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_online, accuracy_kp_online, test_loss_kp_online, _) = \\\n",
    "    net_kp_online.train_online(rng_bp2, train_images, train_labels, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=0.01, max_it=numupdates*batchsize, conv_loss = 1e-1, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noisy Input\n",
    "net_kp_noisy = KolenPollackMLP(rng_kp, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_noisy, accuracy_kp_noisy, test_loss_kp_noisy, _) = \\\n",
    "    net_kp_noisy.train(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      noise_type='gauss',report=report, report_rate=rep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-Stationary Data\n",
    "net_kp_nonstat = KolenPollackMLP(rng_kp, numhidden, sigma=initweight, activation=activation)\n",
    "(losses_kp_nonstat, accuracy_kp_nonstat, test_loss_kp_nonstat, _) = \\\n",
    "    net_kp_nonstat.train_nonstat_data(rng_bp2, train_images, train_labels, numepochs, test_images[:, indices], test_labels[:, indices], \\\n",
    "                      learning_rate=learnrate, batch_size=batchsize, algorithm='kolepoll', noise=noise, \\\n",
    "                      report=report, report_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create arrays\n",
    "# normal \n",
    "tr_loss_normal = [losses_backprop, losses_ffa, losses_node_perturb, losses_kolepoll]\n",
    "te_acc_normal = [accuracy_backprop, accuracy_ffa, accuracy_node_perturb, accuracy_kolepoll]\n",
    "te_loss_normal = [test_loss_backprop, test_loss_ffa, test_loss_node_perturb, test_loss_kolepoll]\n",
    "\n",
    "# online\n",
    "# Calculate the moving average\n",
    "# window_size = 100\n",
    "# losses_online_mean = uniform_filter1d(losses_bp_online, size=window_size)\n",
    "# smoothed version not yet implemented\n",
    "\n",
    "tr_loss_online = [losses_bp_online, losses_ffa_online, losses_np_online, losses_kp_online]\n",
    "te_acc_online = [accuracy_bp_online, accuracy_ffa_online, accuracy_np_online, accuracy_kp_online]\n",
    "te_loss_online = [test_loss_bp_online, test_loss_ffa_online, test_loss_np_online, test_loss_kp_online]\n",
    "\n",
    "# noisy\n",
    "tr_loss_noisy = [losses_bp_noisy, losses_ffa_noisy, losses_np_noisy, losses_kp_noisy]\n",
    "te_acc_noisy = [accuracy_bp_noisy, accuracy_ffa_noisy, accuracy_np_noisy, accuracy_kp_noisy]\n",
    "te_loss_noisy = [test_loss_bp_noisy, test_loss_ffa_noisy, test_loss_np_noisy, test_loss_kp_noisy]\n",
    "\n",
    "# nonstat\n",
    "tr_loss_nonstat = [losses_bp_nonstat, losses_ffa_nonstat, losses_np_nonstat, losses_kp_nonstat]\n",
    "te_acc_nonstat = [accuracy_bp_nonstat, accuracy_ffa_nonstat, accuracy_np_nonstat, accuracy_kp_nonstat]\n",
    "te_loss_nonstat = [test_loss_bp_nonstat, test_loss_ffa_nonstat, test_loss_np_nonstat, test_loss_kp_nonstat]\n",
    "\n",
    "# algorithms\n",
    "algos = ['normal', 'online', 'noisy', 'nonstat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "for i, algo in enumerate(algos):\n",
    "    if algo == 'normal':\n",
    "        tr_loss, te_acc, te_loss = tr_loss_normal, te_acc_normal, te_loss_normal\n",
    "    elif algo == 'online':\n",
    "        tr_loss, te_acc, te_loss = tr_loss_online, te_acc_online, te_loss_online\n",
    "    elif algo == 'noisy':\n",
    "        tr_loss, te_acc, te_loss = tr_loss_noisy, te_acc_noisy, te_loss_noisy\n",
    "    elif algo == 'nonstat':\n",
    "        tr_loss, te_acc, te_loss = tr_loss_nonstat, te_acc_nonstat, te_loss_nonstat\n",
    "        \n",
    "    # plot\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.subplot(131)\n",
    "\n",
    "    plt.plot(tr_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(tr_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(tr_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(tr_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    \n",
    "    plt.xlabel(\"Updates (every batch)\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Training loss\")\n",
    "\n",
    "    plt.subplot(132)\n",
    "    plt.plot(te_acc[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_acc[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_acc[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_acc[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Performance over time\")\n",
    "\n",
    "    plt.subplot(133)\n",
    "    plt.plot(te_loss[0], label=\"Backprop\", color='r')\n",
    "    plt.plot(te_loss[1], label=\"FFA\", color='gold')\n",
    "    plt.plot(te_loss[2], label=\"Node Perturbation\", color='c')\n",
    "    plt.plot(te_loss[3], label=\"Kolen-Pollack\", color='k')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Test loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuromatch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
